{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18fb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db690892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/5/20 0:00</td>\n",
       "      <td>263</td>\n",
       "      <td>240</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/5/20 0:05</td>\n",
       "      <td>263</td>\n",
       "      <td>234</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/5/20 0:10</td>\n",
       "      <td>263</td>\n",
       "      <td>228</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/5/20 0:15</td>\n",
       "      <td>263</td>\n",
       "      <td>227</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/5/20 0:20</td>\n",
       "      <td>263</td>\n",
       "      <td>228</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015/5/20 0:25</td>\n",
       "      <td>263</td>\n",
       "      <td>226</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015/5/20 0:30</td>\n",
       "      <td>263</td>\n",
       "      <td>224</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015/5/20 0:35</td>\n",
       "      <td>263</td>\n",
       "      <td>219</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015/5/20 0:40</td>\n",
       "      <td>263</td>\n",
       "      <td>213</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015/5/20 0:45</td>\n",
       "      <td>263</td>\n",
       "      <td>205</td>\n",
       "      <td>2015/5/20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0    1    2          3\n",
       "0  2015/5/20 0:00  263  240  2015/5/20\n",
       "1  2015/5/20 0:05  263  234  2015/5/20\n",
       "2  2015/5/20 0:10  263  228  2015/5/20\n",
       "3  2015/5/20 0:15  263  227  2015/5/20\n",
       "4  2015/5/20 0:20  263  228  2015/5/20\n",
       "5  2015/5/20 0:25  263  226  2015/5/20\n",
       "6  2015/5/20 0:30  263  224  2015/5/20\n",
       "7  2015/5/20 0:35  263  219  2015/5/20\n",
       "8  2015/5/20 0:40  263  213  2015/5/20\n",
       "9  2015/5/20 0:45  263  205  2015/5/20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\admin\\Desktop\\week_of_data4_headFlaw.csv\",encoding='utf-8',header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec1072e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "      <th>gl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015/5/20 0:00</td>\n",
       "      <td>263</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015/5/20 0:05</td>\n",
       "      <td>263</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015/5/20 0:10</td>\n",
       "      <td>263</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015/5/20 0:15</td>\n",
       "      <td>263</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015/5/20 0:20</td>\n",
       "      <td>263</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   id   gl\n",
       "0  2015/5/20 0:00  263  240\n",
       "1  2015/5/20 0:05  263  234\n",
       "2  2015/5/20 0:10  263  228\n",
       "3  2015/5/20 0:15  263  227\n",
       "4  2015/5/20 0:20  263  228"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['time','id','gl', 'date']\n",
    "df = df[['time','id','gl']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055efc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([263, 106, 185, 218,  74,  53, 216, 219, 113,  47,  14, 134,  37,  61,\n",
      "        46,  33,  54, 278, 136, 274,   9, 265, 283, 273, 119, 129,  32,  27,\n",
      "       236,  26, 206,  18, 165,  31,  24, 267,  22, 247, 124,  79, 258,  58,\n",
      "       234, 175, 156, 158, 188, 189, 201, 203,  77, 127,  67,  70, 102, 137,\n",
      "         7,  95, 232,  23, 271, 130,  68, 227, 228, 164, 111, 251, 155, 245,\n",
      "       229, 277, 193, 101, 269,   3, 250, 116, 109,  81,  65, 184, 146, 105,\n",
      "       138,  76, 198, 139, 214, 166, 135, 123, 253, 187,  17, 205, 220, 243,\n",
      "       281],\n",
      "      dtype='int64', name='id')\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "ID = df['id'].value_counts().index\n",
    "pd.set_option('display.max_rows',100)\n",
    "print(ID)\n",
    "print(len(ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e89f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始获取id为263的被试数据：---------------------------------\n",
      "(2016, 3)\n"
     ]
    }
   ],
   "source": [
    "#获取数据\n",
    "\n",
    "# 创建空的DataFrame\n",
    "total_data = {'id': [],'month':[],'day':[],'hour':[],'minute':[],'weekday':[],'gl': []}\n",
    "total_data = pd.DataFrame(total_data)\n",
    "\n",
    "for i in ID:\n",
    "    print(\"开始获取id为{}的被试数据：---------------------------------\".format(i))\n",
    "    data = df[df['id']== i].copy() \n",
    "    print(data.shape)\n",
    "    #将time列设成date数据类型\n",
    "    data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "    #按照时间排序\n",
    "    data = data.sort_values(by='time') \n",
    "\n",
    "    #提取月为单独的一列\n",
    "    data['month'] = data['time'].dt.month\n",
    "\n",
    "    #提取日为单独的一列\n",
    "    data['day'] = data['time'].dt.day\n",
    "\n",
    "    #提取小时为单独的一列\n",
    "    data['hour'] = data['time'].dt.hour\n",
    "\n",
    "    #提取分钟为单独的一列\n",
    "    data['minute'] = data['time'].dt.minute\n",
    "\n",
    "    # 提取周几（0表示星期一，1表示星期二，依此类推）\n",
    "    data['weekday'] = data['time'].dt.dayofweek\n",
    "\n",
    "    data = data.set_index('time')\n",
    "\n",
    "#     data['target'] = data['gl'].shift(-1)\n",
    "\n",
    "    #使用了shift函数，在最后必然是有缺失值的，这里去掉缺失值所在行\n",
    "    data = data.dropna()     \n",
    "\n",
    "    data = data.astype(np.float32) # 修改数据类型\n",
    "    \n",
    "    #整合全部数据\n",
    "    total_data = pd.concat([total_data, data], ignore_index=True)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9757e0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>gl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>263.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  month   day  hour  minute  weekday     gl\n",
       "0     263.0    5.0  20.0   0.0     0.0      2.0  240.0\n",
       "1     263.0    5.0  20.0   0.0     5.0      2.0  234.0\n",
       "2     263.0    5.0  20.0   0.0    10.0      2.0  228.0\n",
       "3     263.0    5.0  20.0   0.0    15.0      2.0  227.0\n",
       "4     263.0    5.0  20.0   0.0    20.0      2.0  228.0\n",
       "...     ...    ...   ...   ...     ...      ...    ...\n",
       "2011  263.0    5.0  26.0  23.0    38.0      1.0  152.0\n",
       "2012  263.0    5.0  26.0  23.0    43.0      1.0  160.0\n",
       "2013  263.0    5.0  26.0  23.0    48.0      1.0  166.0\n",
       "2014  263.0    5.0  26.0  23.0    53.0      1.0  173.0\n",
       "2015  263.0    5.0  26.0  23.0    58.0      1.0  179.0\n",
       "\n",
       "[2016 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a2aa550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前被试(id == 263)的数据集长度： (2016, 7)\n"
     ]
    }
   ],
   "source": [
    "#窗口划分\n",
    "# 创建一个空的三维数组\n",
    "seq = 24\n",
    "train_total_feats = np.empty((0, seq, 7))\n",
    "train_total_targets = np.empty((0,7))\n",
    "\n",
    "validation_set_feats = np.empty((0, seq, 7))\n",
    "validation_set_targets = np.empty((0, 7))\n",
    "\n",
    "test_total_feats = np.empty((0, seq, 7))\n",
    "test_total_targets = np.empty((0, 7))\n",
    "\n",
    "# 设每条数据序列有48组数据\n",
    "\n",
    "for i in ID:\n",
    "    data = total_data[total_data['id'] == i]\n",
    "    print(\"当前被试(id == {})的数据集长度：\".format(i),data.shape)\n",
    "    \n",
    "    # 创建两个列表，用来存储当前被试的数据特征和标签\n",
    "    one_feats = np.empty((0, seq, 7))\n",
    "    one_targets = np.empty((0,7))\n",
    "    for index in range(len(data) - seq):\n",
    "        # 构建特征集\n",
    "        one_feats = np.concatenate((one_feats, data[index: index + seq].values.reshape(-1,seq,7)), axis=0)\n",
    "        # 构建target集\n",
    "        one_targets = np.concatenate((one_targets, data.iloc[index + seq].values.reshape(1,-1)), axis=0)\n",
    "        \n",
    "    #划分每个被试的训练集和测试集\n",
    "    test_size = int(np.round(0.03 * one_feats.shape[0]))  \n",
    "    \n",
    "    validation_size = int(np.round(0.2 * one_feats.shape[0]))  \n",
    "    \n",
    "    train_size = one_feats.shape[0] - test_size - validation_size \n",
    "    \n",
    "    train_total_feats = np.concatenate((train_total_feats, one_feats[:train_size, :, :]), axis=0)\n",
    "    train_total_targets = np.concatenate((train_total_targets, one_targets[:train_size,:]), axis=0)\n",
    "    \n",
    "    validation_set_feats = np.concatenate((validation_set_feats, one_feats[train_size:train_size+validation_size, :, :]), axis=0)\n",
    "    validation_set_targets = np.concatenate((validation_set_targets, one_targets[train_size:train_size+validation_size, :]), axis=0)\n",
    "    \n",
    "    test_total_feats = np.concatenate((test_total_feats, one_feats[-test_size:, :, :]), axis=0)\n",
    "    test_total_targets = np.concatenate((test_total_targets, one_targets[-test_size:, :]), axis=0)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "662b0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将变量保存到文件，以便下次直接读取，不用在处理数据\n",
    "np.save('./variable_file/train_total_feats_1.npy',train_total_feats)\n",
    "np.save('./variable_file/train_total_targets_1.npy',train_total_targets)\n",
    "\n",
    "np.save('./variable_file/validation_set_feats_1.npy',validation_set_feats)\n",
    "np.save('./variable_file/validation_set_targets_1.npy',validation_set_targets)\n",
    "\n",
    "np.save('./variable_file/test_total_feats_1.npy',test_total_feats)\n",
    "np.save('./variable_file/test_total_targets_1.npy',test_total_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "856369b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据窗口总数： (1534, 24, 7)\n",
      "训练数据标签总数： (1534, 7)\n",
      "验证数据窗口总数： (398, 24, 7)\n",
      "验证数据标签总数： (398, 7)\n",
      "测试数据窗口数： (60, 24, 7)\n",
      "测试数据标签数： (60, 7)\n"
     ]
    }
   ],
   "source": [
    "# 加载变量的代码：train_total_feats = np.load('./variable_file/train_total_feats_1.npy')\n",
    "train_total_feats = np.load('./variable_file/train_total_feats_1.npy')\n",
    "train_total_targets = np.load('./variable_file/train_total_targets_1.npy')\n",
    "\n",
    "validation_set_feats = np.load('./variable_file/validation_set_feats_1.npy')\n",
    "validation_set_targets = np.load('./variable_file/validation_set_targets_1.npy')\n",
    "\n",
    "test_total_feats = np.load('./variable_file/test_total_feats_1.npy')\n",
    "test_total_targets = np.load('./variable_file/test_total_targets_1.npy')\n",
    "\n",
    "print(\"训练数据窗口总数：\",train_total_feats.shape)\n",
    "print(\"训练数据标签总数：\",train_total_targets.shape)\n",
    "\n",
    "print(\"验证数据窗口总数：\",validation_set_feats.shape)\n",
    "print(\"验证数据标签总数：\",validation_set_targets.shape)\n",
    "\n",
    "print(\"测试数据窗口数：\",test_total_feats.shape)\n",
    "print(\"测试数据标签数：\",test_total_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dcd89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1 = MinMaxScaler(feature_range=(-1, 1))  \n",
    "scaler_train_total_feats = scaler1.fit_transform(train_total_feats.reshape(-1,7))\n",
    "scaler_train_total_targets = scaler1.transform(train_total_targets)\n",
    "\n",
    "scaler2 = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_validation_set_feats = scaler2.fit_transform(validation_set_feats.reshape(-1,7))\n",
    "scaler_validation_set_targets = scaler2.transform(validation_set_targets)\n",
    "\n",
    "scaler3 = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_test_total_feats = scaler3.fit_transform(test_total_feats.reshape(-1,7))\n",
    "scaler_test_total_targets = scaler3.transform(test_total_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb33ff2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将三维NumPy数组变成二维、进行归一化、反归一化、然后再将其变回三维的过程中，最终的数据可能不会与最初的数据完全一样。\n",
    "#这是因为归一化和反归一化过程中可能会引入数值精度的损失，导致微小的数值差异。(最重要的是数据排列不变)\n",
    "Raw_train_total_feats = scaler1.inverse_transform(scaler_train_total_feats).reshape(-1,24,7)\n",
    "np.allclose(train_total_feats, Raw_train_total_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17c023dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device(\"cuda:0\")\n",
    "trainX = torch.from_numpy(scaler_train_total_feats.reshape(-1,seq,7)).type(torch.Tensor).to(device)\n",
    "trainY = torch.from_numpy(scaler_train_total_targets).type(torch.Tensor).to(device)\n",
    "\n",
    "validationX = torch.from_numpy(scaler_validation_set_feats.reshape(-1,seq,7)).type(torch.Tensor).to(device)\n",
    "validationY = torch.from_numpy(scaler_validation_set_targets).type(torch.Tensor).to(device)\n",
    "\n",
    "testX = torch.from_numpy(scaler_test_total_feats.reshape(-1,seq,7)).type(torch.Tensor).to(device)\n",
    "testY = torch.from_numpy(scaler_test_total_targets).type(torch.Tensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13487b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape =  torch.Size([1534, 24, 7])\n",
      "y_train.shape =  torch.Size([1534, 7])\n",
      "x_test.shape =  torch.Size([398, 24, 7])\n",
      "y_test.shape =  torch.Size([398, 7])\n"
     ]
    }
   ],
   "source": [
    "print('x_train.shape = ',trainX.shape)\n",
    "print('y_train.shape = ',trainY.shape)\n",
    "print('x_test.shape = ',validationX.shape)\n",
    "print('y_test.shape = ',validationY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec08e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "train = TensorDataset(trainX,trainY)\n",
    "validation = TensorDataset(validationX,validationY)\n",
    "\n",
    "train_loader = DataLoader(dataset=train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=validation, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9df00abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_dim = 7      # 数据的特征数\n",
    "hidden_dim = 64   # LSTM1隐藏层的神经元个数\n",
    "num_layers = 2     # LSTM的层数\n",
    "output_dim = 7     # 预测值的特征数\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)   \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).cuda()\n",
    "        \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).cuda()\n",
    "        \n",
    "        out, (h0_1, c0_1) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        out = self.fc(out[:,-1,:]) \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b016d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(7, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 实例化模型\n",
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "model = model.to(device)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001) # 使用Adam优化算法\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')             # 使用均方差作为损失函数\n",
    "loss_fn = loss_fn.to(device)\n",
    "\n",
    "# 设定数据遍历次数\n",
    "num_epochs = 300\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dacdc663",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------第1轮训练开始----------------------\n",
      "训练次数：5, Loss: 0.536666989326477\n",
      "训练次数：10, Loss: 0.43250811100006104\n",
      "训练次数：15, Loss: 0.21603745222091675\n",
      "训练次数：20, Loss: 0.21882207691669464\n",
      "训练次数：25, Loss: 0.20482079684734344\n",
      "训练次数：30, Loss: 0.12428870797157288\n",
      "训练次数：35, Loss: 0.19429627060890198\n",
      "训练次数：40, Loss: 0.12291869521141052\n",
      "训练次数：45, Loss: 0.7191054224967957\n",
      "第 1 轮训练总体误差值：15.428574562072754\n",
      "**********开始本轮验证**********\n",
      "第 1 轮训练在整体验证集上的Loss: 6.764100827276707\n",
      "allen_0.pth 模型已保存\n",
      "--------------------第2轮训练开始----------------------\n",
      "训练次数：50, Loss: 0.72048020362854\n",
      "训练次数：55, Loss: 0.5057145357131958\n",
      "训练次数：60, Loss: 0.2092481553554535\n",
      "训练次数：65, Loss: 0.2606348693370819\n",
      "训练次数：70, Loss: 0.09261009097099304\n",
      "训练次数：75, Loss: 0.27190709114074707\n",
      "训练次数：80, Loss: 0.15641765296459198\n",
      "训练次数：85, Loss: 0.3151453733444214\n",
      "训练次数：90, Loss: 0.2050294578075409\n",
      "训练次数：95, Loss: 0.5451912879943848\n",
      "第 2 轮训练总体误差值：14.641502380371094\n",
      "**********开始本轮验证**********\n",
      "第 2 轮训练在整体验证集上的Loss: 5.148224115371704\n",
      "allen_1.pth 模型已保存\n",
      "--------------------第3轮训练开始----------------------\n",
      "训练次数：100, Loss: 0.28693708777427673\n",
      "训练次数：105, Loss: 0.2774108052253723\n",
      "训练次数：110, Loss: 0.13603003323078156\n",
      "训练次数：115, Loss: 0.11670920252799988\n",
      "训练次数：120, Loss: 0.07658253610134125\n",
      "训练次数：125, Loss: 0.1326874941587448\n",
      "训练次数：130, Loss: 0.10409168154001236\n",
      "训练次数：135, Loss: 0.19659219682216644\n",
      "训练次数：140, Loss: 0.15214858949184418\n",
      "第 3 轮训练总体误差值：10.114068984985352\n",
      "**********开始本轮验证**********\n",
      "第 3 轮训练在整体验证集上的Loss: 4.197206377983093\n",
      "allen_2.pth 模型已保存\n",
      "--------------------第4轮训练开始----------------------\n",
      "训练次数：145, Loss: 0.19185347855091095\n",
      "训练次数：150, Loss: 0.24590232968330383\n",
      "训练次数：155, Loss: 0.08727981895208359\n",
      "训练次数：160, Loss: 0.15303698182106018\n",
      "训练次数：165, Loss: 0.09788663685321808\n",
      "训练次数：170, Loss: 0.10896540433168411\n",
      "训练次数：175, Loss: 0.07183604687452316\n",
      "训练次数：180, Loss: 0.19588454067707062\n",
      "训练次数：185, Loss: 0.0789131224155426\n",
      "训练次数：190, Loss: 0.40023115277290344\n",
      "第 4 轮训练总体误差值：7.655417442321777\n",
      "**********开始本轮验证**********\n",
      "第 4 轮训练在整体验证集上的Loss: 2.9654723778367043\n",
      "allen_3.pth 模型已保存\n",
      "--------------------第5轮训练开始----------------------\n",
      "训练次数：195, Loss: 0.16990937292575836\n",
      "训练次数：200, Loss: 0.16730128228664398\n",
      "训练次数：205, Loss: 0.10884653031826019\n",
      "训练次数：210, Loss: 0.1363840252161026\n",
      "训练次数：215, Loss: 0.07669638097286224\n",
      "训练次数：220, Loss: 0.07298140972852707\n",
      "训练次数：225, Loss: 0.09707621484994888\n",
      "训练次数：230, Loss: 0.11004456132650375\n",
      "训练次数：235, Loss: 0.10312037914991379\n",
      "训练次数：240, Loss: 0.2622051537036896\n",
      "第 5 轮训练总体误差值：6.173983573913574\n",
      "**********开始本轮验证**********\n",
      "第 5 轮训练在整体验证集上的Loss: 2.2377732694149017\n",
      "allen_4.pth 模型已保存\n",
      "--------------------第6轮训练开始----------------------\n",
      "训练次数：245, Loss: 0.07922253012657166\n",
      "训练次数：250, Loss: 0.061106570065021515\n",
      "训练次数：255, Loss: 0.07818007469177246\n",
      "训练次数：260, Loss: 0.08368637412786484\n",
      "训练次数：265, Loss: 0.08095183223485947\n",
      "训练次数：270, Loss: 0.07755324244499207\n",
      "训练次数：275, Loss: 0.07359637320041656\n",
      "训练次数：280, Loss: 0.0698390007019043\n",
      "训练次数：285, Loss: 0.2498140037059784\n",
      "第 6 轮训练总体误差值：4.431976318359375\n",
      "**********开始本轮验证**********\n",
      "第 6 轮训练在整体验证集上的Loss: 1.7570757642388344\n",
      "allen_5.pth 模型已保存\n",
      "--------------------第7轮训练开始----------------------\n",
      "训练次数：290, Loss: 0.08821595460176468\n",
      "训练次数：295, Loss: 0.08499627560377121\n",
      "训练次数：300, Loss: 0.08956264704465866\n",
      "训练次数：305, Loss: 0.05954373627901077\n",
      "训练次数：310, Loss: 0.06696520745754242\n",
      "训练次数：315, Loss: 0.09738332778215408\n",
      "训练次数：320, Loss: 0.07241146266460419\n",
      "训练次数：325, Loss: 0.055864233523607254\n",
      "训练次数：330, Loss: 0.06751242280006409\n",
      "训练次数：335, Loss: 0.07271371781826019\n",
      "第 7 轮训练总体误差值：3.594907760620117\n",
      "**********开始本轮验证**********\n",
      "第 7 轮训练在整体验证集上的Loss: 1.8214191496372223\n",
      "allen_6.pth 模型已保存\n",
      "--------------------第8轮训练开始----------------------\n",
      "训练次数：340, Loss: 0.05831150710582733\n",
      "训练次数：345, Loss: 0.11916116625070572\n",
      "训练次数：350, Loss: 0.06160712614655495\n",
      "训练次数：355, Loss: 0.04779844358563423\n",
      "训练次数：360, Loss: 0.05775444582104683\n",
      "训练次数：365, Loss: 0.0627887025475502\n",
      "训练次数：370, Loss: 0.059097860008478165\n",
      "训练次数：375, Loss: 0.05336104333400726\n",
      "训练次数：380, Loss: 0.057258203625679016\n",
      "第 8 轮训练总体误差值：3.4395253658294678\n",
      "**********开始本轮验证**********\n",
      "第 8 轮训练在整体验证集上的Loss: 1.5548712015151978\n",
      "allen_7.pth 模型已保存\n",
      "--------------------第9轮训练开始----------------------\n",
      "训练次数：385, Loss: 0.11587470769882202\n",
      "训练次数：390, Loss: 0.05147148296236992\n",
      "训练次数：395, Loss: 0.06184379756450653\n",
      "训练次数：400, Loss: 0.05536441132426262\n",
      "训练次数：405, Loss: 0.05063188448548317\n",
      "训练次数：410, Loss: 0.06730504333972931\n",
      "训练次数：415, Loss: 0.04804890975356102\n",
      "训练次数：420, Loss: 0.09816055744886398\n",
      "训练次数：425, Loss: 0.0508309043943882\n",
      "训练次数：430, Loss: 0.20653466880321503\n",
      "第 9 轮训练总体误差值：3.5698769092559814\n",
      "**********开始本轮验证**********\n",
      "第 9 轮训练在整体验证集上的Loss: 1.3906575292348862\n",
      "allen_8.pth 模型已保存\n",
      "--------------------第10轮训练开始----------------------\n",
      "训练次数：435, Loss: 0.06618804484605789\n",
      "训练次数：440, Loss: 0.08507125824689865\n",
      "训练次数：445, Loss: 0.06588609516620636\n",
      "训练次数：450, Loss: 0.08636198937892914\n",
      "训练次数：455, Loss: 0.04434214159846306\n",
      "训练次数：460, Loss: 0.041272152215242386\n",
      "训练次数：465, Loss: 0.041135240346193314\n",
      "训练次数：470, Loss: 0.04077101871371269\n",
      "训练次数：475, Loss: 0.044147659093141556\n",
      "训练次数：480, Loss: 0.14604566991329193\n",
      "第 10 轮训练总体误差值：3.1161375045776367\n",
      "**********开始本轮验证**********\n",
      "第 10 轮训练在整体验证集上的Loss: 1.522206623107195\n",
      "allen_9.pth 模型已保存\n",
      "--------------------第11轮训练开始----------------------\n",
      "训练次数：485, Loss: 0.0572340190410614\n",
      "训练次数：490, Loss: 0.04402093216776848\n",
      "训练次数：495, Loss: 0.04337647184729576\n",
      "训练次数：500, Loss: 0.036529626697301865\n",
      "训练次数：505, Loss: 0.034189313650131226\n",
      "训练次数：510, Loss: 0.03840845078229904\n",
      "训练次数：515, Loss: 0.03484739363193512\n",
      "训练次数：520, Loss: 0.0322643518447876\n",
      "训练次数：525, Loss: 0.2577965557575226\n",
      "第 11 轮训练总体误差值：2.607252836227417\n",
      "**********开始本轮验证**********\n",
      "第 11 轮训练在整体验证集上的Loss: 1.0744544193148613\n",
      "allen_10.pth 模型已保存\n",
      "--------------------第12轮训练开始----------------------\n",
      "训练次数：530, Loss: 0.08675868064165115\n",
      "训练次数：535, Loss: 0.033231236040592194\n",
      "训练次数：540, Loss: 0.03008587658405304\n",
      "训练次数：545, Loss: 0.037863146513700485\n",
      "训练次数：550, Loss: 0.021267181262373924\n",
      "训练次数：555, Loss: 0.05418890714645386\n",
      "训练次数：560, Loss: 0.026405034586787224\n",
      "训练次数：565, Loss: 0.020310301333665848\n",
      "训练次数：570, Loss: 0.029981039464473724\n",
      "训练次数：575, Loss: 0.056074611842632294\n",
      "第 12 轮训练总体误差值：1.917588710784912\n",
      "**********开始本轮验证**********\n",
      "第 12 轮训练在整体验证集上的Loss: 1.396718855947256\n",
      "allen_11.pth 模型已保存\n",
      "--------------------第13轮训练开始----------------------\n",
      "训练次数：580, Loss: 0.05008630082011223\n",
      "训练次数：585, Loss: 0.06242896243929863\n",
      "训练次数：590, Loss: 0.03392055258154869\n",
      "训练次数：595, Loss: 0.02551589533686638\n",
      "训练次数：600, Loss: 0.015754632651805878\n",
      "训练次数：605, Loss: 0.028379574418067932\n",
      "训练次数：610, Loss: 0.029407665133476257\n",
      "训练次数：615, Loss: 0.01570555567741394\n",
      "训练次数：620, Loss: 0.021112656220793724\n",
      "第 13 轮训练总体误差值：1.8105806112289429\n",
      "**********开始本轮验证**********\n",
      "第 13 轮训练在整体验证集上的Loss: 0.8263251110911369\n",
      "allen_12.pth 模型已保存\n",
      "--------------------第14轮训练开始----------------------\n",
      "训练次数：625, Loss: 0.0663226842880249\n",
      "训练次数：630, Loss: 0.018419796600937843\n",
      "训练次数：635, Loss: 0.021601824089884758\n",
      "训练次数：640, Loss: 0.01834653690457344\n",
      "训练次数：645, Loss: 0.016125520691275597\n",
      "训练次数：650, Loss: 0.022197136655449867\n",
      "训练次数：655, Loss: 0.016329491510987282\n",
      "训练次数：660, Loss: 0.049990128725767136\n",
      "训练次数：665, Loss: 0.014586332254111767\n",
      "训练次数：670, Loss: 0.04169856756925583\n",
      "第 14 轮训练总体误差值：1.3091607093811035\n",
      "**********开始本轮验证**********\n",
      "第 14 轮训练在整体验证集上的Loss: 0.6583842653781176\n",
      "allen_13.pth 模型已保存\n",
      "--------------------第15轮训练开始----------------------\n",
      "训练次数：675, Loss: 0.021797824651002884\n",
      "训练次数：680, Loss: 0.023439208045601845\n",
      "训练次数：685, Loss: 0.01867137849330902\n",
      "训练次数：690, Loss: 0.04313911125063896\n",
      "训练次数：695, Loss: 0.012987378053367138\n",
      "训练次数：700, Loss: 0.011165847070515156\n",
      "训练次数：705, Loss: 0.01613965816795826\n",
      "训练次数：710, Loss: 0.01167799811810255\n",
      "训练次数：715, Loss: 0.015441058203577995\n",
      "训练次数：720, Loss: 0.025142552331089973\n",
      "第 15 轮训练总体误差值：1.0301296710968018\n",
      "**********开始本轮验证**********\n",
      "第 15 轮训练在整体验证集上的Loss: 0.6916727367788553\n",
      "allen_14.pth 模型已保存\n",
      "--------------------第16轮训练开始----------------------\n",
      "训练次数：725, Loss: 0.011180003173649311\n",
      "训练次数：730, Loss: 0.011697615496814251\n",
      "训练次数：735, Loss: 0.012868741527199745\n",
      "训练次数：740, Loss: 0.009561649523675442\n",
      "训练次数：745, Loss: 0.012491480447351933\n",
      "训练次数：750, Loss: 0.01727198250591755\n",
      "训练次数：755, Loss: 0.011777139268815517\n",
      "训练次数：760, Loss: 0.01702343486249447\n",
      "训练次数：765, Loss: 0.11555764824151993\n",
      "第 16 轮训练总体误差值：0.9010079503059387\n",
      "**********开始本轮验证**********\n",
      "第 16 轮训练在整体验证集上的Loss: 0.5413497313857079\n",
      "allen_15.pth 模型已保存\n",
      "--------------------第17轮训练开始----------------------\n",
      "训练次数：770, Loss: 0.048398055136203766\n",
      "训练次数：775, Loss: 0.013311874121427536\n",
      "训练次数：780, Loss: 0.01662006415426731\n",
      "训练次数：785, Loss: 0.013236696831882\n",
      "训练次数：790, Loss: 0.009388177655637264\n",
      "训练次数：795, Loss: 0.031572338193655014\n",
      "训练次数：800, Loss: 0.0143783800303936\n",
      "训练次数：805, Loss: 0.007152250502258539\n",
      "训练次数：810, Loss: 0.007287307642400265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：815, Loss: 0.011733049526810646\n",
      "第 17 轮训练总体误差值：0.8505866527557373\n",
      "**********开始本轮验证**********\n",
      "第 17 轮训练在整体验证集上的Loss: 0.7912035509943962\n",
      "allen_16.pth 模型已保存\n",
      "--------------------第18轮训练开始----------------------\n",
      "训练次数：820, Loss: 0.018170058727264404\n",
      "训练次数：825, Loss: 0.037267766892910004\n",
      "训练次数：830, Loss: 0.01200341247022152\n",
      "训练次数：835, Loss: 0.006323696114122868\n",
      "训练次数：840, Loss: 0.007182691246271133\n",
      "训练次数：845, Loss: 0.004819205030798912\n",
      "训练次数：850, Loss: 0.010589214973151684\n",
      "训练次数：855, Loss: 0.005888150539249182\n",
      "训练次数：860, Loss: 0.006298688240349293\n",
      "第 18 轮训练总体误差值：0.7295918464660645\n",
      "**********开始本轮验证**********\n",
      "第 18 轮训练在整体验证集上的Loss: 0.41877258382737637\n",
      "allen_17.pth 模型已保存\n",
      "--------------------第19轮训练开始----------------------\n",
      "训练次数：865, Loss: 0.021432969719171524\n",
      "训练次数：870, Loss: 0.008974054828286171\n",
      "训练次数：875, Loss: 0.008403602056205273\n",
      "训练次数：880, Loss: 0.010612580925226212\n",
      "训练次数：885, Loss: 0.00720725255087018\n",
      "训练次数：890, Loss: 0.009883301332592964\n",
      "训练次数：895, Loss: 0.009347504004836082\n",
      "训练次数：900, Loss: 0.03183582425117493\n",
      "训练次数：905, Loss: 0.004224209580570459\n",
      "训练次数：910, Loss: 0.05372264236211777\n",
      "第 19 轮训练总体误差值：0.7096637487411499\n",
      "**********开始本轮验证**********\n",
      "第 19 轮训练在整体验证集上的Loss: 0.47126742359250784\n",
      "allen_18.pth 模型已保存\n",
      "--------------------第20轮训练开始----------------------\n",
      "训练次数：915, Loss: 0.02964121475815773\n",
      "训练次数：920, Loss: 0.01561778225004673\n",
      "训练次数：925, Loss: 0.008279806934297085\n",
      "训练次数：930, Loss: 0.025201626121997833\n",
      "训练次数：935, Loss: 0.007681886199861765\n",
      "训练次数：940, Loss: 0.004514818079769611\n",
      "训练次数：945, Loss: 0.008332937024533749\n",
      "训练次数：950, Loss: 0.0038852915167808533\n",
      "训练次数：955, Loss: 0.00823043379932642\n",
      "训练次数：960, Loss: 0.026881735771894455\n",
      "第 20 轮训练总体误差值：0.7218064665794373\n",
      "**********开始本轮验证**********\n",
      "第 20 轮训练在整体验证集上的Loss: 0.48420214373618364\n",
      "allen_19.pth 模型已保存\n",
      "--------------------第21轮训练开始----------------------\n",
      "训练次数：965, Loss: 0.007830511778593063\n",
      "训练次数：970, Loss: 0.00709321815520525\n",
      "训练次数：975, Loss: 0.007405900862067938\n",
      "训练次数：980, Loss: 0.003946490120142698\n",
      "训练次数：985, Loss: 0.0064218598417937756\n",
      "训练次数：990, Loss: 0.012580124661326408\n",
      "训练次数：995, Loss: 0.0076374453492462635\n",
      "训练次数：1000, Loss: 0.00959346629679203\n",
      "训练次数：1005, Loss: 0.07401668280363083\n",
      "第 21 轮训练总体误差值：0.5225570201873779\n",
      "**********开始本轮验证**********\n",
      "第 21 轮训练在整体验证集上的Loss: 0.4587241290137172\n",
      "allen_20.pth 模型已保存\n",
      "--------------------第22轮训练开始----------------------\n",
      "训练次数：1010, Loss: 0.02377755008637905\n",
      "训练次数：1015, Loss: 0.005833581555634737\n",
      "训练次数：1020, Loss: 0.008086571469902992\n",
      "训练次数：1025, Loss: 0.00775936059653759\n",
      "训练次数：1030, Loss: 0.0027082308661192656\n",
      "训练次数：1035, Loss: 0.02127392403781414\n",
      "训练次数：1040, Loss: 0.01016913540661335\n",
      "训练次数：1045, Loss: 0.002619610633701086\n",
      "训练次数：1050, Loss: 0.00549996318295598\n",
      "训练次数：1055, Loss: 0.020514409989118576\n",
      "第 22 轮训练总体误差值：0.5294433832168579\n",
      "**********开始本轮验证**********\n",
      "第 22 轮训练在整体验证集上的Loss: 0.37265473790466785\n",
      "allen_21.pth 模型已保存\n",
      "--------------------第23轮训练开始----------------------\n",
      "训练次数：1060, Loss: 0.01660919189453125\n",
      "训练次数：1065, Loss: 0.023738287389278412\n",
      "训练次数：1070, Loss: 0.010033294558525085\n",
      "训练次数：1075, Loss: 0.0038262372836470604\n",
      "训练次数：1080, Loss: 0.003431465709581971\n",
      "训练次数：1085, Loss: 0.0021760500967502594\n",
      "训练次数：1090, Loss: 0.007324284873902798\n",
      "训练次数：1095, Loss: 0.002415345050394535\n",
      "训练次数：1100, Loss: 0.004152234643697739\n",
      "第 23 轮训练总体误差值：0.5355312824249268\n",
      "**********开始本轮验证**********\n",
      "第 23 轮训练在整体验证集上的Loss: 0.44310988299548626\n",
      "allen_22.pth 模型已保存\n",
      "--------------------第24轮训练开始----------------------\n",
      "训练次数：1105, Loss: 0.009434838779270649\n",
      "训练次数：1110, Loss: 0.0051764631643891335\n",
      "训练次数：1115, Loss: 0.0038895427715033293\n",
      "训练次数：1120, Loss: 0.0033731344155967236\n",
      "训练次数：1125, Loss: 0.003306721104308963\n",
      "训练次数：1130, Loss: 0.007411658763885498\n",
      "训练次数：1135, Loss: 0.00816400721669197\n",
      "训练次数：1140, Loss: 0.024266907945275307\n",
      "训练次数：1145, Loss: 0.0023915425408631563\n",
      "训练次数：1150, Loss: 0.007902855984866619\n",
      "第 24 轮训练总体误差值：0.36175230145454407\n",
      "**********开始本轮验证**********\n",
      "第 24 轮训练在整体验证集上的Loss: 0.3623359641060233\n",
      "allen_23.pth 模型已保存\n",
      "--------------------第25轮训练开始----------------------\n",
      "训练次数：1155, Loss: 0.008314083330333233\n",
      "训练次数：1160, Loss: 0.010048781521618366\n",
      "训练次数：1165, Loss: 0.0038972359616309404\n",
      "训练次数：1170, Loss: 0.018198542296886444\n",
      "训练次数：1175, Loss: 0.004263333976268768\n",
      "训练次数：1180, Loss: 0.0019236011430621147\n",
      "训练次数：1185, Loss: 0.006610232871025801\n",
      "训练次数：1190, Loss: 0.0012949886731803417\n",
      "训练次数：1195, Loss: 0.004278778564184904\n",
      "训练次数：1200, Loss: 0.004279431886970997\n",
      "第 25 轮训练总体误差值：0.3697974979877472\n",
      "**********开始本轮验证**********\n",
      "第 25 轮训练在整体验证集上的Loss: 0.33521435502916574\n",
      "allen_24.pth 模型已保存\n",
      "--------------------第26轮训练开始----------------------\n",
      "训练次数：1205, Loss: 0.0026864157989621162\n",
      "训练次数：1210, Loss: 0.0037103435024619102\n",
      "训练次数：1215, Loss: 0.0023458281066268682\n",
      "训练次数：1220, Loss: 0.002228453988209367\n",
      "训练次数：1225, Loss: 0.003490741830319166\n",
      "训练次数：1230, Loss: 0.008126887492835522\n",
      "训练次数：1235, Loss: 0.005809697322547436\n",
      "训练次数：1240, Loss: 0.0037337064277380705\n",
      "训练次数：1245, Loss: 0.04789133369922638\n",
      "第 26 轮训练总体误差值：0.31612101197242737\n",
      "**********开始本轮验证**********\n",
      "第 26 轮训练在整体验证集上的Loss: 0.4633998339995742\n",
      "allen_25.pth 模型已保存\n",
      "--------------------第27轮训练开始----------------------\n",
      "训练次数：1250, Loss: 0.007554096635431051\n",
      "训练次数：1255, Loss: 0.005647126119583845\n",
      "训练次数：1260, Loss: 0.0047439164482057095\n",
      "训练次数：1265, Loss: 0.006927101872861385\n",
      "训练次数：1270, Loss: 0.002209492027759552\n",
      "训练次数：1275, Loss: 0.01517072319984436\n",
      "训练次数：1280, Loss: 0.0045510102063417435\n",
      "训练次数：1285, Loss: 0.0012623303337022662\n",
      "训练次数：1290, Loss: 0.0027401188854128122\n",
      "训练次数：1295, Loss: 0.004891580902040005\n",
      "第 27 轮训练总体误差值：0.3030011057853699\n",
      "**********开始本轮验证**********\n",
      "第 27 轮训练在整体验证集上的Loss: 0.4785528602078557\n",
      "allen_26.pth 模型已保存\n",
      "--------------------第28轮训练开始----------------------\n",
      "训练次数：1300, Loss: 0.0074423872865736485\n",
      "训练次数：1305, Loss: 0.023193616420030594\n",
      "训练次数：1310, Loss: 0.009225055575370789\n",
      "训练次数：1315, Loss: 0.0031573029700666666\n",
      "训练次数：1320, Loss: 0.00352102960459888\n",
      "训练次数：1325, Loss: 0.001363713527098298\n",
      "训练次数：1330, Loss: 0.00544050894677639\n",
      "训练次数：1335, Loss: 0.0018214413430541754\n",
      "训练次数：1340, Loss: 0.0029043303802609444\n",
      "第 28 轮训练总体误差值：0.3867994248867035\n",
      "**********开始本轮验证**********\n",
      "第 28 轮训练在整体验证集上的Loss: 0.5708275130018592\n",
      "allen_27.pth 模型已保存\n",
      "--------------------第29轮训练开始----------------------\n",
      "训练次数：1345, Loss: 0.019047124311327934\n",
      "训练次数：1350, Loss: 0.00403559161350131\n",
      "训练次数：1355, Loss: 0.026626961305737495\n",
      "训练次数：1360, Loss: 0.005874766036868095\n",
      "训练次数：1365, Loss: 0.002857308369129896\n",
      "训练次数：1370, Loss: 0.0068693263456225395\n",
      "训练次数：1375, Loss: 0.004856941290199757\n",
      "训练次数：1380, Loss: 0.021050365641713142\n",
      "训练次数：1385, Loss: 0.001385473064146936\n",
      "训练次数：1390, Loss: 0.005387351848185062\n",
      "第 29 轮训练总体误差值：0.4170696437358856\n",
      "**********开始本轮验证**********\n",
      "第 29 轮训练在整体验证集上的Loss: 0.43605404533445835\n",
      "allen_28.pth 模型已保存\n",
      "--------------------第30轮训练开始----------------------\n",
      "训练次数：1395, Loss: 0.0028322346042841673\n",
      "训练次数：1400, Loss: 0.004585070535540581\n",
      "训练次数：1405, Loss: 0.005861041136085987\n",
      "训练次数：1410, Loss: 0.016910631209611893\n",
      "训练次数：1415, Loss: 0.003067850135266781\n",
      "训练次数：1420, Loss: 0.0015016855904832482\n",
      "训练次数：1425, Loss: 0.005928835831582546\n",
      "训练次数：1430, Loss: 0.0022370812948793173\n",
      "训练次数：1435, Loss: 0.0034784795716404915\n",
      "训练次数：1440, Loss: 0.0027651351410895586\n",
      "第 30 轮训练总体误差值：0.2773017883300781\n",
      "**********开始本轮验证**********\n",
      "第 30 轮训练在整体验证集上的Loss: 0.5071176746860147\n",
      "allen_29.pth 模型已保存\n",
      "--------------------第31轮训练开始----------------------\n",
      "训练次数：1445, Loss: 0.0025448398664593697\n",
      "训练次数：1450, Loss: 0.0036952784284949303\n",
      "训练次数：1455, Loss: 0.0026056619826704264\n",
      "训练次数：1460, Loss: 0.001232779468409717\n",
      "训练次数：1465, Loss: 0.0035803879145532846\n",
      "训练次数：1470, Loss: 0.00865139439702034\n",
      "训练次数：1475, Loss: 0.005655832123011351\n",
      "训练次数：1480, Loss: 0.0036217670422047377\n",
      "训练次数：1485, Loss: 0.04098943620920181\n",
      "第 31 轮训练总体误差值：0.3032745122909546\n",
      "**********开始本轮验证**********\n",
      "第 31 轮训练在整体验证集上的Loss: 0.6091482723131776\n",
      "allen_30.pth 模型已保存\n",
      "--------------------第32轮训练开始----------------------\n",
      "训练次数：1490, Loss: 0.00792664848268032\n",
      "训练次数：1495, Loss: 0.004202373791486025\n",
      "训练次数：1500, Loss: 0.004754405003041029\n",
      "训练次数：1505, Loss: 0.005740735214203596\n",
      "训练次数：1510, Loss: 0.0013842080952599645\n",
      "训练次数：1515, Loss: 0.013067045249044895\n",
      "训练次数：1520, Loss: 0.0042122439481318\n",
      "训练次数：1525, Loss: 0.0010600211098790169\n",
      "训练次数：1530, Loss: 0.004011649638414383\n",
      "训练次数：1535, Loss: 0.005796263925731182\n",
      "第 32 轮训练总体误差值：0.2806437909603119\n",
      "**********开始本轮验证**********\n",
      "第 32 轮训练在整体验证集上的Loss: 0.5692231561988592\n",
      "allen_31.pth 模型已保存\n",
      "--------------------第33轮训练开始----------------------\n",
      "训练次数：1540, Loss: 0.0054303985089063644\n",
      "训练次数：1545, Loss: 0.01951812021434307\n",
      "训练次数：1550, Loss: 0.010130754671990871\n",
      "训练次数：1555, Loss: 0.002982107689604163\n",
      "训练次数：1560, Loss: 0.0021499888971447945\n",
      "训练次数：1565, Loss: 0.0010583271505311131\n",
      "训练次数：1570, Loss: 0.004671347793191671\n",
      "训练次数：1575, Loss: 0.0017542799469083548\n",
      "训练次数：1580, Loss: 0.0031948985997587442\n",
      "第 33 轮训练总体误差值：0.3470267653465271\n",
      "**********开始本轮验证**********\n",
      "第 33 轮训练在整体验证集上的Loss: 0.6295027509331703\n",
      "allen_32.pth 模型已保存\n",
      "--------------------第34轮训练开始----------------------\n",
      "训练次数：1585, Loss: 0.023189561441540718\n",
      "训练次数：1590, Loss: 0.003935618791729212\n",
      "训练次数：1595, Loss: 0.00853454228490591\n",
      "训练次数：1600, Loss: 0.004854717291891575\n",
      "训练次数：1605, Loss: 0.0035716264974325895\n",
      "训练次数：1610, Loss: 0.006668975111097097\n",
      "训练次数：1615, Loss: 0.006963073275983334\n",
      "训练次数：1620, Loss: 0.018526077270507812\n",
      "训练次数：1625, Loss: 0.0011010280577465892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：1630, Loss: 0.01704287901520729\n",
      "第 34 轮训练总体误差值：0.36942440271377563\n",
      "**********开始本轮验证**********\n",
      "第 34 轮训练在整体验证集上的Loss: 0.7179521396756172\n",
      "allen_33.pth 模型已保存\n",
      "--------------------第35轮训练开始----------------------\n",
      "训练次数：1635, Loss: 0.009416243992745876\n",
      "训练次数：1640, Loss: 0.00815724115818739\n",
      "训练次数：1645, Loss: 0.004334221128374338\n",
      "训练次数：1650, Loss: 0.03329191729426384\n",
      "训练次数：1655, Loss: 0.0017118289833888412\n",
      "训练次数：1660, Loss: 0.004519856534898281\n",
      "训练次数：1665, Loss: 0.0034434909466654062\n",
      "训练次数：1670, Loss: 0.0021668679546564817\n",
      "训练次数：1675, Loss: 0.003886591177433729\n",
      "训练次数：1680, Loss: 0.012974673882126808\n",
      "第 35 轮训练总体误差值：0.42959079146385193\n",
      "**********开始本轮验证**********\n",
      "第 35 轮训练在整体验证集上的Loss: 0.6212702328339219\n",
      "allen_34.pth 模型已保存\n",
      "--------------------第36轮训练开始----------------------\n",
      "训练次数：1685, Loss: 0.0059461393393576145\n",
      "训练次数：1690, Loss: 0.003467558417469263\n",
      "训练次数：1695, Loss: 0.009764107875525951\n",
      "训练次数：1700, Loss: 0.0017703692428767681\n",
      "训练次数：1705, Loss: 0.006958042737096548\n",
      "训练次数：1710, Loss: 0.004087628796696663\n",
      "训练次数：1715, Loss: 0.005962013266980648\n",
      "训练次数：1720, Loss: 0.0016305146273225546\n",
      "训练次数：1725, Loss: 0.041845183819532394\n",
      "第 36 轮训练总体误差值：0.3795485198497772\n",
      "**********开始本轮验证**********\n",
      "第 36 轮训练在整体验证集上的Loss: 0.8822796633467078\n",
      "allen_35.pth 模型已保存\n",
      "--------------------第37轮训练开始----------------------\n",
      "训练次数：1730, Loss: 0.044807318598032\n",
      "训练次数：1735, Loss: 0.00806360226124525\n",
      "训练次数：1740, Loss: 0.008795002475380898\n",
      "训练次数：1745, Loss: 0.0036736081819981337\n",
      "训练次数：1750, Loss: 0.0018486632034182549\n",
      "训练次数：1755, Loss: 0.013450877740979195\n",
      "训练次数：1760, Loss: 0.0035458041820675135\n",
      "训练次数：1765, Loss: 0.0023101100232452154\n",
      "训练次数：1770, Loss: 0.0033806893043220043\n",
      "训练次数：1775, Loss: 0.006169765256345272\n",
      "第 37 轮训练总体误差值：0.5064222812652588\n",
      "**********开始本轮验证**********\n",
      "第 37 轮训练在整体验证集上的Loss: 0.6720249569043517\n",
      "allen_36.pth 模型已保存\n",
      "--------------------第38轮训练开始----------------------\n",
      "训练次数：1780, Loss: 0.009350741282105446\n",
      "训练次数：1785, Loss: 0.017642874270677567\n",
      "训练次数：1790, Loss: 0.008188137784600258\n",
      "训练次数：1795, Loss: 0.0012130684917792678\n",
      "训练次数：1800, Loss: 0.0028472666162997484\n",
      "训练次数：1805, Loss: 0.0018846257589757442\n",
      "训练次数：1810, Loss: 0.005580023396760225\n",
      "训练次数：1815, Loss: 0.002511457307264209\n",
      "训练次数：1820, Loss: 0.003275893861427903\n",
      "第 38 轮训练总体误差值：0.36817941069602966\n",
      "**********开始本轮验证**********\n",
      "第 38 轮训练在整体验证集上的Loss: 0.5184915130957961\n",
      "allen_37.pth 模型已保存\n",
      "--------------------第39轮训练开始----------------------\n",
      "训练次数：1825, Loss: 0.01440981961786747\n",
      "训练次数：1830, Loss: 0.004732379224151373\n",
      "训练次数：1835, Loss: 0.002814614912495017\n",
      "训练次数：1840, Loss: 0.002512312727048993\n",
      "训练次数：1845, Loss: 0.002368899527937174\n",
      "训练次数：1850, Loss: 0.005437218584120274\n",
      "训练次数：1855, Loss: 0.004856505431234837\n",
      "训练次数：1860, Loss: 0.017075873911380768\n",
      "训练次数：1865, Loss: 0.0013179226079955697\n",
      "训练次数：1870, Loss: 0.007235161028802395\n",
      "第 39 轮训练总体误差值：0.28172802925109863\n",
      "**********开始本轮验证**********\n",
      "第 39 轮训练在整体验证集上的Loss: 0.4262418746948242\n",
      "allen_38.pth 模型已保存\n",
      "--------------------第40轮训练开始----------------------\n",
      "训练次数：1875, Loss: 0.00208735722117126\n",
      "训练次数：1880, Loss: 0.005868908483535051\n",
      "训练次数：1885, Loss: 0.0034681949764490128\n",
      "训练次数：1890, Loss: 0.0147048095241189\n",
      "训练次数：1895, Loss: 0.0038570782635360956\n",
      "训练次数：1900, Loss: 0.002090752823278308\n",
      "训练次数：1905, Loss: 0.0036222052294760942\n",
      "训练次数：1910, Loss: 0.001121179899200797\n",
      "训练次数：1915, Loss: 0.002366810105741024\n",
      "训练次数：1920, Loss: 0.0033246027305722237\n",
      "第 40 轮训练总体误差值：0.23603004217147827\n",
      "**********开始本轮验证**********\n",
      "第 40 轮训练在整体验证集上的Loss: 0.6090334327891469\n",
      "allen_39.pth 模型已保存\n",
      "--------------------第41轮训练开始----------------------\n",
      "训练次数：1925, Loss: 0.004935217089951038\n",
      "训练次数：1930, Loss: 0.008455809205770493\n",
      "训练次数：1935, Loss: 0.0029722487088292837\n",
      "训练次数：1940, Loss: 0.0025957224424928427\n",
      "训练次数：1945, Loss: 0.004485924728214741\n",
      "训练次数：1950, Loss: 0.0024621286429464817\n",
      "训练次数：1955, Loss: 0.005066021345555782\n",
      "训练次数：1960, Loss: 0.0012534878915175796\n",
      "训练次数：1965, Loss: 0.03063301183283329\n",
      "第 41 轮训练总体误差值：0.32718080282211304\n",
      "**********开始本轮验证**********\n",
      "第 41 轮训练在整体验证集上的Loss: 0.477791678160429\n",
      "allen_40.pth 模型已保存\n",
      "--------------------第42轮训练开始----------------------\n",
      "训练次数：1970, Loss: 0.02414427511394024\n",
      "训练次数：1975, Loss: 0.003359545022249222\n",
      "训练次数：1980, Loss: 0.004930255003273487\n",
      "训练次数：1985, Loss: 0.0041668107733130455\n",
      "训练次数：1990, Loss: 0.0037310051266103983\n",
      "训练次数：1995, Loss: 0.012333827093243599\n",
      "训练次数：2000, Loss: 0.003409401746466756\n",
      "训练次数：2005, Loss: 0.0020928867161273956\n",
      "训练次数：2010, Loss: 0.0017928531160578132\n",
      "训练次数：2015, Loss: 0.016111455857753754\n",
      "第 42 轮训练总体误差值：0.3553743064403534\n",
      "**********开始本轮验证**********\n",
      "第 42 轮训练在整体验证集上的Loss: 0.4144707676023245\n",
      "allen_41.pth 模型已保存\n",
      "--------------------第43轮训练开始----------------------\n",
      "训练次数：2020, Loss: 0.008457721211016178\n",
      "训练次数：2025, Loss: 0.01618846319615841\n",
      "训练次数：2030, Loss: 0.007688071578741074\n",
      "训练次数：2035, Loss: 0.0009370545158162713\n",
      "训练次数：2040, Loss: 0.0025921063497662544\n",
      "训练次数：2045, Loss: 0.002084127627313137\n",
      "训练次数：2050, Loss: 0.003826432628557086\n",
      "训练次数：2055, Loss: 0.002044211607426405\n",
      "训练次数：2060, Loss: 0.0037921229377388954\n",
      "第 43 轮训练总体误差值：0.3266163468360901\n",
      "**********开始本轮验证**********\n",
      "第 43 轮训练在整体验证集上的Loss: 0.5121895205229521\n",
      "allen_42.pth 模型已保存\n",
      "--------------------第44轮训练开始----------------------\n",
      "训练次数：2065, Loss: 0.027939606457948685\n",
      "训练次数：2070, Loss: 0.003131255740299821\n",
      "训练次数：2075, Loss: 0.0024562596809118986\n",
      "训练次数：2080, Loss: 0.0034782872535288334\n",
      "训练次数：2085, Loss: 0.0024969028308987617\n",
      "训练次数：2090, Loss: 0.004126114305108786\n",
      "训练次数：2095, Loss: 0.002569809090346098\n",
      "训练次数：2100, Loss: 0.016717329621315002\n",
      "训练次数：2105, Loss: 0.002976486226543784\n",
      "训练次数：2110, Loss: 0.011946515180170536\n",
      "第 44 轮训练总体误差值：0.30335861444473267\n",
      "**********开始本轮验证**********\n",
      "第 44 轮训练在整体验证集上的Loss: 0.4780617021024227\n",
      "allen_43.pth 模型已保存\n",
      "--------------------第45轮训练开始----------------------\n",
      "训练次数：2115, Loss: 0.02475774846971035\n",
      "训练次数：2120, Loss: 0.0062205432914197445\n",
      "训练次数：2125, Loss: 0.00551321916282177\n",
      "训练次数：2130, Loss: 0.015547757968306541\n",
      "训练次数：2135, Loss: 0.0035419438499957323\n",
      "训练次数：2140, Loss: 0.0038031605072319508\n",
      "训练次数：2145, Loss: 0.005330804269760847\n",
      "训练次数：2150, Loss: 0.0006919298903085291\n",
      "训练次数：2155, Loss: 0.0034148232080042362\n",
      "训练次数：2160, Loss: 0.014118492603302002\n",
      "第 45 轮训练总体误差值：0.44984740018844604\n",
      "**********开始本轮验证**********\n",
      "第 45 轮训练在整体验证集上的Loss: 0.4544593561440706\n",
      "allen_44.pth 模型已保存\n",
      "--------------------第46轮训练开始----------------------\n",
      "训练次数：2165, Loss: 0.004418309312313795\n",
      "训练次数：2170, Loss: 0.0028411729726940393\n",
      "训练次数：2175, Loss: 0.0035887425765395164\n",
      "训练次数：2180, Loss: 0.0014358354965224862\n",
      "训练次数：2185, Loss: 0.004021681845188141\n",
      "训练次数：2190, Loss: 0.002184282522648573\n",
      "训练次数：2195, Loss: 0.003943818621337414\n",
      "训练次数：2200, Loss: 0.002031489508226514\n",
      "训练次数：2205, Loss: 0.04276763275265694\n",
      "第 46 轮训练总体误差值：0.28549644351005554\n",
      "**********开始本轮验证**********\n",
      "第 46 轮训练在整体验证集上的Loss: 0.6104459082707763\n",
      "allen_45.pth 模型已保存\n",
      "--------------------第47轮训练开始----------------------\n",
      "训练次数：2210, Loss: 0.02842741459608078\n",
      "训练次数：2215, Loss: 0.01545623131096363\n",
      "训练次数：2220, Loss: 0.014041256159543991\n",
      "训练次数：2225, Loss: 0.012275799177587032\n",
      "训练次数：2230, Loss: 0.002529584802687168\n",
      "训练次数：2235, Loss: 0.014036581851541996\n",
      "训练次数：2240, Loss: 0.002638663398101926\n",
      "训练次数：2245, Loss: 0.002188796875998378\n",
      "训练次数：2250, Loss: 0.002567138522863388\n",
      "训练次数：2255, Loss: 0.010293221101164818\n",
      "第 47 轮训练总体误差值：0.4842885136604309\n",
      "**********开始本轮验证**********\n",
      "第 47 轮训练在整体验证集上的Loss: 0.5111906602978706\n",
      "allen_46.pth 模型已保存\n",
      "--------------------第48轮训练开始----------------------\n",
      "训练次数：2260, Loss: 0.021324867382645607\n",
      "训练次数：2265, Loss: 0.015981175005435944\n",
      "训练次数：2270, Loss: 0.01886329986155033\n",
      "训练次数：2275, Loss: 0.0022657227236777544\n",
      "训练次数：2280, Loss: 0.003119447734206915\n",
      "训练次数：2285, Loss: 0.002226993441581726\n",
      "训练次数：2290, Loss: 0.0036238422617316246\n",
      "训练次数：2295, Loss: 0.0025849295780062675\n",
      "训练次数：2300, Loss: 0.0025376256089657545\n",
      "第 48 轮训练总体误差值：0.44639164209365845\n",
      "**********开始本轮验证**********\n",
      "第 48 轮训练在整体验证集上的Loss: 0.5129428878426552\n",
      "allen_47.pth 模型已保存\n",
      "--------------------第49轮训练开始----------------------\n",
      "训练次数：2305, Loss: 0.016085712239146233\n",
      "训练次数：2310, Loss: 0.004663809202611446\n",
      "训练次数：2315, Loss: 0.007196704391390085\n",
      "训练次数：2320, Loss: 0.0026016756892204285\n",
      "训练次数：2325, Loss: 0.002474526409059763\n",
      "训练次数：2330, Loss: 0.0033514793030917645\n",
      "训练次数：2335, Loss: 0.004080756567418575\n",
      "训练次数：2340, Loss: 0.01457025483250618\n",
      "训练次数：2345, Loss: 0.0008054968202486634\n",
      "训练次数：2350, Loss: 0.00785504188388586\n",
      "第 49 轮训练总体误差值：0.2773565649986267\n",
      "**********开始本轮验证**********\n",
      "第 49 轮训练在整体验证集上的Loss: 0.41872232407331467\n",
      "allen_48.pth 模型已保存\n",
      "--------------------第50轮训练开始----------------------\n",
      "训练次数：2355, Loss: 0.007402838207781315\n",
      "训练次数：2360, Loss: 0.007756182458251715\n",
      "训练次数：2365, Loss: 0.003483874723315239\n",
      "训练次数：2370, Loss: 0.01266382820904255\n",
      "训练次数：2375, Loss: 0.0037458864971995354\n",
      "训练次数：2380, Loss: 0.0016576095949858427\n",
      "训练次数：2385, Loss: 0.003970202058553696\n",
      "训练次数：2390, Loss: 0.0008105621091090143\n",
      "训练次数：2395, Loss: 0.002561025321483612\n",
      "训练次数：2400, Loss: 0.002908096881583333\n",
      "第 50 轮训练总体误差值：0.24352353811264038\n",
      "**********开始本轮验证**********\n",
      "第 50 轮训练在整体验证集上的Loss: 0.6351077202707529\n",
      "allen_49.pth 模型已保存\n",
      "--------------------第51轮训练开始----------------------\n",
      "训练次数：2405, Loss: 0.009214832447469234\n",
      "训练次数：2410, Loss: 0.010009841993451118\n",
      "训练次数：2415, Loss: 0.00588091928511858\n",
      "训练次数：2420, Loss: 0.0023037376813590527\n",
      "训练次数：2425, Loss: 0.006735827773809433\n",
      "训练次数：2430, Loss: 0.004177523776888847\n",
      "训练次数：2435, Loss: 0.006892767269164324\n",
      "训练次数：2440, Loss: 0.0025744764134287834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：2445, Loss: 0.017357684671878815\n",
      "第 51 轮训练总体误差值：0.35819756984710693\n",
      "**********开始本轮验证**********\n",
      "第 51 轮训练在整体验证集上的Loss: 0.42428915575146675\n",
      "allen_50.pth 模型已保存\n",
      "--------------------第52轮训练开始----------------------\n",
      "训练次数：2450, Loss: 0.009153202176094055\n",
      "训练次数：2455, Loss: 0.0029741949401795864\n",
      "训练次数：2460, Loss: 0.008088314905762672\n",
      "训练次数：2465, Loss: 0.0024775643832981586\n",
      "训练次数：2470, Loss: 0.0014346876414492726\n",
      "训练次数：2475, Loss: 0.01210634782910347\n",
      "训练次数：2480, Loss: 0.002701160265132785\n",
      "训练次数：2485, Loss: 0.0009757201187312603\n",
      "训练次数：2490, Loss: 0.001629295409657061\n",
      "训练次数：2495, Loss: 0.004117803182452917\n",
      "第 52 轮训练总体误差值：0.21581166982650757\n",
      "**********开始本轮验证**********\n",
      "第 52 轮训练在整体验证集上的Loss: 0.39389007072895765\n",
      "allen_51.pth 模型已保存\n",
      "--------------------第53轮训练开始----------------------\n",
      "训练次数：2500, Loss: 0.007336627691984177\n",
      "训练次数：2505, Loss: 0.01083285640925169\n",
      "训练次数：2510, Loss: 0.009064970538020134\n",
      "训练次数：2515, Loss: 0.0016372615937143564\n",
      "训练次数：2520, Loss: 0.0036112891975790262\n",
      "训练次数：2525, Loss: 0.001415278296917677\n",
      "训练次数：2530, Loss: 0.006312813144177198\n",
      "训练次数：2535, Loss: 0.0019317660480737686\n",
      "训练次数：2540, Loss: 0.006538784131407738\n",
      "第 53 轮训练总体误差值：0.32429075241088867\n",
      "**********开始本轮验证**********\n",
      "第 53 轮训练在整体验证集上的Loss: 0.5893700495362282\n",
      "allen_52.pth 模型已保存\n",
      "--------------------第54轮训练开始----------------------\n",
      "训练次数：2545, Loss: 0.007918997667729855\n",
      "训练次数：2550, Loss: 0.004372124560177326\n",
      "训练次数：2555, Loss: 0.0006632112199440598\n",
      "训练次数：2560, Loss: 0.003444325877353549\n",
      "训练次数：2565, Loss: 0.002146058948710561\n",
      "训练次数：2570, Loss: 0.00502149760723114\n",
      "训练次数：2575, Loss: 0.0017540943808853626\n",
      "训练次数：2580, Loss: 0.015666967257857323\n",
      "训练次数：2585, Loss: 0.0008268508827313781\n",
      "训练次数：2590, Loss: 0.009618095122277737\n",
      "第 54 轮训练总体误差值：0.22374190390110016\n",
      "**********开始本轮验证**********\n",
      "第 54 轮训练在整体验证集上的Loss: 0.3217311780899763\n",
      "allen_53.pth 模型已保存\n",
      "--------------------第55轮训练开始----------------------\n",
      "训练次数：2595, Loss: 0.010648866184055805\n",
      "训练次数：2600, Loss: 0.005423638038337231\n",
      "训练次数：2605, Loss: 0.00474162632599473\n",
      "训练次数：2610, Loss: 0.013657500967383385\n",
      "训练次数：2615, Loss: 0.0022936922032386065\n",
      "训练次数：2620, Loss: 0.002013002522289753\n",
      "训练次数：2625, Loss: 0.0029863945674151182\n",
      "训练次数：2630, Loss: 0.0011280938051640987\n",
      "训练次数：2635, Loss: 0.0027844023425132036\n",
      "训练次数：2640, Loss: 0.010043608024716377\n",
      "第 55 轮训练总体误差值：0.2766623795032501\n",
      "**********开始本轮验证**********\n",
      "第 55 轮训练在整体验证集上的Loss: 0.5693561471998692\n",
      "allen_54.pth 模型已保存\n",
      "--------------------第56轮训练开始----------------------\n",
      "训练次数：2645, Loss: 0.005303157959133387\n",
      "训练次数：2650, Loss: 0.006401925813406706\n",
      "训练次数：2655, Loss: 0.00436810776591301\n",
      "训练次数：2660, Loss: 0.0004554421757347882\n",
      "训练次数：2665, Loss: 0.0049844044260680676\n",
      "训练次数：2670, Loss: 0.002613055519759655\n",
      "训练次数：2675, Loss: 0.003507977817207575\n",
      "训练次数：2680, Loss: 0.0015116480644792318\n",
      "训练次数：2685, Loss: 0.029247676953673363\n",
      "第 56 轮训练总体误差值：0.28420621156692505\n",
      "**********开始本轮验证**********\n",
      "第 56 轮训练在整体验证集上的Loss: 0.3919493816792965\n",
      "allen_55.pth 模型已保存\n",
      "--------------------第57轮训练开始----------------------\n",
      "训练次数：2690, Loss: 0.016263138502836227\n",
      "训练次数：2695, Loss: 0.009844995103776455\n",
      "训练次数：2700, Loss: 0.003957315813750029\n",
      "训练次数：2705, Loss: 0.0075272442772984505\n",
      "训练次数：2710, Loss: 0.0016005111392587423\n",
      "训练次数：2715, Loss: 0.009671664796769619\n",
      "训练次数：2720, Loss: 0.0020621754229068756\n",
      "训练次数：2725, Loss: 0.0007106647244654596\n",
      "训练次数：2730, Loss: 0.0015059207798913121\n",
      "训练次数：2735, Loss: 0.007914426736533642\n",
      "第 57 轮训练总体误差值：0.29732435941696167\n",
      "**********开始本轮验证**********\n",
      "第 57 轮训练在整体验证集上的Loss: 0.5132371941581368\n",
      "allen_56.pth 模型已保存\n",
      "--------------------第58轮训练开始----------------------\n",
      "训练次数：2740, Loss: 0.007346530444920063\n",
      "训练次数：2745, Loss: 0.012290185317397118\n",
      "训练次数：2750, Loss: 0.0018819952383637428\n",
      "训练次数：2755, Loss: 0.0012008543126285076\n",
      "训练次数：2760, Loss: 0.0011502697598189116\n",
      "训练次数：2765, Loss: 0.0020143960136920214\n",
      "训练次数：2770, Loss: 0.0020729638636112213\n",
      "训练次数：2775, Loss: 0.0007725682808086276\n",
      "训练次数：2780, Loss: 0.0013348979409784079\n",
      "第 58 轮训练总体误差值：0.22091469168663025\n",
      "**********开始本轮验证**********\n",
      "第 58 轮训练在整体验证集上的Loss: 0.3121550539508462\n",
      "allen_57.pth 模型已保存\n",
      "--------------------第59轮训练开始----------------------\n",
      "训练次数：2785, Loss: 0.009892076253890991\n",
      "训练次数：2790, Loss: 0.005047948565334082\n",
      "训练次数：2795, Loss: 0.0020776591263711452\n",
      "训练次数：2800, Loss: 0.002210059203207493\n",
      "训练次数：2805, Loss: 0.0015216023894026875\n",
      "训练次数：2810, Loss: 0.00604636874049902\n",
      "训练次数：2815, Loss: 0.0023257851134985685\n",
      "训练次数：2820, Loss: 0.012101763859391212\n",
      "训练次数：2825, Loss: 0.0006710108136758208\n",
      "训练次数：2830, Loss: 0.007209550589323044\n",
      "第 59 轮训练总体误差值：0.20720136165618896\n",
      "**********开始本轮验证**********\n",
      "第 59 轮训练在整体验证集上的Loss: 0.4144573174417019\n",
      "allen_58.pth 模型已保存\n",
      "--------------------第60轮训练开始----------------------\n",
      "训练次数：2835, Loss: 0.0044388058595359325\n",
      "训练次数：2840, Loss: 0.005962882656604052\n",
      "训练次数：2845, Loss: 0.0026558160316199064\n",
      "训练次数：2850, Loss: 0.009698327630758286\n",
      "训练次数：2855, Loss: 0.0025602367240935564\n",
      "训练次数：2860, Loss: 0.0007608023006469011\n",
      "训练次数：2865, Loss: 0.002434987109154463\n",
      "训练次数：2870, Loss: 0.0005472996272146702\n",
      "训练次数：2875, Loss: 0.0012216180330142379\n",
      "训练次数：2880, Loss: 0.003779882099479437\n",
      "第 60 轮训练总体误差值：0.19349047541618347\n",
      "**********开始本轮验证**********\n",
      "第 60 轮训练在整体验证集上的Loss: 0.3343113297596574\n",
      "allen_59.pth 模型已保存\n",
      "--------------------第61轮训练开始----------------------\n",
      "训练次数：2885, Loss: 0.002487979596480727\n",
      "训练次数：2890, Loss: 0.000910250237211585\n",
      "训练次数：2895, Loss: 0.0011575184762477875\n",
      "训练次数：2900, Loss: 0.0008047707960940897\n",
      "训练次数：2905, Loss: 0.0013681849231943488\n",
      "训练次数：2910, Loss: 0.0017341452185064554\n",
      "训练次数：2915, Loss: 0.0038420474156737328\n",
      "训练次数：2920, Loss: 0.0006554136634804308\n",
      "训练次数：2925, Loss: 0.016113510355353355\n",
      "第 61 轮训练总体误差值：0.14294937252998352\n",
      "**********开始本轮验证**********\n",
      "第 61 轮训练在整体验证集上的Loss: 0.40038188826292753\n",
      "allen_60.pth 模型已保存\n",
      "--------------------第62轮训练开始----------------------\n",
      "训练次数：2930, Loss: 0.014140603132545948\n",
      "训练次数：2935, Loss: 0.0026552961207926273\n",
      "训练次数：2940, Loss: 0.005269924644380808\n",
      "训练次数：2945, Loss: 0.0037411958910524845\n",
      "训练次数：2950, Loss: 0.001217179698869586\n",
      "训练次数：2955, Loss: 0.007415120489895344\n",
      "训练次数：2960, Loss: 0.002026478759944439\n",
      "训练次数：2965, Loss: 0.0005770926363766193\n",
      "训练次数：2970, Loss: 0.0011165490141138434\n",
      "训练次数：2975, Loss: 0.004853575490415096\n",
      "第 62 轮训练总体误差值：0.2060527801513672\n",
      "**********开始本轮验证**********\n",
      "第 62 轮训练在整体验证集上的Loss: 0.3926736684516072\n",
      "allen_61.pth 模型已保存\n",
      "--------------------第63轮训练开始----------------------\n",
      "训练次数：2980, Loss: 0.001496910466812551\n",
      "训练次数：2985, Loss: 0.010181481949985027\n",
      "训练次数：2990, Loss: 0.0021859107073396444\n",
      "训练次数：2995, Loss: 0.000843556656036526\n",
      "训练次数：3000, Loss: 0.0010115100303664804\n",
      "训练次数：3005, Loss: 0.0008875346975401044\n",
      "训练次数：3010, Loss: 0.0014451813185587525\n",
      "训练次数：3015, Loss: 0.0005654832348227501\n",
      "训练次数：3020, Loss: 0.0011018398217856884\n",
      "第 63 轮训练总体误差值：0.14148540794849396\n",
      "**********开始本轮验证**********\n",
      "第 63 轮训练在整体验证集上的Loss: 0.31192124355584383\n",
      "allen_62.pth 模型已保存\n",
      "--------------------第64轮训练开始----------------------\n",
      "训练次数：3025, Loss: 0.005210416857153177\n",
      "训练次数：3030, Loss: 0.004533437080681324\n",
      "训练次数：3035, Loss: 0.00301611190661788\n",
      "训练次数：3040, Loss: 0.0035248612985014915\n",
      "训练次数：3045, Loss: 0.001414963393472135\n",
      "训练次数：3050, Loss: 0.007621224038302898\n",
      "训练次数：3055, Loss: 0.0018917247653007507\n",
      "训练次数：3060, Loss: 0.010645922273397446\n",
      "训练次数：3065, Loss: 0.0010643028654158115\n",
      "训练次数：3070, Loss: 0.005516969598829746\n",
      "第 64 轮训练总体误差值：0.18962447345256805\n",
      "**********开始本轮验证**********\n",
      "第 64 轮训练在整体验证集上的Loss: 0.42623784206807613\n",
      "allen_63.pth 模型已保存\n",
      "--------------------第65轮训练开始----------------------\n",
      "训练次数：3075, Loss: 0.009848196990787983\n",
      "训练次数：3080, Loss: 0.007076684385538101\n",
      "训练次数：3085, Loss: 0.005835396237671375\n",
      "训练次数：3090, Loss: 0.008875633589923382\n",
      "训练次数：3095, Loss: 0.0015784730203449726\n",
      "训练次数：3100, Loss: 0.003072560764849186\n",
      "训练次数：3105, Loss: 0.004002920351922512\n",
      "训练次数：3110, Loss: 0.0031913721468299627\n",
      "训练次数：3115, Loss: 0.0073935664258897305\n",
      "训练次数：3120, Loss: 0.0050290292128920555\n",
      "第 65 轮训练总体误差值：0.28467801213264465\n",
      "**********开始本轮验证**********\n",
      "第 65 轮训练在整体验证集上的Loss: 0.3180235871113837\n",
      "allen_64.pth 模型已保存\n",
      "--------------------第66轮训练开始----------------------\n",
      "训练次数：3125, Loss: 0.0038562046829611063\n",
      "训练次数：3130, Loss: 0.0011659449664875865\n",
      "训练次数：3135, Loss: 0.0031532244756817818\n",
      "训练次数：3140, Loss: 0.0014444866683334112\n",
      "训练次数：3145, Loss: 0.0013583467807620764\n",
      "训练次数：3150, Loss: 0.0025802000891417265\n",
      "训练次数：3155, Loss: 0.019331835210323334\n",
      "训练次数：3160, Loss: 0.010450133122503757\n",
      "训练次数：3165, Loss: 0.029770202934741974\n",
      "第 66 轮训练总体误差值：0.2591487467288971\n",
      "**********开始本轮验证**********\n",
      "第 66 轮训练在整体验证集上的Loss: 0.6176055241376162\n",
      "allen_65.pth 模型已保存\n",
      "--------------------第67轮训练开始----------------------\n",
      "训练次数：3170, Loss: 0.01377369835972786\n",
      "训练次数：3175, Loss: 0.014489270746707916\n",
      "训练次数：3180, Loss: 0.007358117029070854\n",
      "训练次数：3185, Loss: 0.004641604609787464\n",
      "训练次数：3190, Loss: 0.004020521882921457\n",
      "训练次数：3195, Loss: 0.010420342907309532\n",
      "训练次数：3200, Loss: 0.004197369329631329\n",
      "训练次数：3205, Loss: 0.00288283359259367\n",
      "训练次数：3210, Loss: 0.009659452363848686\n",
      "训练次数：3215, Loss: 0.02133016102015972\n",
      "第 67 轮训练总体误差值：0.42941850423812866\n",
      "**********开始本轮验证**********\n",
      "第 67 轮训练在整体验证集上的Loss: 0.8095619715750217\n",
      "allen_66.pth 模型已保存\n",
      "--------------------第68轮训练开始----------------------\n",
      "训练次数：3220, Loss: 0.007343197241425514\n",
      "训练次数：3225, Loss: 0.013626153580844402\n",
      "训练次数：3230, Loss: 0.005951112136244774\n",
      "训练次数：3235, Loss: 0.005755146965384483\n",
      "训练次数：3240, Loss: 0.002623240929096937\n",
      "训练次数：3245, Loss: 0.0030665432568639517\n",
      "训练次数：3250, Loss: 0.0013943061931058764\n",
      "训练次数：3255, Loss: 0.0011438503861427307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：3260, Loss: 0.0025146391708403826\n",
      "第 68 轮训练总体误差值：0.36054128408432007\n",
      "**********开始本轮验证**********\n",
      "第 68 轮训练在整体验证集上的Loss: 0.7986378027126193\n",
      "allen_67.pth 模型已保存\n",
      "--------------------第69轮训练开始----------------------\n",
      "训练次数：3265, Loss: 0.11523184180259705\n",
      "训练次数：3270, Loss: 0.02864886447787285\n",
      "训练次数：3275, Loss: 0.008795887231826782\n",
      "训练次数：3280, Loss: 0.01885298639535904\n",
      "训练次数：3285, Loss: 0.005895686335861683\n",
      "训练次数：3290, Loss: 0.012776101008057594\n",
      "训练次数：3295, Loss: 0.003539038123562932\n",
      "训练次数：3300, Loss: 0.016305185854434967\n",
      "训练次数：3305, Loss: 0.001257976284250617\n",
      "训练次数：3310, Loss: 0.020439838990569115\n",
      "第 69 轮训练总体误差值：0.8694055676460266\n",
      "**********开始本轮验证**********\n",
      "第 69 轮训练在整体验证集上的Loss: 0.7230254467576742\n",
      "allen_68.pth 模型已保存\n",
      "--------------------第70轮训练开始----------------------\n",
      "训练次数：3315, Loss: 0.028424404561519623\n",
      "训练次数：3320, Loss: 0.007783888839185238\n",
      "训练次数：3325, Loss: 0.008790052495896816\n",
      "训练次数：3330, Loss: 0.01397008914500475\n",
      "训练次数：3335, Loss: 0.0016889511607587337\n",
      "训练次数：3340, Loss: 0.0054291351698338985\n",
      "训练次数：3345, Loss: 0.0019104662351310253\n",
      "训练次数：3350, Loss: 0.00080623768735677\n",
      "训练次数：3355, Loss: 0.003462253138422966\n",
      "训练次数：3360, Loss: 0.005679391790181398\n",
      "第 70 轮训练总体误差值：0.42689982056617737\n",
      "**********开始本轮验证**********\n",
      "第 70 轮训练在整体验证集上的Loss: 0.4419204453006387\n",
      "allen_69.pth 模型已保存\n",
      "--------------------第71轮训练开始----------------------\n",
      "训练次数：3365, Loss: 0.00375343207269907\n",
      "训练次数：3370, Loss: 0.0030310717411339283\n",
      "训练次数：3375, Loss: 0.0014942518901079893\n",
      "训练次数：3380, Loss: 0.0019217306980863214\n",
      "训练次数：3385, Loss: 0.002709196414798498\n",
      "训练次数：3390, Loss: 0.002788717858493328\n",
      "训练次数：3395, Loss: 0.003257447388023138\n",
      "训练次数：3400, Loss: 0.0010901070199906826\n",
      "训练次数：3405, Loss: 0.01603986695408821\n",
      "第 71 轮训练总体误差值：0.2023218274116516\n",
      "**********开始本轮验证**********\n",
      "第 71 轮训练在整体验证集上的Loss: 0.5498398197814822\n",
      "allen_70.pth 模型已保存\n",
      "--------------------第72轮训练开始----------------------\n",
      "训练次数：3410, Loss: 0.036846328526735306\n",
      "训练次数：3415, Loss: 0.011637242510914803\n",
      "训练次数：3420, Loss: 0.010847141034901142\n",
      "训练次数：3425, Loss: 0.004970431327819824\n",
      "训练次数：3430, Loss: 0.001960722031071782\n",
      "训练次数：3435, Loss: 0.0069939931854605675\n",
      "训练次数：3440, Loss: 0.0034950743429362774\n",
      "训练次数：3445, Loss: 0.0016994551988318563\n",
      "训练次数：3450, Loss: 0.001293541630730033\n",
      "训练次数：3455, Loss: 0.005008607171475887\n",
      "第 72 轮训练总体误差值：0.3432096838951111\n",
      "**********开始本轮验证**********\n",
      "第 72 轮训练在整体验证集上的Loss: 0.38843693118542433\n",
      "allen_71.pth 模型已保存\n",
      "--------------------第73轮训练开始----------------------\n",
      "训练次数：3460, Loss: 0.004252511542290449\n",
      "训练次数：3465, Loss: 0.011334894225001335\n",
      "训练次数：3470, Loss: 0.002012157579883933\n",
      "训练次数：3475, Loss: 0.00071594218024984\n",
      "训练次数：3480, Loss: 0.001063541043549776\n",
      "训练次数：3485, Loss: 0.0014343132497742772\n",
      "训练次数：3490, Loss: 0.001165584078989923\n",
      "训练次数：3495, Loss: 0.0005102967261336744\n",
      "训练次数：3500, Loss: 0.0012001680443063378\n",
      "第 73 轮训练总体误差值：0.16347379982471466\n",
      "**********开始本轮验证**********\n",
      "第 73 轮训练在整体验证集上的Loss: 0.40796843729913235\n",
      "allen_72.pth 模型已保存\n",
      "--------------------第74轮训练开始----------------------\n",
      "训练次数：3505, Loss: 0.009982786141335964\n",
      "训练次数：3510, Loss: 0.002563433488830924\n",
      "训练次数：3515, Loss: 0.002294922713190317\n",
      "训练次数：3520, Loss: 0.0015081276651471853\n",
      "训练次数：3525, Loss: 0.0018639210611581802\n",
      "训练次数：3530, Loss: 0.005636095535010099\n",
      "训练次数：3535, Loss: 0.0022612055763602257\n",
      "训练次数：3540, Loss: 0.009354089386761189\n",
      "训练次数：3545, Loss: 0.0005388801801018417\n",
      "训练次数：3550, Loss: 0.00479796901345253\n",
      "第 74 轮训练总体误差值：0.1678643524646759\n",
      "**********开始本轮验证**********\n",
      "第 74 轮训练在整体验证集上的Loss: 0.3814792586490512\n",
      "allen_73.pth 模型已保存\n",
      "--------------------第75轮训练开始----------------------\n",
      "训练次数：3555, Loss: 0.0060721877962350845\n",
      "训练次数：3560, Loss: 0.006970324087888002\n",
      "训练次数：3565, Loss: 0.0009738884982652962\n",
      "训练次数：3570, Loss: 0.00847184844315052\n",
      "训练次数：3575, Loss: 0.0013906351523473859\n",
      "训练次数：3580, Loss: 0.000845494563691318\n",
      "训练次数：3585, Loss: 0.0013511517317965627\n",
      "训练次数：3590, Loss: 0.00039685695082880557\n",
      "训练次数：3595, Loss: 0.0010406167712062597\n",
      "训练次数：3600, Loss: 0.0018351504113525152\n",
      "第 75 轮训练总体误差值：0.15016905963420868\n",
      "**********开始本轮验证**********\n",
      "第 75 轮训练在整体验证集上的Loss: 0.43289732467383146\n",
      "allen_74.pth 模型已保存\n",
      "--------------------第76轮训练开始----------------------\n",
      "训练次数：3605, Loss: 0.005072258412837982\n",
      "训练次数：3610, Loss: 0.006574416067451239\n",
      "训练次数：3615, Loss: 0.0018576738657429814\n",
      "训练次数：3620, Loss: 0.0005080632981844246\n",
      "训练次数：3625, Loss: 0.0038676178082823753\n",
      "训练次数：3630, Loss: 0.0027016731910407543\n",
      "训练次数：3635, Loss: 0.004151954781264067\n",
      "训练次数：3640, Loss: 0.0013049638364464045\n",
      "训练次数：3645, Loss: 0.006965723820030689\n",
      "第 76 轮训练总体误差值：0.19314680993556976\n",
      "**********开始本轮验证**********\n",
      "第 76 轮训练在整体验证集上的Loss: 0.4074713084846735\n",
      "allen_75.pth 模型已保存\n",
      "--------------------第77轮训练开始----------------------\n",
      "训练次数：3650, Loss: 0.01760193146765232\n",
      "训练次数：3655, Loss: 0.0013950825668871403\n",
      "训练次数：3660, Loss: 0.004779496695846319\n",
      "训练次数：3665, Loss: 0.002354881726205349\n",
      "训练次数：3670, Loss: 0.0010276015382260084\n",
      "训练次数：3675, Loss: 0.006364951375871897\n",
      "训练次数：3680, Loss: 0.0019083322258666158\n",
      "训练次数：3685, Loss: 0.0006774686626158655\n",
      "训练次数：3690, Loss: 0.001090733683668077\n",
      "训练次数：3695, Loss: 0.0008188110077753663\n",
      "第 77 轮训练总体误差值：0.17528313398361206\n",
      "**********开始本轮验证**********\n",
      "第 77 轮训练在整体验证集上的Loss: 0.4366935817524791\n",
      "allen_76.pth 模型已保存\n",
      "--------------------第78轮训练开始----------------------\n",
      "训练次数：3700, Loss: 0.009969494305551052\n",
      "训练次数：3705, Loss: 0.012292901054024696\n",
      "训练次数：3710, Loss: 0.005387072451412678\n",
      "训练次数：3715, Loss: 0.0018188848625868559\n",
      "训练次数：3720, Loss: 0.0018920288421213627\n",
      "训练次数：3725, Loss: 0.0018240894423797727\n",
      "训练次数：3730, Loss: 0.0017856000922620296\n",
      "训练次数：3735, Loss: 0.0007872741553001106\n",
      "训练次数：3740, Loss: 0.0009699041838757694\n",
      "第 78 轮训练总体误差值：0.1928478628396988\n",
      "**********开始本轮验证**********\n",
      "第 78 轮训练在整体验证集上的Loss: 0.33819938916713\n",
      "allen_77.pth 模型已保存\n",
      "--------------------第79轮训练开始----------------------\n",
      "训练次数：3745, Loss: 0.005485880188643932\n",
      "训练次数：3750, Loss: 0.002517127664759755\n",
      "训练次数：3755, Loss: 0.0030247943941503763\n",
      "训练次数：3760, Loss: 0.0016817334108054638\n",
      "训练次数：3765, Loss: 0.0012820621486753225\n",
      "训练次数：3770, Loss: 0.006990818306803703\n",
      "训练次数：3775, Loss: 0.001476034987717867\n",
      "训练次数：3780, Loss: 0.008698396384716034\n",
      "训练次数：3785, Loss: 0.0009169623954221606\n",
      "训练次数：3790, Loss: 0.002544612856581807\n",
      "第 79 轮训练总体误差值：0.1266704499721527\n",
      "**********开始本轮验证**********\n",
      "第 79 轮训练在整体验证集上的Loss: 0.40834955498576164\n",
      "allen_78.pth 模型已保存\n",
      "--------------------第80轮训练开始----------------------\n",
      "训练次数：3795, Loss: 0.006015052553266287\n",
      "训练次数：3800, Loss: 0.008639276027679443\n",
      "训练次数：3805, Loss: 0.0035447138361632824\n",
      "训练次数：3810, Loss: 0.009092999622225761\n",
      "训练次数：3815, Loss: 0.0012781884288415313\n",
      "训练次数：3820, Loss: 0.0009376517264172435\n",
      "训练次数：3825, Loss: 0.0009441692964173853\n",
      "训练次数：3830, Loss: 0.0003228740533813834\n",
      "训练次数：3835, Loss: 0.0015112843830138445\n",
      "训练次数：3840, Loss: 0.0011523591820150614\n",
      "第 80 轮训练总体误差值：0.16631020605564117\n",
      "**********开始本轮验证**********\n",
      "第 80 轮训练在整体验证集上的Loss: 0.3602340370416641\n",
      "allen_79.pth 模型已保存\n",
      "--------------------第81轮训练开始----------------------\n",
      "训练次数：3845, Loss: 0.002654249547049403\n",
      "训练次数：3850, Loss: 0.001886669546365738\n",
      "训练次数：3855, Loss: 0.000933790288399905\n",
      "训练次数：3860, Loss: 0.0006600444321520627\n",
      "训练次数：3865, Loss: 0.001902930554933846\n",
      "训练次数：3870, Loss: 0.0014956732047721744\n",
      "训练次数：3875, Loss: 0.0029789127875119448\n",
      "训练次数：3880, Loss: 0.0006005996838212013\n",
      "训练次数：3885, Loss: 0.008149485103785992\n",
      "第 81 轮训练总体误差值：0.12944871187210083\n",
      "**********开始本轮验证**********\n",
      "第 81 轮训练在整体验证集上的Loss: 0.42982014641165733\n",
      "allen_80.pth 模型已保存\n",
      "--------------------第82轮训练开始----------------------\n",
      "训练次数：3890, Loss: 0.009543371386826038\n",
      "训练次数：3895, Loss: 0.00709445308893919\n",
      "训练次数：3900, Loss: 0.004455407150089741\n",
      "训练次数：3905, Loss: 0.0029123465064913034\n",
      "训练次数：3910, Loss: 0.0006244595278985798\n",
      "训练次数：3915, Loss: 0.006884042639285326\n",
      "训练次数：3920, Loss: 0.0013510502176359296\n",
      "训练次数：3925, Loss: 0.0010816174326464534\n",
      "训练次数：3930, Loss: 0.0011583486339077353\n",
      "训练次数：3935, Loss: 0.0041803838685154915\n",
      "第 82 轮训练总体误差值：0.1601899415254593\n",
      "**********开始本轮验证**********\n",
      "第 82 轮训练在整体验证集上的Loss: 0.4192195050418377\n",
      "allen_81.pth 模型已保存\n",
      "--------------------第83轮训练开始----------------------\n",
      "训练次数：3940, Loss: 0.00576768396422267\n",
      "训练次数：3945, Loss: 0.007926980964839458\n",
      "训练次数：3950, Loss: 0.0041055744513869286\n",
      "训练次数：3955, Loss: 0.0014213650720193982\n",
      "训练次数：3960, Loss: 0.0016544422833248973\n",
      "训练次数：3965, Loss: 0.001987755997106433\n",
      "训练次数：3970, Loss: 0.001303094788454473\n",
      "训练次数：3975, Loss: 0.0010870378464460373\n",
      "训练次数：3980, Loss: 0.0012156021548435092\n",
      "第 83 轮训练总体误差值：0.21090178191661835\n",
      "**********开始本轮验证**********\n",
      "第 83 轮训练在整体验证集上的Loss: 0.48439779598265886\n",
      "allen_82.pth 模型已保存\n",
      "--------------------第84轮训练开始----------------------\n",
      "训练次数：3985, Loss: 0.0052359504625201225\n",
      "训练次数：3990, Loss: 0.0056145512498915195\n",
      "训练次数：3995, Loss: 0.0016413916600868106\n",
      "训练次数：4000, Loss: 0.0038835513405501842\n",
      "训练次数：4005, Loss: 0.0012754304334521294\n",
      "训练次数：4010, Loss: 0.0239401962608099\n",
      "训练次数：4015, Loss: 0.00206571351736784\n",
      "训练次数：4020, Loss: 0.009849957190454006\n",
      "训练次数：4025, Loss: 0.0017669697990640998\n",
      "训练次数：4030, Loss: 0.0064640166237950325\n",
      "第 84 轮训练总体误差值：0.2584584951400757\n",
      "**********开始本轮验证**********\n",
      "第 84 轮训练在整体验证集上的Loss: 0.796416662633419\n",
      "allen_83.pth 模型已保存\n",
      "--------------------第85轮训练开始----------------------\n",
      "训练次数：4035, Loss: 0.011214721016585827\n",
      "训练次数：4040, Loss: 0.011660868301987648\n",
      "训练次数：4045, Loss: 0.00456908717751503\n",
      "训练次数：4050, Loss: 0.019112465903162956\n",
      "训练次数：4055, Loss: 0.0018990609096363187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：4060, Loss: 0.005314281675964594\n",
      "训练次数：4065, Loss: 0.001182241947390139\n",
      "训练次数：4070, Loss: 0.0022820187732577324\n",
      "训练次数：4075, Loss: 0.0014093799982219934\n",
      "训练次数：4080, Loss: 0.007450908422470093\n",
      "第 85 轮训练总体误差值：0.33131080865859985\n",
      "**********开始本轮验证**********\n",
      "第 85 轮训练在整体验证集上的Loss: 0.6024649599567056\n",
      "allen_84.pth 模型已保存\n",
      "--------------------第86轮训练开始----------------------\n",
      "训练次数：4085, Loss: 0.029990950599312782\n",
      "训练次数：4090, Loss: 0.007342991419136524\n",
      "训练次数：4095, Loss: 0.009051202796399593\n",
      "训练次数：4100, Loss: 0.002865221817046404\n",
      "训练次数：4105, Loss: 0.006255688611418009\n",
      "训练次数：4110, Loss: 0.0042865341529250145\n",
      "训练次数：4115, Loss: 0.007518733385950327\n",
      "训练次数：4120, Loss: 0.0023308272939175367\n",
      "训练次数：4125, Loss: 0.024582048878073692\n",
      "第 86 轮训练总体误差值：0.5932316184043884\n",
      "**********开始本轮验证**********\n",
      "第 86 轮训练在整体验证集上的Loss: 0.5964307030662894\n",
      "allen_85.pth 模型已保存\n",
      "--------------------第87轮训练开始----------------------\n",
      "训练次数：4130, Loss: 0.010824655182659626\n",
      "训练次数：4135, Loss: 0.004989244043827057\n",
      "训练次数：4140, Loss: 0.005265611689537764\n",
      "训练次数：4145, Loss: 0.0023046727292239666\n",
      "训练次数：4150, Loss: 0.0009658716153353453\n",
      "训练次数：4155, Loss: 0.007367650978267193\n",
      "训练次数：4160, Loss: 0.0011162752052769065\n",
      "训练次数：4165, Loss: 0.0017846336122602224\n",
      "训练次数：4170, Loss: 0.001360001740977168\n",
      "训练次数：4175, Loss: 0.006360241677612066\n",
      "第 87 轮训练总体误差值：0.20731587707996368\n",
      "**********开始本轮验证**********\n",
      "第 87 轮训练在整体验证集上的Loss: 0.3794151321053505\n",
      "allen_86.pth 模型已保存\n",
      "--------------------第88轮训练开始----------------------\n",
      "训练次数：4180, Loss: 0.008926253765821457\n",
      "训练次数：4185, Loss: 0.009324854239821434\n",
      "训练次数：4190, Loss: 0.00418938510119915\n",
      "训练次数：4195, Loss: 0.001403936417773366\n",
      "训练次数：4200, Loss: 0.0014326304662972689\n",
      "训练次数：4205, Loss: 0.0025006288196891546\n",
      "训练次数：4210, Loss: 0.0017392219742760062\n",
      "训练次数：4215, Loss: 0.0009725558338686824\n",
      "训练次数：4220, Loss: 0.0017066900618374348\n",
      "第 88 轮训练总体误差值：0.22052370011806488\n",
      "**********开始本轮验证**********\n",
      "第 88 轮训练在整体验证集上的Loss: 0.5581583064049482\n",
      "allen_87.pth 模型已保存\n",
      "--------------------第89轮训练开始----------------------\n",
      "训练次数：4225, Loss: 0.022080324590206146\n",
      "训练次数：4230, Loss: 0.007020067423582077\n",
      "训练次数：4235, Loss: 0.004580820444971323\n",
      "训练次数：4240, Loss: 0.004639608785510063\n",
      "训练次数：4245, Loss: 0.0012236019829288125\n",
      "训练次数：4250, Loss: 0.005766008980572224\n",
      "训练次数：4255, Loss: 0.002033466240391135\n",
      "训练次数：4260, Loss: 0.008709322661161423\n",
      "训练次数：4265, Loss: 0.000670043402351439\n",
      "训练次数：4270, Loss: 0.011617426760494709\n",
      "第 89 轮训练总体误差值：0.2744385600090027\n",
      "**********开始本轮验证**********\n",
      "第 89 轮训练在整体验证集上的Loss: 0.3690844299271703\n",
      "allen_88.pth 模型已保存\n",
      "--------------------第90轮训练开始----------------------\n",
      "训练次数：4275, Loss: 0.011488238349556923\n",
      "训练次数：4280, Loss: 0.009321549907326698\n",
      "训练次数：4285, Loss: 0.0035154535435140133\n",
      "训练次数：4290, Loss: 0.010838707908987999\n",
      "训练次数：4295, Loss: 0.0006858279812149704\n",
      "训练次数：4300, Loss: 0.003402639413252473\n",
      "训练次数：4305, Loss: 0.0010407202644273639\n",
      "训练次数：4310, Loss: 0.000637702876701951\n",
      "训练次数：4315, Loss: 0.0012210742570459843\n",
      "训练次数：4320, Loss: 0.007295910734683275\n",
      "第 90 轮训练总体误差值：0.22021913528442383\n",
      "**********开始本轮验证**********\n",
      "第 90 轮训练在整体验证集上的Loss: 0.4244242887943983\n",
      "allen_89.pth 模型已保存\n",
      "--------------------第91轮训练开始----------------------\n",
      "训练次数：4325, Loss: 0.0034831692464649677\n",
      "训练次数：4330, Loss: 0.0006491519743576646\n",
      "训练次数：4335, Loss: 0.0014750468544661999\n",
      "训练次数：4340, Loss: 0.0007197559461928904\n",
      "训练次数：4345, Loss: 0.0010085662361234426\n",
      "训练次数：4350, Loss: 0.0026213291566818953\n",
      "训练次数：4355, Loss: 0.0030955751426517963\n",
      "训练次数：4360, Loss: 0.0018096879357472062\n",
      "训练次数：4365, Loss: 0.009773876518011093\n",
      "第 91 轮训练总体误差值：0.14175362884998322\n",
      "**********开始本轮验证**********\n",
      "第 91 轮训练在整体验证集上的Loss: 0.3421526225283742\n",
      "allen_90.pth 模型已保存\n",
      "--------------------第92轮训练开始----------------------\n",
      "训练次数：4370, Loss: 0.009448006749153137\n",
      "训练次数：4375, Loss: 0.003076721215620637\n",
      "训练次数：4380, Loss: 0.0011652670800685883\n",
      "训练次数：4385, Loss: 0.0031279621180146933\n",
      "训练次数：4390, Loss: 0.00027247268008068204\n",
      "训练次数：4395, Loss: 0.004481838084757328\n",
      "训练次数：4400, Loss: 0.0013414244167506695\n",
      "训练次数：4405, Loss: 0.00044714263640344143\n",
      "训练次数：4410, Loss: 0.0008554850937798619\n",
      "训练次数：4415, Loss: 0.005950013175606728\n",
      "第 92 轮训练总体误差值：0.13684847950935364\n",
      "**********开始本轮验证**********\n",
      "第 92 轮训练在整体验证集上的Loss: 0.3604560438543558\n",
      "allen_91.pth 模型已保存\n",
      "--------------------第93轮训练开始----------------------\n",
      "训练次数：4420, Loss: 0.002135263755917549\n",
      "训练次数：4425, Loss: 0.0053427014499902725\n",
      "训练次数：4430, Loss: 0.0008017910295166075\n",
      "训练次数：4435, Loss: 0.0007268491899594665\n",
      "训练次数：4440, Loss: 0.000663803715724498\n",
      "训练次数：4445, Loss: 0.0007012099376879632\n",
      "训练次数：4450, Loss: 0.0012207676190882921\n",
      "训练次数：4455, Loss: 0.0004684200102929026\n",
      "训练次数：4460, Loss: 0.0008415060001425445\n",
      "第 93 轮训练总体误差值：0.10845132917165756\n",
      "**********开始本轮验证**********\n",
      "第 93 轮训练在整体验证集上的Loss: 0.37532283645123243\n",
      "allen_92.pth 模型已保存\n",
      "--------------------第94轮训练开始----------------------\n",
      "训练次数：4465, Loss: 0.011632769368588924\n",
      "训练次数：4470, Loss: 0.0030378818046301603\n",
      "训练次数：4475, Loss: 0.0023111985065042973\n",
      "训练次数：4480, Loss: 0.0017081397818401456\n",
      "训练次数：4485, Loss: 0.0004677295219153166\n",
      "训练次数：4490, Loss: 0.004780976567417383\n",
      "训练次数：4495, Loss: 0.001122336252592504\n",
      "训练次数：4500, Loss: 0.005282591562718153\n",
      "训练次数：4505, Loss: 0.0003241454251110554\n",
      "训练次数：4510, Loss: 0.006118898279964924\n",
      "第 94 轮训练总体误差值：0.1368560642004013\n",
      "**********开始本轮验证**********\n",
      "第 94 轮训练在整体验证集上的Loss: 0.3366588857024908\n",
      "allen_93.pth 模型已保存\n",
      "--------------------第95轮训练开始----------------------\n",
      "训练次数：4515, Loss: 0.002348826266825199\n",
      "训练次数：4520, Loss: 0.009417411871254444\n",
      "训练次数：4525, Loss: 0.0010628357995301485\n",
      "训练次数：4530, Loss: 0.009266894310712814\n",
      "训练次数：4535, Loss: 0.0017951240297406912\n",
      "训练次数：4540, Loss: 0.0006508887745440006\n",
      "训练次数：4545, Loss: 0.0020070686005055904\n",
      "训练次数：4550, Loss: 0.00032253749668598175\n",
      "训练次数：4555, Loss: 0.0012212088331580162\n",
      "训练次数：4560, Loss: 0.0025723769795149565\n",
      "第 95 轮训练总体误差值：0.11583814024925232\n",
      "**********开始本轮验证**********\n",
      "第 95 轮训练在整体验证集上的Loss: 0.40126995742321014\n",
      "allen_94.pth 模型已保存\n",
      "--------------------第96轮训练开始----------------------\n",
      "训练次数：4565, Loss: 0.002104799961671233\n",
      "训练次数：4570, Loss: 0.0017218957655131817\n",
      "训练次数：4575, Loss: 0.0011491060722619295\n",
      "训练次数：4580, Loss: 0.00023410783614963293\n",
      "训练次数：4585, Loss: 0.0021494473330676556\n",
      "训练次数：4590, Loss: 0.0015727800782769918\n",
      "训练次数：4595, Loss: 0.0019400608725845814\n",
      "训练次数：4600, Loss: 0.0010830559767782688\n",
      "训练次数：4605, Loss: 0.006092125084251165\n",
      "第 96 轮训练总体误差值：0.13937348127365112\n",
      "**********开始本轮验证**********\n",
      "第 96 轮训练在整体验证集上的Loss: 0.37607087194919586\n",
      "allen_95.pth 模型已保存\n",
      "--------------------第97轮训练开始----------------------\n",
      "训练次数：4610, Loss: 0.011683905497193336\n",
      "训练次数：4615, Loss: 0.00112258386798203\n",
      "训练次数：4620, Loss: 0.0027466663159430027\n",
      "训练次数：4625, Loss: 0.0013392121763899922\n",
      "训练次数：4630, Loss: 0.001982050947844982\n",
      "训练次数：4635, Loss: 0.006102549843490124\n",
      "训练次数：4640, Loss: 0.001277812640182674\n",
      "训练次数：4645, Loss: 0.00037165978574194014\n",
      "训练次数：4650, Loss: 0.0010523807723075151\n",
      "训练次数：4655, Loss: 0.0046387286856770515\n",
      "第 97 轮训练总体误差值：0.180417999625206\n",
      "**********开始本轮验证**********\n",
      "第 97 轮训练在整体验证集上的Loss: 0.5381760150194168\n",
      "allen_96.pth 模型已保存\n",
      "--------------------第98轮训练开始----------------------\n",
      "训练次数：4660, Loss: 0.010334370657801628\n",
      "训练次数：4665, Loss: 0.008907544426620007\n",
      "训练次数：4670, Loss: 0.005623054690659046\n",
      "训练次数：4675, Loss: 0.002623197389766574\n",
      "训练次数：4680, Loss: 0.0016905583906918764\n",
      "训练次数：4685, Loss: 0.0011831453302875161\n",
      "训练次数：4690, Loss: 0.012650301679968834\n",
      "训练次数：4695, Loss: 0.003307997714728117\n",
      "训练次数：4700, Loss: 0.006288303527981043\n",
      "第 98 轮训练总体误差值：0.3757023215293884\n",
      "**********开始本轮验证**********\n",
      "第 98 轮训练在整体验证集上的Loss: 0.6819545049220324\n",
      "allen_97.pth 模型已保存\n",
      "--------------------第99轮训练开始----------------------\n",
      "训练次数：4705, Loss: 0.020272741094231606\n",
      "训练次数：4710, Loss: 0.023231403902173042\n",
      "训练次数：4715, Loss: 0.004309551324695349\n",
      "训练次数：4720, Loss: 0.008023626171052456\n",
      "训练次数：4725, Loss: 0.0036933061201125383\n",
      "训练次数：4730, Loss: 0.005615548696368933\n",
      "训练次数：4735, Loss: 0.0030216826125979424\n",
      "训练次数：4740, Loss: 0.019332267343997955\n",
      "训练次数：4745, Loss: 0.0014166448963806033\n",
      "训练次数：4750, Loss: 0.03379794955253601\n",
      "第 99 轮训练总体误差值：0.5080059170722961\n",
      "**********开始本轮验证**********\n",
      "第 99 轮训练在整体验证集上的Loss: 0.8772001108154655\n",
      "allen_98.pth 模型已保存\n",
      "--------------------第100轮训练开始----------------------\n",
      "训练次数：4755, Loss: 0.028048725798726082\n",
      "训练次数：4760, Loss: 0.009812228381633759\n",
      "训练次数：4765, Loss: 0.017306111752986908\n",
      "训练次数：4770, Loss: 0.026767203584313393\n",
      "训练次数：4775, Loss: 0.006415016017854214\n",
      "训练次数：4780, Loss: 0.005182957276701927\n",
      "训练次数：4785, Loss: 0.0026272388640791178\n",
      "训练次数：4790, Loss: 0.04787445440888405\n",
      "训练次数：4795, Loss: 0.031624771654605865\n",
      "训练次数：4800, Loss: 0.03525829687714577\n",
      "第 100 轮训练总体误差值：1.2298897504806519\n",
      "**********开始本轮验证**********\n",
      "第 100 轮训练在整体验证集上的Loss: 1.119294736534357\n",
      "allen_99.pth 模型已保存\n",
      "--------------------第101轮训练开始----------------------\n",
      "训练次数：4805, Loss: 0.0585525706410408\n",
      "训练次数：4810, Loss: 0.0373573824763298\n",
      "训练次数：4815, Loss: 0.019518552348017693\n",
      "训练次数：4820, Loss: 0.031042195856571198\n",
      "训练次数：4825, Loss: 0.012820311821997166\n",
      "训练次数：4830, Loss: 0.0282319113612175\n",
      "训练次数：4835, Loss: 0.023421432822942734\n",
      "训练次数：4840, Loss: 0.024597253650426865\n",
      "训练次数：4845, Loss: 0.06119769811630249\n",
      "第 101 轮训练总体误差值：1.4011867046356201\n",
      "**********开始本轮验证**********\n",
      "第 101 轮训练在整体验证集上的Loss: 0.8663225853815675\n",
      "allen_100.pth 模型已保存\n",
      "--------------------第102轮训练开始----------------------\n",
      "训练次数：4850, Loss: 0.08310241997241974\n",
      "训练次数：4855, Loss: 0.05761882662773132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：4860, Loss: 0.011517150327563286\n",
      "训练次数：4865, Loss: 0.011490043252706528\n",
      "训练次数：4870, Loss: 0.010519307106733322\n",
      "训练次数：4875, Loss: 0.015479523688554764\n",
      "训练次数：4880, Loss: 0.010453692637383938\n",
      "训练次数：4885, Loss: 0.0033887983299791813\n",
      "训练次数：4890, Loss: 0.002622895175591111\n",
      "训练次数：4895, Loss: 0.022815342992544174\n",
      "第 102 轮训练总体误差值：0.9568528532981873\n",
      "**********开始本轮验证**********\n",
      "第 102 轮训练在整体验证集上的Loss: 0.8252496421337128\n",
      "allen_101.pth 模型已保存\n",
      "--------------------第103轮训练开始----------------------\n",
      "训练次数：4900, Loss: 0.006176070775836706\n",
      "训练次数：4905, Loss: 0.02415871061384678\n",
      "训练次数：4910, Loss: 0.0036729557905346155\n",
      "训练次数：4915, Loss: 0.002174102934077382\n",
      "训练次数：4920, Loss: 0.0011506970040500164\n",
      "训练次数：4925, Loss: 0.0012170582776889205\n",
      "训练次数：4930, Loss: 0.0031839802395552397\n",
      "训练次数：4935, Loss: 0.0007601940887980163\n",
      "训练次数：4940, Loss: 0.0020326822996139526\n",
      "第 103 轮训练总体误差值：0.43598848581314087\n",
      "**********开始本轮验证**********\n",
      "第 103 轮训练在整体验证集上的Loss: 0.7145312633365393\n",
      "allen_102.pth 模型已保存\n",
      "--------------------第104轮训练开始----------------------\n",
      "训练次数：4945, Loss: 0.03847610205411911\n",
      "训练次数：4950, Loss: 0.011794980615377426\n",
      "训练次数：4955, Loss: 0.03544731065630913\n",
      "训练次数：4960, Loss: 0.003973215818405151\n",
      "训练次数：4965, Loss: 0.0017724117496982217\n",
      "训练次数：4970, Loss: 0.016819020733237267\n",
      "训练次数：4975, Loss: 0.0025140426587313414\n",
      "训练次数：4980, Loss: 0.00939229503273964\n",
      "训练次数：4985, Loss: 0.0007431371486745775\n",
      "训练次数：4990, Loss: 0.01134291011840105\n",
      "第 104 轮训练总体误差值：0.5259749293327332\n",
      "**********开始本轮验证**********\n",
      "第 104 轮训练在整体验证集上的Loss: 0.7410374181345105\n",
      "allen_103.pth 模型已保存\n",
      "--------------------第105轮训练开始----------------------\n",
      "训练次数：4995, Loss: 0.0523771233856678\n",
      "训练次数：5000, Loss: 0.012512660585343838\n",
      "训练次数：5005, Loss: 0.010140715166926384\n",
      "训练次数：5010, Loss: 0.014652112498879433\n",
      "训练次数：5015, Loss: 0.0012604637304320931\n",
      "训练次数：5020, Loss: 0.001850942731834948\n",
      "训练次数：5025, Loss: 0.0020579732954502106\n",
      "训练次数：5030, Loss: 0.0007368632359430194\n",
      "训练次数：5035, Loss: 0.0017068927409127355\n",
      "训练次数：5040, Loss: 0.0033477074466645718\n",
      "第 105 轮训练总体误差值：0.5062453150749207\n",
      "**********开始本轮验证**********\n",
      "第 105 轮训练在整体验证集上的Loss: 0.49394826404750347\n",
      "allen_104.pth 模型已保存\n",
      "--------------------第106轮训练开始----------------------\n",
      "训练次数：5045, Loss: 0.008461582474410534\n",
      "训练次数：5050, Loss: 0.0027543711476027966\n",
      "训练次数：5055, Loss: 0.0023247995413839817\n",
      "训练次数：5060, Loss: 0.0028440256137400866\n",
      "训练次数：5065, Loss: 0.003115409519523382\n",
      "训练次数：5070, Loss: 0.002420825883746147\n",
      "训练次数：5075, Loss: 0.006989962421357632\n",
      "训练次数：5080, Loss: 0.0010720317950472236\n",
      "训练次数：5085, Loss: 0.01759478449821472\n",
      "第 106 轮训练总体误差值：0.2558017373085022\n",
      "**********开始本轮验证**********\n",
      "第 106 轮训练在整体验证集上的Loss: 0.3791390899568796\n",
      "allen_105.pth 模型已保存\n",
      "--------------------第107轮训练开始----------------------\n",
      "训练次数：5090, Loss: 0.007676814682781696\n",
      "训练次数：5095, Loss: 0.0017901500687003136\n",
      "训练次数：5100, Loss: 0.00231266301125288\n",
      "训练次数：5105, Loss: 0.002596135949715972\n",
      "训练次数：5110, Loss: 0.0008872036123648286\n",
      "训练次数：5115, Loss: 0.008763384073972702\n",
      "训练次数：5120, Loss: 0.0009436703403480351\n",
      "训练次数：5125, Loss: 0.000474586762720719\n",
      "训练次数：5130, Loss: 0.0012512754183262587\n",
      "训练次数：5135, Loss: 0.005784151144325733\n",
      "第 107 轮训练总体误差值：0.15733203291893005\n",
      "**********开始本轮验证**********\n",
      "第 107 轮训练在整体验证集上的Loss: 0.34090954530984163\n",
      "allen_106.pth 模型已保存\n",
      "--------------------第108轮训练开始----------------------\n",
      "训练次数：5140, Loss: 0.0026341439224779606\n",
      "训练次数：5145, Loss: 0.007487809751182795\n",
      "训练次数：5150, Loss: 0.0013988829450681806\n",
      "训练次数：5155, Loss: 0.0007233504438772798\n",
      "训练次数：5160, Loss: 0.0010573730105534196\n",
      "训练次数：5165, Loss: 0.0013493297155946493\n",
      "训练次数：5170, Loss: 0.0015850908821448684\n",
      "训练次数：5175, Loss: 0.0005578265991061926\n",
      "训练次数：5180, Loss: 0.001088266959413886\n",
      "第 108 轮训练总体误差值：0.13988053798675537\n",
      "**********开始本轮验证**********\n",
      "第 108 轮训练在整体验证集上的Loss: 0.41516145411878824\n",
      "allen_107.pth 模型已保存\n",
      "--------------------第109轮训练开始----------------------\n",
      "训练次数：5185, Loss: 0.017484521493315697\n",
      "训练次数：5190, Loss: 0.0012071100063621998\n",
      "训练次数：5195, Loss: 0.003122795606032014\n",
      "训练次数：5200, Loss: 0.0017171467188745737\n",
      "训练次数：5205, Loss: 0.0013196705840528011\n",
      "训练次数：5210, Loss: 0.004783732816576958\n",
      "训练次数：5215, Loss: 0.0010593291372060776\n",
      "训练次数：5220, Loss: 0.012272005900740623\n",
      "训练次数：5225, Loss: 0.0003470233059488237\n",
      "训练次数：5230, Loss: 0.005148792173713446\n",
      "第 109 轮训练总体误差值：0.14339634776115417\n",
      "**********开始本轮验证**********\n",
      "第 109 轮训练在整体验证集上的Loss: 0.337921928614378\n",
      "allen_108.pth 模型已保存\n",
      "--------------------第110轮训练开始----------------------\n",
      "训练次数：5235, Loss: 0.0027155231218785048\n",
      "训练次数：5240, Loss: 0.007829859852790833\n",
      "训练次数：5245, Loss: 0.0017363945953547955\n",
      "训练次数：5250, Loss: 0.006293625105172396\n",
      "训练次数：5255, Loss: 0.0008361326763406396\n",
      "训练次数：5260, Loss: 0.0010499656200408936\n",
      "训练次数：5265, Loss: 0.001181269297376275\n",
      "训练次数：5270, Loss: 0.0002082394785247743\n",
      "训练次数：5275, Loss: 0.0007677951944060624\n",
      "训练次数：5280, Loss: 0.0037236863281577826\n",
      "第 110 轮训练总体误差值：0.10606192797422409\n",
      "**********开始本轮验证**********\n",
      "第 110 轮训练在整体验证集上的Loss: 0.3285283911973238\n",
      "allen_109.pth 模型已保存\n",
      "--------------------第111轮训练开始----------------------\n",
      "训练次数：5285, Loss: 0.00048757524928078055\n",
      "训练次数：5290, Loss: 0.0008661112515255809\n",
      "训练次数：5295, Loss: 0.0004073498712386936\n",
      "训练次数：5300, Loss: 0.0003751743061002344\n",
      "训练次数：5305, Loss: 0.0009824956068769097\n",
      "训练次数：5310, Loss: 0.0014042785624042153\n",
      "训练次数：5315, Loss: 0.0034978981129825115\n",
      "训练次数：5320, Loss: 0.0003738167870324105\n",
      "训练次数：5325, Loss: 0.006313336081802845\n",
      "第 111 轮训练总体误差值：0.08532184362411499\n",
      "**********开始本轮验证**********\n",
      "第 111 轮训练在整体验证集上的Loss: 0.3470966387540102\n",
      "allen_110.pth 模型已保存\n",
      "--------------------第112轮训练开始----------------------\n",
      "训练次数：5330, Loss: 0.0014927949523553252\n",
      "训练次数：5335, Loss: 0.0007315792026929557\n",
      "训练次数：5340, Loss: 0.0010218743700534105\n",
      "训练次数：5345, Loss: 0.001355753163807094\n",
      "训练次数：5350, Loss: 0.0006606520619243383\n",
      "训练次数：5355, Loss: 0.0038647670298814774\n",
      "训练次数：5360, Loss: 0.0006879109423607588\n",
      "训练次数：5365, Loss: 0.00029747432563453913\n",
      "训练次数：5370, Loss: 0.0007875981973484159\n",
      "训练次数：5375, Loss: 0.002935168333351612\n",
      "第 112 轮训练总体误差值：0.08937027305364609\n",
      "**********开始本轮验证**********\n",
      "第 112 轮训练在整体验证集上的Loss: 0.3001278452575207\n",
      "allen_111.pth 模型已保存\n",
      "--------------------第113轮训练开始----------------------\n",
      "训练次数：5380, Loss: 0.0006478982977569103\n",
      "训练次数：5385, Loss: 0.005114272236824036\n",
      "训练次数：5390, Loss: 0.00119791179895401\n",
      "训练次数：5395, Loss: 0.00029991596238687634\n",
      "训练次数：5400, Loss: 0.0005591085646301508\n",
      "训练次数：5405, Loss: 0.0008764409576542675\n",
      "训练次数：5410, Loss: 0.0008868242730386555\n",
      "训练次数：5415, Loss: 0.00027563414187170565\n",
      "训练次数：5420, Loss: 0.0005534440279006958\n",
      "第 113 轮训练总体误差值：0.07503192126750946\n",
      "**********开始本轮验证**********\n",
      "第 113 轮训练在整体验证集上的Loss: 0.3582796137779951\n",
      "allen_112.pth 模型已保存\n",
      "--------------------第114轮训练开始----------------------\n",
      "训练次数：5425, Loss: 0.0019183630356565118\n",
      "训练次数：5430, Loss: 0.0008374073659069836\n",
      "训练次数：5435, Loss: 0.000691726861987263\n",
      "训练次数：5440, Loss: 0.0008942154236137867\n",
      "训练次数：5445, Loss: 0.0005117562832310796\n",
      "训练次数：5450, Loss: 0.005922893527895212\n",
      "训练次数：5455, Loss: 0.0011253487318754196\n",
      "训练次数：5460, Loss: 0.006816359236836433\n",
      "训练次数：5465, Loss: 0.00027133626281283796\n",
      "训练次数：5470, Loss: 0.001115424558520317\n",
      "第 114 轮训练总体误差值：0.0733632817864418\n",
      "**********开始本轮验证**********\n",
      "第 114 轮训练在整体验证集上的Loss: 0.30790427327156067\n",
      "allen_113.pth 模型已保存\n",
      "--------------------第115轮训练开始----------------------\n",
      "训练次数：5475, Loss: 0.0016474575968459249\n",
      "训练次数：5480, Loss: 0.010434701107442379\n",
      "训练次数：5485, Loss: 0.0011804135283455253\n",
      "训练次数：5490, Loss: 0.004907452967017889\n",
      "训练次数：5495, Loss: 0.0006481071468442678\n",
      "训练次数：5500, Loss: 0.0009423845331184566\n",
      "训练次数：5505, Loss: 0.0007902915240265429\n",
      "训练次数：5510, Loss: 0.0001814958086470142\n",
      "训练次数：5515, Loss: 0.0006954644923098385\n",
      "训练次数：5520, Loss: 0.000583074928727001\n",
      "第 115 轮训练总体误差值：0.076506607234478\n",
      "**********开始本轮验证**********\n",
      "第 115 轮训练在整体验证集上的Loss: 0.36759393382817507\n",
      "allen_114.pth 模型已保存\n",
      "--------------------第116轮训练开始----------------------\n",
      "训练次数：5525, Loss: 0.000558556872420013\n",
      "训练次数：5530, Loss: 0.0008144948515109718\n",
      "训练次数：5535, Loss: 0.0003890297084581107\n",
      "训练次数：5540, Loss: 0.00077447370858863\n",
      "训练次数：5545, Loss: 0.0009079254232347012\n",
      "训练次数：5550, Loss: 0.0014436256606131792\n",
      "训练次数：5555, Loss: 0.002618039958178997\n",
      "训练次数：5560, Loss: 0.0003449650830589235\n",
      "训练次数：5565, Loss: 0.0043853651732206345\n",
      "第 116 轮训练总体误差值：0.07705648988485336\n",
      "**********开始本轮验证**********\n",
      "第 116 轮训练在整体验证集上的Loss: 0.3147998405620456\n",
      "allen_115.pth 模型已保存\n",
      "--------------------第117轮训练开始----------------------\n",
      "训练次数：5570, Loss: 0.002182852942496538\n",
      "训练次数：5575, Loss: 0.0010346020571887493\n",
      "训练次数：5580, Loss: 0.0008540193666703999\n",
      "训练次数：5585, Loss: 0.0014136683894321322\n",
      "训练次数：5590, Loss: 0.0003933603293262422\n",
      "训练次数：5595, Loss: 0.004015844780951738\n",
      "训练次数：5600, Loss: 0.0007193885976448655\n",
      "训练次数：5605, Loss: 0.0002606821362860501\n",
      "训练次数：5610, Loss: 0.000682988902553916\n",
      "训练次数：5615, Loss: 0.0031177259515970945\n",
      "第 117 轮训练总体误差值：0.0837194174528122\n",
      "**********开始本轮验证**********\n",
      "第 117 轮训练在整体验证集上的Loss: 0.37053692154586315\n",
      "allen_116.pth 模型已保存\n",
      "--------------------第118轮训练开始----------------------\n",
      "训练次数：5620, Loss: 0.000895216828212142\n",
      "训练次数：5625, Loss: 0.004864466842263937\n",
      "训练次数：5630, Loss: 0.001348646474070847\n",
      "训练次数：5635, Loss: 0.0005659612361341715\n",
      "训练次数：5640, Loss: 0.0007533475290983915\n",
      "训练次数：5645, Loss: 0.0006832029903307557\n",
      "训练次数：5650, Loss: 0.001008498016744852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：5655, Loss: 0.0004113382310606539\n",
      "训练次数：5660, Loss: 0.0005278292810544372\n",
      "第 118 轮训练总体误差值：0.09260014444589615\n",
      "**********开始本轮验证**********\n",
      "第 118 轮训练在整体验证集上的Loss: 0.3361901054158807\n",
      "allen_117.pth 模型已保存\n",
      "--------------------第119轮训练开始----------------------\n",
      "训练次数：5665, Loss: 0.004139992408454418\n",
      "训练次数：5670, Loss: 0.0006298942025750875\n",
      "训练次数：5675, Loss: 0.0007220433908514678\n",
      "训练次数：5680, Loss: 0.0008303978247568011\n",
      "训练次数：5685, Loss: 0.0006557359010912478\n",
      "训练次数：5690, Loss: 0.0026453877799212933\n",
      "训练次数：5695, Loss: 0.0010076737962663174\n",
      "训练次数：5700, Loss: 0.0040172310546040535\n",
      "训练次数：5705, Loss: 0.0003052164101973176\n",
      "训练次数：5710, Loss: 0.008067004382610321\n",
      "第 119 轮训练总体误差值：0.08636433631181717\n",
      "**********开始本轮验证**********\n",
      "第 119 轮训练在整体验证集上的Loss: 0.35487344581633806\n",
      "allen_118.pth 模型已保存\n",
      "--------------------第120轮训练开始----------------------\n",
      "训练次数：5715, Loss: 0.0032271461095660925\n",
      "训练次数：5720, Loss: 0.011497911997139454\n",
      "训练次数：5725, Loss: 0.0013771747471764684\n",
      "训练次数：5730, Loss: 0.00440530339255929\n",
      "训练次数：5735, Loss: 0.0006222117808647454\n",
      "训练次数：5740, Loss: 0.0006022792076691985\n",
      "训练次数：5745, Loss: 0.0006541595212183893\n",
      "训练次数：5750, Loss: 0.0001575568167027086\n",
      "训练次数：5755, Loss: 0.0005731738638132811\n",
      "训练次数：5760, Loss: 0.0074143186211586\n",
      "第 120 轮训练总体误差值：0.10023951530456543\n",
      "**********开始本轮验证**********\n",
      "第 120 轮训练在整体验证集上的Loss: 0.3502228418365121\n",
      "allen_119.pth 模型已保存\n",
      "--------------------第121轮训练开始----------------------\n",
      "训练次数：5765, Loss: 0.00166955660097301\n",
      "训练次数：5770, Loss: 0.0003667071578092873\n",
      "训练次数：5775, Loss: 0.0014413559110835195\n",
      "训练次数：5780, Loss: 0.0004781864117830992\n",
      "训练次数：5785, Loss: 0.0018993271514773369\n",
      "训练次数：5790, Loss: 0.0011498579988256097\n",
      "训练次数：5795, Loss: 0.001333041931502521\n",
      "训练次数：5800, Loss: 0.0005352757289074361\n",
      "训练次数：5805, Loss: 0.008496388792991638\n",
      "第 121 轮训练总体误差值：0.11696828156709671\n",
      "**********开始本轮验证**********\n",
      "第 121 轮训练在整体验证集上的Loss: 0.3701404947787523\n",
      "allen_120.pth 模型已保存\n",
      "--------------------第122轮训练开始----------------------\n",
      "训练次数：5810, Loss: 0.004970833659172058\n",
      "训练次数：5815, Loss: 0.0015777149237692356\n",
      "训练次数：5820, Loss: 0.0010007263626903296\n",
      "训练次数：5825, Loss: 0.0016183541156351566\n",
      "训练次数：5830, Loss: 0.00040162503137253225\n",
      "训练次数：5835, Loss: 0.002269406570121646\n",
      "训练次数：5840, Loss: 0.0005804406246170402\n",
      "训练次数：5845, Loss: 0.00031970260897651315\n",
      "训练次数：5850, Loss: 0.0009580543264746666\n",
      "训练次数：5855, Loss: 0.005219650454819202\n",
      "第 122 轮训练总体误差值：0.10741712152957916\n",
      "**********开始本轮验证**********\n",
      "第 122 轮训练在整体验证集上的Loss: 0.34663742408156395\n",
      "allen_121.pth 模型已保存\n",
      "--------------------第123轮训练开始----------------------\n",
      "训练次数：5860, Loss: 0.003327824641019106\n",
      "训练次数：5865, Loss: 0.006856780964881182\n",
      "训练次数：5870, Loss: 0.001343984855338931\n",
      "训练次数：5875, Loss: 0.0006385244778357446\n",
      "训练次数：5880, Loss: 0.0008779348572716117\n",
      "训练次数：5885, Loss: 0.001284667756408453\n",
      "训练次数：5890, Loss: 0.0006558962631970644\n",
      "训练次数：5895, Loss: 0.0003316147194709629\n",
      "训练次数：5900, Loss: 0.007444911636412144\n",
      "第 123 轮训练总体误差值：0.11499638110399246\n",
      "**********开始本轮验证**********\n",
      "第 123 轮训练在整体验证集上的Loss: 0.4899429362267256\n",
      "allen_122.pth 模型已保存\n",
      "--------------------第124轮训练开始----------------------\n",
      "训练次数：5905, Loss: 0.00606977753341198\n",
      "训练次数：5910, Loss: 0.002429465763270855\n",
      "训练次数：5915, Loss: 0.0012863350566476583\n",
      "训练次数：5920, Loss: 0.00166797055862844\n",
      "训练次数：5925, Loss: 0.0010789795778691769\n",
      "训练次数：5930, Loss: 0.002627398120239377\n",
      "训练次数：5935, Loss: 0.001349341357126832\n",
      "训练次数：5940, Loss: 0.01787624880671501\n",
      "训练次数：5945, Loss: 0.0008448025910183787\n",
      "训练次数：5950, Loss: 0.002206995850428939\n",
      "第 124 轮训练总体误差值：0.21268874406814575\n",
      "**********开始本轮验证**********\n",
      "第 124 轮训练在整体验证集上的Loss: 0.5898378547281027\n",
      "allen_123.pth 模型已保存\n",
      "--------------------第125轮训练开始----------------------\n",
      "训练次数：5955, Loss: 0.029547641053795815\n",
      "训练次数：5960, Loss: 0.018826181069016457\n",
      "训练次数：5965, Loss: 0.00825877208262682\n",
      "训练次数：5970, Loss: 0.017373330891132355\n",
      "训练次数：5975, Loss: 0.0018394545186311007\n",
      "训练次数：5980, Loss: 0.00728173553943634\n",
      "训练次数：5985, Loss: 0.0024750912562012672\n",
      "训练次数：5990, Loss: 0.0009548796806484461\n",
      "训练次数：5995, Loss: 0.0028066018130630255\n",
      "训练次数：6000, Loss: 0.005467230919748545\n",
      "第 125 轮训练总体误差值：0.48307040333747864\n",
      "**********开始本轮验证**********\n",
      "第 125 轮训练在整体验证集上的Loss: 0.5906893191859126\n",
      "allen_124.pth 模型已保存\n",
      "--------------------第126轮训练开始----------------------\n",
      "训练次数：6005, Loss: 0.009619935415685177\n",
      "训练次数：6010, Loss: 0.006516750436276197\n",
      "训练次数：6015, Loss: 0.004427285399287939\n",
      "训练次数：6020, Loss: 0.002402869751676917\n",
      "训练次数：6025, Loss: 0.0009757744846865535\n",
      "训练次数：6030, Loss: 0.0030938605777919292\n",
      "训练次数：6035, Loss: 0.009628680534660816\n",
      "训练次数：6040, Loss: 0.0009086260688491166\n",
      "训练次数：6045, Loss: 0.020447518676519394\n",
      "第 126 轮训练总体误差值：0.2658463418483734\n",
      "**********开始本轮验证**********\n",
      "第 126 轮训练在整体验证集上的Loss: 0.3106593186967075\n",
      "allen_125.pth 模型已保存\n",
      "--------------------第127轮训练开始----------------------\n",
      "训练次数：6050, Loss: 0.007120939902961254\n",
      "训练次数：6055, Loss: 0.0031762360595166683\n",
      "训练次数：6060, Loss: 0.003400135086849332\n",
      "训练次数：6065, Loss: 0.002291186712682247\n",
      "训练次数：6070, Loss: 0.0005115545936860144\n",
      "训练次数：6075, Loss: 0.0038750781677663326\n",
      "训练次数：6080, Loss: 0.00139923847746104\n",
      "训练次数：6085, Loss: 0.00044442981015890837\n",
      "训练次数：6090, Loss: 0.0009829249465838075\n",
      "训练次数：6095, Loss: 0.0024648539256304502\n",
      "第 127 轮训练总体误差值：0.15204736590385437\n",
      "**********开始本轮验证**********\n",
      "第 127 轮训练在整体验证集上的Loss: 0.46132954116910696\n",
      "allen_126.pth 模型已保存\n",
      "--------------------第128轮训练开始----------------------\n",
      "训练次数：6100, Loss: 0.0032469264697283506\n",
      "训练次数：6105, Loss: 0.0119629530236125\n",
      "训练次数：6110, Loss: 0.002341947052627802\n",
      "训练次数：6115, Loss: 0.000920963182579726\n",
      "训练次数：6120, Loss: 0.001845571561716497\n",
      "训练次数：6125, Loss: 0.0015263954410329461\n",
      "训练次数：6130, Loss: 0.0016544212121516466\n",
      "训练次数：6135, Loss: 0.0015123444609344006\n",
      "训练次数：6140, Loss: 0.0020912911277264357\n",
      "第 128 轮训练总体误差值：0.18902422487735748\n",
      "**********开始本轮验证**********\n",
      "第 128 轮训练在整体验证集上的Loss: 0.3908337061293423\n",
      "allen_127.pth 模型已保存\n",
      "--------------------第129轮训练开始----------------------\n",
      "训练次数：6145, Loss: 0.004326957743614912\n",
      "训练次数：6150, Loss: 0.0069894068874418736\n",
      "训练次数：6155, Loss: 0.0017436646157875657\n",
      "训练次数：6160, Loss: 0.0021293528843671083\n",
      "训练次数：6165, Loss: 0.001283444231376052\n",
      "训练次数：6170, Loss: 0.006705298088490963\n",
      "训练次数：6175, Loss: 0.001948685385286808\n",
      "训练次数：6180, Loss: 0.00980795081704855\n",
      "训练次数：6185, Loss: 0.0015126337530091405\n",
      "训练次数：6190, Loss: 0.007111337501555681\n",
      "第 129 轮训练总体误差值：0.18526555597782135\n",
      "**********开始本轮验证**********\n",
      "第 129 轮训练在整体验证集上的Loss: 0.4711242187768221\n",
      "allen_128.pth 模型已保存\n",
      "--------------------第130轮训练开始----------------------\n",
      "训练次数：6195, Loss: 0.008533129468560219\n",
      "训练次数：6200, Loss: 0.005267432890832424\n",
      "训练次数：6205, Loss: 0.003132169833406806\n",
      "训练次数：6210, Loss: 0.011063707992434502\n",
      "训练次数：6215, Loss: 0.006861476693302393\n",
      "训练次数：6220, Loss: 0.025972558185458183\n",
      "训练次数：6225, Loss: 0.002099178032949567\n",
      "训练次数：6230, Loss: 0.0028331701178103685\n",
      "训练次数：6235, Loss: 0.002854785416275263\n",
      "训练次数：6240, Loss: 0.010172845795750618\n",
      "第 130 轮训练总体误差值：0.8979644775390625\n",
      "**********开始本轮验证**********\n",
      "第 130 轮训练在整体验证集上的Loss: 0.5706446822732687\n",
      "allen_129.pth 模型已保存\n",
      "--------------------第131轮训练开始----------------------\n",
      "训练次数：6245, Loss: 0.03004235401749611\n",
      "训练次数：6250, Loss: 0.02703399583697319\n",
      "训练次数：6255, Loss: 0.014411812648177147\n",
      "训练次数：6260, Loss: 0.021073486655950546\n",
      "训练次数：6265, Loss: 0.002648384543135762\n",
      "训练次数：6270, Loss: 0.005993989296257496\n",
      "训练次数：6275, Loss: 0.019894804805517197\n",
      "训练次数：6280, Loss: 0.0024924331810325384\n",
      "训练次数：6285, Loss: 0.07468762248754501\n",
      "第 131 轮训练总体误差值：1.0927634239196777\n",
      "**********开始本轮验证**********\n",
      "第 131 轮训练在整体验证集上的Loss: 0.9430222976952791\n",
      "allen_130.pth 模型已保存\n",
      "--------------------第132轮训练开始----------------------\n",
      "训练次数：6290, Loss: 0.05157191678881645\n",
      "训练次数：6295, Loss: 0.02854325622320175\n",
      "训练次数：6300, Loss: 0.007030450738966465\n",
      "训练次数：6305, Loss: 0.003856376279145479\n",
      "训练次数：6310, Loss: 0.004278871230781078\n",
      "训练次数：6315, Loss: 0.015063316561281681\n",
      "训练次数：6320, Loss: 0.004452807828783989\n",
      "训练次数：6325, Loss: 0.005051697138696909\n",
      "训练次数：6330, Loss: 0.005193479359149933\n",
      "训练次数：6335, Loss: 0.007353403139859438\n",
      "第 132 轮训练总体误差值：0.5677548050880432\n",
      "**********开始本轮验证**********\n",
      "第 132 轮训练在整体验证集上的Loss: 0.452330213971436\n",
      "allen_131.pth 模型已保存\n",
      "--------------------第133轮训练开始----------------------\n",
      "训练次数：6340, Loss: 0.01450537983328104\n",
      "训练次数：6345, Loss: 0.01754090189933777\n",
      "训练次数：6350, Loss: 0.006729194428771734\n",
      "训练次数：6355, Loss: 0.0023615602403879166\n",
      "训练次数：6360, Loss: 0.001183479093015194\n",
      "训练次数：6365, Loss: 0.003409836906939745\n",
      "训练次数：6370, Loss: 0.003960950765758753\n",
      "训练次数：6375, Loss: 0.0014602249721065164\n",
      "训练次数：6380, Loss: 0.0009752996847964823\n",
      "第 133 轮训练总体误差值：0.3564959466457367\n",
      "**********开始本轮验证**********\n",
      "第 133 轮训练在整体验证集上的Loss: 0.5368240233510733\n",
      "allen_132.pth 模型已保存\n",
      "--------------------第134轮训练开始----------------------\n",
      "训练次数：6385, Loss: 0.01692979596555233\n",
      "训练次数：6390, Loss: 0.006562693044543266\n",
      "训练次数：6395, Loss: 0.0006787384627386928\n",
      "训练次数：6400, Loss: 0.004104353953152895\n",
      "训练次数：6405, Loss: 0.0010320113506168127\n",
      "训练次数：6410, Loss: 0.008063613437116146\n",
      "训练次数：6415, Loss: 0.0020912622567266226\n",
      "训练次数：6420, Loss: 0.007477160543203354\n",
      "训练次数：6425, Loss: 0.0005277968593873084\n",
      "训练次数：6430, Loss: 0.023442793637514114\n",
      "第 134 轮训练总体误差值：0.3083800673484802\n",
      "**********开始本轮验证**********\n",
      "第 134 轮训练在整体验证集上的Loss: 0.4207924669608474\n",
      "allen_133.pth 模型已保存\n",
      "--------------------第135轮训练开始----------------------\n",
      "训练次数：6435, Loss: 0.005350104998797178\n",
      "训练次数：6440, Loss: 0.0055902814492583275\n",
      "训练次数：6445, Loss: 0.00315977749414742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：6450, Loss: 0.008253728970885277\n",
      "训练次数：6455, Loss: 0.001283559249714017\n",
      "训练次数：6460, Loss: 0.0011013478506356478\n",
      "训练次数：6465, Loss: 0.0020084045827388763\n",
      "训练次数：6470, Loss: 0.0003492274263408035\n",
      "训练次数：6475, Loss: 0.0012211110442876816\n",
      "训练次数：6480, Loss: 0.011427842080593109\n",
      "第 135 轮训练总体误差值：0.30370402336120605\n",
      "**********开始本轮验证**********\n",
      "第 135 轮训练在整体验证集上的Loss: 0.42618854250758886\n",
      "allen_134.pth 模型已保存\n",
      "--------------------第136轮训练开始----------------------\n",
      "训练次数：6485, Loss: 0.002958348486572504\n",
      "训练次数：6490, Loss: 0.0004082469968125224\n",
      "训练次数：6495, Loss: 0.0022651911713182926\n",
      "训练次数：6500, Loss: 0.0010357638821005821\n",
      "训练次数：6505, Loss: 0.002541925059631467\n",
      "训练次数：6510, Loss: 0.0015119814779609442\n",
      "训练次数：6515, Loss: 0.004770373925566673\n",
      "训练次数：6520, Loss: 0.0005746308015659451\n",
      "训练次数：6525, Loss: 0.02077939361333847\n",
      "第 136 轮训练总体误差值：0.2056720107793808\n",
      "**********开始本轮验证**********\n",
      "第 136 轮训练在整体验证集上的Loss: 0.3726336173713207\n",
      "allen_135.pth 模型已保存\n",
      "--------------------第137轮训练开始----------------------\n",
      "训练次数：6530, Loss: 0.00307792192324996\n",
      "训练次数：6535, Loss: 0.0019882654305547476\n",
      "训练次数：6540, Loss: 0.002029607305303216\n",
      "训练次数：6545, Loss: 0.0016692443750798702\n",
      "训练次数：6550, Loss: 0.0007298424607142806\n",
      "训练次数：6555, Loss: 0.003827647538855672\n",
      "训练次数：6560, Loss: 0.0011084838770329952\n",
      "训练次数：6565, Loss: 0.0002753626031335443\n",
      "训练次数：6570, Loss: 0.0006663647945970297\n",
      "训练次数：6575, Loss: 0.0029003003146499395\n",
      "第 137 轮训练总体误差值：0.11964333057403564\n",
      "**********开始本轮验证**********\n",
      "第 137 轮训练在整体验证集上的Loss: 0.37013561418280005\n",
      "allen_136.pth 模型已保存\n",
      "--------------------第138轮训练开始----------------------\n",
      "训练次数：6580, Loss: 0.003423742251470685\n",
      "训练次数：6585, Loss: 0.007407677359879017\n",
      "训练次数：6590, Loss: 0.0021680020727217197\n",
      "训练次数：6595, Loss: 0.0007353422697633505\n",
      "训练次数：6600, Loss: 0.0006191361462697387\n",
      "训练次数：6605, Loss: 0.0009087712969630957\n",
      "训练次数：6610, Loss: 0.001298967283219099\n",
      "训练次数：6615, Loss: 0.00035795889561995864\n",
      "训练次数：6620, Loss: 0.0007964043179526925\n",
      "第 138 轮训练总体误差值：0.1130288764834404\n",
      "**********开始本轮验证**********\n",
      "第 138 轮训练在整体验证集上的Loss: 0.36387822963297367\n",
      "allen_137.pth 模型已保存\n",
      "--------------------第139轮训练开始----------------------\n",
      "训练次数：6625, Loss: 0.006398471537977457\n",
      "训练次数：6630, Loss: 0.0014297771267592907\n",
      "训练次数：6635, Loss: 0.0011049917666241527\n",
      "训练次数：6640, Loss: 0.0017900681123137474\n",
      "训练次数：6645, Loss: 0.0010241754353046417\n",
      "训练次数：6650, Loss: 0.004391010385006666\n",
      "训练次数：6655, Loss: 0.0006261079688556492\n",
      "训练次数：6660, Loss: 0.006228158716112375\n",
      "训练次数：6665, Loss: 0.00023591856006532907\n",
      "训练次数：6670, Loss: 0.0017438720678910613\n",
      "第 139 轮训练总体误差值：0.09932009875774384\n",
      "**********开始本轮验证**********\n",
      "第 139 轮训练在整体验证集上的Loss: 0.34209275618195534\n",
      "allen_138.pth 模型已保存\n",
      "--------------------第140轮训练开始----------------------\n",
      "训练次数：6675, Loss: 0.002673851093277335\n",
      "训练次数：6680, Loss: 0.008829761296510696\n",
      "训练次数：6685, Loss: 0.001736990176141262\n",
      "训练次数：6690, Loss: 0.011943760327994823\n",
      "训练次数：6695, Loss: 0.0008382979431189597\n",
      "训练次数：6700, Loss: 0.0009402984287589788\n",
      "训练次数：6705, Loss: 0.000549410586245358\n",
      "训练次数：6710, Loss: 0.00035151990596204996\n",
      "训练次数：6715, Loss: 0.0006137752789072692\n",
      "训练次数：6720, Loss: 0.0022749355994164944\n",
      "第 140 轮训练总体误差值：0.09503588825464249\n",
      "**********开始本轮验证**********\n",
      "第 140 轮训练在整体验证集上的Loss: 0.303685097489506\n",
      "allen_139.pth 模型已保存\n",
      "--------------------第141轮训练开始----------------------\n",
      "训练次数：6725, Loss: 0.0009266712586395442\n",
      "训练次数：6730, Loss: 0.002377941273152828\n",
      "训练次数：6735, Loss: 0.0016104205278679729\n",
      "训练次数：6740, Loss: 0.0005003430997021496\n",
      "训练次数：6745, Loss: 0.0008305947412736714\n",
      "训练次数：6750, Loss: 0.0011233622208237648\n",
      "训练次数：6755, Loss: 0.0016009468818083405\n",
      "训练次数：6760, Loss: 0.0004672007926274091\n",
      "训练次数：6765, Loss: 0.0062188198789954185\n",
      "第 141 轮训练总体误差值：0.09454873204231262\n",
      "**********开始本轮验证**********\n",
      "第 141 轮训练在整体验证集上的Loss: 0.3835938600823283\n",
      "allen_140.pth 模型已保存\n",
      "--------------------第142轮训练开始----------------------\n",
      "训练次数：6770, Loss: 0.007169485557824373\n",
      "训练次数：6775, Loss: 0.0032478859648108482\n",
      "训练次数：6780, Loss: 0.001078458153642714\n",
      "训练次数：6785, Loss: 0.00226309965364635\n",
      "训练次数：6790, Loss: 0.0003290819295216352\n",
      "训练次数：6795, Loss: 0.0033871368505060673\n",
      "训练次数：6800, Loss: 0.0012491499073803425\n",
      "训练次数：6805, Loss: 0.000429678795626387\n",
      "训练次数：6810, Loss: 0.0006818742258474231\n",
      "训练次数：6815, Loss: 0.006509336177259684\n",
      "第 142 轮训练总体误差值：0.14060115814208984\n",
      "**********开始本轮验证**********\n",
      "第 142 轮训练在整体验证集上的Loss: 0.39519278379157186\n",
      "allen_141.pth 模型已保存\n",
      "--------------------第143轮训练开始----------------------\n",
      "训练次数：6820, Loss: 0.006640125531703234\n",
      "训练次数：6825, Loss: 0.004365050699561834\n",
      "训练次数：6830, Loss: 0.00134920550044626\n",
      "训练次数：6835, Loss: 0.0010302674490958452\n",
      "训练次数：6840, Loss: 0.0013921164209023118\n",
      "训练次数：6845, Loss: 0.0005978650879114866\n",
      "训练次数：6850, Loss: 0.0009191243443638086\n",
      "训练次数：6855, Loss: 0.00032098309020511806\n",
      "训练次数：6860, Loss: 0.0008191729430109262\n",
      "第 143 轮训练总体误差值：0.16761405766010284\n",
      "**********开始本轮验证**********\n",
      "第 143 轮训练在整体验证集上的Loss: 0.375337696634233\n",
      "allen_142.pth 模型已保存\n",
      "--------------------第144轮训练开始----------------------\n",
      "训练次数：6865, Loss: 0.005204829853028059\n",
      "训练次数：6870, Loss: 0.001953628147020936\n",
      "训练次数：6875, Loss: 0.003325986210256815\n",
      "训练次数：6880, Loss: 0.002137826755642891\n",
      "训练次数：6885, Loss: 0.0006859461427666247\n",
      "训练次数：6890, Loss: 0.005638278089463711\n",
      "训练次数：6895, Loss: 0.0006952997646294534\n",
      "训练次数：6900, Loss: 0.006089384201914072\n",
      "训练次数：6905, Loss: 0.0002697232412174344\n",
      "训练次数：6910, Loss: 0.01728152297437191\n",
      "第 144 轮训练总体误差值：0.15294423699378967\n",
      "**********开始本轮验证**********\n",
      "第 144 轮训练在整体验证集上的Loss: 0.40588031290099025\n",
      "allen_143.pth 模型已保存\n",
      "--------------------第145轮训练开始----------------------\n",
      "训练次数：6915, Loss: 0.008403400890529156\n",
      "训练次数：6920, Loss: 0.010765807703137398\n",
      "训练次数：6925, Loss: 0.001716349390335381\n",
      "训练次数：6930, Loss: 0.004898645915091038\n",
      "训练次数：6935, Loss: 0.000839904067106545\n",
      "训练次数：6940, Loss: 0.001200955593958497\n",
      "训练次数：6945, Loss: 0.0008070656913332641\n",
      "训练次数：6950, Loss: 0.00023685740598011762\n",
      "训练次数：6955, Loss: 0.0008448337321169674\n",
      "训练次数：6960, Loss: 0.006245479453355074\n",
      "第 145 轮训练总体误差值：0.14515617489814758\n",
      "**********开始本轮验证**********\n",
      "第 145 轮训练在整体验证集上的Loss: 0.3422429012134671\n",
      "allen_144.pth 模型已保存\n",
      "--------------------第146轮训练开始----------------------\n",
      "训练次数：6965, Loss: 0.0016170375747606158\n",
      "训练次数：6970, Loss: 0.0019016095902770758\n",
      "训练次数：6975, Loss: 0.000918468227609992\n",
      "训练次数：6980, Loss: 0.00045515631791204214\n",
      "训练次数：6985, Loss: 0.0008974999072961509\n",
      "训练次数：6990, Loss: 0.0014499147655442357\n",
      "训练次数：6995, Loss: 0.0010261913994327188\n",
      "训练次数：7000, Loss: 0.00042724781087599695\n",
      "训练次数：7005, Loss: 0.0056076948530972\n",
      "第 146 轮训练总体误差值：0.0879887118935585\n",
      "**********开始本轮验证**********\n",
      "第 146 轮训练在整体验证集上的Loss: 0.411664973013103\n",
      "allen_145.pth 模型已保存\n",
      "--------------------第147轮训练开始----------------------\n",
      "训练次数：7010, Loss: 0.013178645633161068\n",
      "训练次数：7015, Loss: 0.0021461891010403633\n",
      "训练次数：7020, Loss: 0.0010506997350603342\n",
      "训练次数：7025, Loss: 0.005590915214270353\n",
      "训练次数：7030, Loss: 0.0004055369063280523\n",
      "训练次数：7035, Loss: 0.0035033535677939653\n",
      "训练次数：7040, Loss: 0.0009257792262360454\n",
      "训练次数：7045, Loss: 0.00025424722116440535\n",
      "训练次数：7050, Loss: 0.0006198754417710006\n",
      "训练次数：7055, Loss: 0.0024841956328600645\n",
      "第 147 轮训练总体误差值：0.13269802927970886\n",
      "**********开始本轮验证**********\n",
      "第 147 轮训练在整体验证集上的Loss: 0.3789179567247629\n",
      "allen_146.pth 模型已保存\n",
      "--------------------第148轮训练开始----------------------\n",
      "训练次数：7060, Loss: 0.004665238317102194\n",
      "训练次数：7065, Loss: 0.004363757558166981\n",
      "训练次数：7070, Loss: 0.0023619525600224733\n",
      "训练次数：7075, Loss: 0.0007570498273707926\n",
      "训练次数：7080, Loss: 0.0008430715533904731\n",
      "训练次数：7085, Loss: 0.0009191555436700583\n",
      "训练次数：7090, Loss: 0.0008481508120894432\n",
      "训练次数：7095, Loss: 0.00046993314754217863\n",
      "训练次数：7100, Loss: 0.0005674006533809006\n",
      "第 148 轮训练总体误差值：0.12383811175823212\n",
      "**********开始本轮验证**********\n",
      "第 148 轮训练在整体验证集上的Loss: 0.33414038084447384\n",
      "allen_147.pth 模型已保存\n",
      "--------------------第149轮训练开始----------------------\n",
      "训练次数：7105, Loss: 0.0014859626535326242\n",
      "训练次数：7110, Loss: 0.0007888125837780535\n",
      "训练次数：7115, Loss: 0.0004485812387429178\n",
      "训练次数：7120, Loss: 0.000805071962531656\n",
      "训练次数：7125, Loss: 0.0007666581077501178\n",
      "训练次数：7130, Loss: 0.005787522532045841\n",
      "训练次数：7135, Loss: 0.0005057449452579021\n",
      "训练次数：7140, Loss: 0.004524938762187958\n",
      "训练次数：7145, Loss: 0.00016158411744982004\n",
      "训练次数：7150, Loss: 0.0015390462940558791\n",
      "第 149 轮训练总体误差值：0.06110776960849762\n",
      "**********开始本轮验证**********\n",
      "第 149 轮训练在整体验证集上的Loss: 0.3124255780130625\n",
      "allen_148.pth 模型已保存\n",
      "--------------------第150轮训练开始----------------------\n",
      "训练次数：7155, Loss: 0.0025990281719714403\n",
      "训练次数：7160, Loss: 0.011796941049396992\n",
      "训练次数：7165, Loss: 0.0004967133863829076\n",
      "训练次数：7170, Loss: 0.003615543246269226\n",
      "训练次数：7175, Loss: 0.0005025304853916168\n",
      "训练次数：7180, Loss: 0.000553085352294147\n",
      "训练次数：7185, Loss: 0.00047741722664795816\n",
      "训练次数：7190, Loss: 0.000290235155262053\n",
      "训练次数：7195, Loss: 0.0009299724479205906\n",
      "训练次数：7200, Loss: 0.0008641076274216175\n",
      "第 150 轮训练总体误差值：0.07537520676851273\n",
      "**********开始本轮验证**********\n",
      "第 150 轮训练在整体验证集上的Loss: 0.3414385626092553\n",
      "allen_149.pth 模型已保存\n",
      "--------------------第151轮训练开始----------------------\n",
      "训练次数：7205, Loss: 0.0021771932952106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：7210, Loss: 0.0006995503208599985\n",
      "训练次数：7215, Loss: 0.001440503285266459\n",
      "训练次数：7220, Loss: 0.00018756400095298886\n",
      "训练次数：7225, Loss: 0.002031926764175296\n",
      "训练次数：7230, Loss: 0.0014848068822175264\n",
      "训练次数：7235, Loss: 0.006172554101794958\n",
      "训练次数：7240, Loss: 0.0007107684505172074\n",
      "训练次数：7245, Loss: 0.0034712422639131546\n",
      "第 151 轮训练总体误差值：0.09863672405481339\n",
      "**********开始本轮验证**********\n",
      "第 151 轮训练在整体验证集上的Loss: 0.40998492389917374\n",
      "allen_150.pth 模型已保存\n",
      "--------------------第152轮训练开始----------------------\n",
      "训练次数：7250, Loss: 0.011775145307183266\n",
      "训练次数：7255, Loss: 0.004858416970819235\n",
      "训练次数：7260, Loss: 0.0021598548628389835\n",
      "训练次数：7265, Loss: 0.002646970096975565\n",
      "训练次数：7270, Loss: 0.00046533008571714163\n",
      "训练次数：7275, Loss: 0.00996874738484621\n",
      "训练次数：7280, Loss: 0.0008509663748554885\n",
      "训练次数：7285, Loss: 0.0005384242394939065\n",
      "训练次数：7290, Loss: 0.0016091825673356652\n",
      "训练次数：7295, Loss: 0.003986286465078592\n",
      "第 152 轮训练总体误差值：0.17090274393558502\n",
      "**********开始本轮验证**********\n",
      "第 152 轮训练在整体验证集上的Loss: 0.6191855426877737\n",
      "allen_151.pth 模型已保存\n",
      "--------------------第153轮训练开始----------------------\n",
      "训练次数：7300, Loss: 0.01322096772491932\n",
      "训练次数：7305, Loss: 0.00627021212130785\n",
      "训练次数：7310, Loss: 0.007018433418124914\n",
      "训练次数：7315, Loss: 0.0014281736221164465\n",
      "训练次数：7320, Loss: 0.0012329077580943704\n",
      "训练次数：7325, Loss: 0.0027341279201209545\n",
      "训练次数：7330, Loss: 0.0016544447280466557\n",
      "训练次数：7335, Loss: 0.0007408325327560306\n",
      "训练次数：7340, Loss: 0.0010022309143096209\n",
      "第 153 轮训练总体误差值：0.2780972719192505\n",
      "**********开始本轮验证**********\n",
      "第 153 轮训练在整体验证集上的Loss: 0.3523111464455724\n",
      "allen_152.pth 模型已保存\n",
      "--------------------第154轮训练开始----------------------\n",
      "训练次数：7345, Loss: 0.0033839840907603502\n",
      "训练次数：7350, Loss: 0.0011494081700220704\n",
      "训练次数：7355, Loss: 0.0005623441538773477\n",
      "训练次数：7360, Loss: 0.0010727441404014826\n",
      "训练次数：7365, Loss: 0.0005263447528705001\n",
      "训练次数：7370, Loss: 0.004109371919184923\n",
      "训练次数：7375, Loss: 0.00047089753206819296\n",
      "训练次数：7380, Loss: 0.012329843826591969\n",
      "训练次数：7385, Loss: 0.00027744899853132665\n",
      "训练次数：7390, Loss: 0.008224207907915115\n",
      "第 154 轮训练总体误差值：0.10696916282176971\n",
      "**********开始本轮验证**********\n",
      "第 154 轮训练在整体验证集上的Loss: 0.29619630705565214\n",
      "allen_153.pth 模型已保存\n",
      "--------------------第155轮训练开始----------------------\n",
      "训练次数：7395, Loss: 0.0025544101372361183\n",
      "训练次数：7400, Loss: 0.008912991732358932\n",
      "训练次数：7405, Loss: 0.0007048870902508497\n",
      "训练次数：7410, Loss: 0.0041550262831151485\n",
      "训练次数：7415, Loss: 0.00041013903683051467\n",
      "训练次数：7420, Loss: 0.0009709331206977367\n",
      "训练次数：7425, Loss: 0.000721499091014266\n",
      "训练次数：7430, Loss: 0.0003157285391353071\n",
      "训练次数：7435, Loss: 0.0007832134724594653\n",
      "训练次数：7440, Loss: 0.004959561862051487\n",
      "第 155 轮训练总体误差值：0.09493554383516312\n",
      "**********开始本轮验证**********\n",
      "第 155 轮训练在整体验证集上的Loss: 0.376572591252625\n",
      "allen_154.pth 模型已保存\n",
      "--------------------第156轮训练开始----------------------\n",
      "训练次数：7445, Loss: 0.0013970169238746166\n",
      "训练次数：7450, Loss: 0.002594851655885577\n",
      "训练次数：7455, Loss: 0.0008527657482773066\n",
      "训练次数：7460, Loss: 0.0008207555511035025\n",
      "训练次数：7465, Loss: 0.000659047276712954\n",
      "训练次数：7470, Loss: 0.001560162054374814\n",
      "训练次数：7475, Loss: 0.0013149076839908957\n",
      "训练次数：7480, Loss: 0.00029301963513717055\n",
      "训练次数：7485, Loss: 0.0044738417491316795\n",
      "第 156 轮训练总体误差值：0.0893276184797287\n",
      "**********开始本轮验证**********\n",
      "第 156 轮训练在整体验证集上的Loss: 0.32765456940978765\n",
      "allen_155.pth 模型已保存\n",
      "--------------------第157轮训练开始----------------------\n",
      "训练次数：7490, Loss: 0.0057833995670080185\n",
      "训练次数：7495, Loss: 0.0014780705096200109\n",
      "训练次数：7500, Loss: 0.0010330005316063762\n",
      "训练次数：7505, Loss: 0.001863766461610794\n",
      "训练次数：7510, Loss: 0.0005762368673458695\n",
      "训练次数：7515, Loss: 0.0023064406123012304\n",
      "训练次数：7520, Loss: 0.0007143709226511419\n",
      "训练次数：7525, Loss: 0.0002150051441276446\n",
      "训练次数：7530, Loss: 0.0005490524927154183\n",
      "训练次数：7535, Loss: 0.0017474341439083219\n",
      "第 157 轮训练总体误差值：0.08055777847766876\n",
      "**********开始本轮验证**********\n",
      "第 157 轮训练在整体验证集上的Loss: 0.3452436877414584\n",
      "allen_156.pth 模型已保存\n",
      "--------------------第158轮训练开始----------------------\n",
      "训练次数：7540, Loss: 0.0015301157254725695\n",
      "训练次数：7545, Loss: 0.010928933508694172\n",
      "训练次数：7550, Loss: 0.0009117976878769696\n",
      "训练次数：7555, Loss: 0.0010749847861006856\n",
      "训练次数：7560, Loss: 0.0002855689963325858\n",
      "训练次数：7565, Loss: 0.0005856719217263162\n",
      "训练次数：7570, Loss: 0.0007370022940449417\n",
      "训练次数：7575, Loss: 0.0001802038896130398\n",
      "训练次数：7580, Loss: 0.0003073884581681341\n",
      "第 158 轮训练总体误差值：0.07190334796905518\n",
      "**********开始本轮验证**********\n",
      "第 158 轮训练在整体验证集上的Loss: 0.32017969293519855\n",
      "allen_157.pth 模型已保存\n",
      "--------------------第159轮训练开始----------------------\n",
      "训练次数：7585, Loss: 0.0043746959418058395\n",
      "训练次数：7590, Loss: 0.0008464023703709245\n",
      "训练次数：7595, Loss: 0.0013800219167023897\n",
      "训练次数：7600, Loss: 0.000775350141339004\n",
      "训练次数：7605, Loss: 0.000696946051903069\n",
      "训练次数：7610, Loss: 0.001638121553696692\n",
      "训练次数：7615, Loss: 0.0005784242530353367\n",
      "训练次数：7620, Loss: 0.0017230116063728929\n",
      "训练次数：7625, Loss: 0.00037034443812444806\n",
      "训练次数：7630, Loss: 0.004737551789730787\n",
      "第 159 轮训练总体误差值：0.09796278178691864\n",
      "**********开始本轮验证**********\n",
      "第 159 轮训练在整体验证集上的Loss: 0.34347931668162346\n",
      "allen_158.pth 模型已保存\n",
      "--------------------第160轮训练开始----------------------\n",
      "训练次数：7635, Loss: 0.0014297821326181293\n",
      "训练次数：7640, Loss: 0.004496852867305279\n",
      "训练次数：7645, Loss: 0.00109883735422045\n",
      "训练次数：7650, Loss: 0.009985916316509247\n",
      "训练次数：7655, Loss: 0.000895833654794842\n",
      "训练次数：7660, Loss: 0.00047055823961272836\n",
      "训练次数：7665, Loss: 0.0004513523308560252\n",
      "训练次数：7670, Loss: 0.00018603399803396314\n",
      "训练次数：7675, Loss: 0.0005426660645753145\n",
      "训练次数：7680, Loss: 0.004962326493114233\n",
      "第 160 轮训练总体误差值：0.08249597251415253\n",
      "**********开始本轮验证**********\n",
      "第 160 轮训练在整体验证集上的Loss: 0.316665749065578\n",
      "allen_159.pth 模型已保存\n",
      "--------------------第161轮训练开始----------------------\n",
      "训练次数：7685, Loss: 0.0013203943381085992\n",
      "训练次数：7690, Loss: 0.0007398176821880043\n",
      "训练次数：7695, Loss: 0.0012636815663427114\n",
      "训练次数：7700, Loss: 0.0001710966316750273\n",
      "训练次数：7705, Loss: 0.0016903071664273739\n",
      "训练次数：7710, Loss: 0.0009490406373515725\n",
      "训练次数：7715, Loss: 0.0011320575140416622\n",
      "训练次数：7720, Loss: 0.000497566070407629\n",
      "训练次数：7725, Loss: 0.010730938985943794\n",
      "第 161 轮训练总体误差值：0.10986419767141342\n",
      "**********开始本轮验证**********\n",
      "第 161 轮训练在整体验证集上的Loss: 0.39503591461107135\n",
      "allen_160.pth 模型已保存\n",
      "--------------------第162轮训练开始----------------------\n",
      "训练次数：7730, Loss: 0.005719429813325405\n",
      "训练次数：7735, Loss: 0.003075342858210206\n",
      "训练次数：7740, Loss: 0.0026358782779425383\n",
      "训练次数：7745, Loss: 0.0030259289778769016\n",
      "训练次数：7750, Loss: 0.00032368843676522374\n",
      "训练次数：7755, Loss: 0.0017934329807758331\n",
      "训练次数：7760, Loss: 0.0006576473242603242\n",
      "训练次数：7765, Loss: 0.00026553624775260687\n",
      "训练次数：7770, Loss: 0.000507791293784976\n",
      "训练次数：7775, Loss: 0.010325153358280659\n",
      "第 162 轮训练总体误差值：0.1468544900417328\n",
      "**********开始本轮验证**********\n",
      "第 162 轮训练在整体验证集上的Loss: 0.30974123254418373\n",
      "allen_161.pth 模型已保存\n",
      "--------------------第163轮训练开始----------------------\n",
      "训练次数：7780, Loss: 0.0030341872479766607\n",
      "训练次数：7785, Loss: 0.0040501793846488\n",
      "训练次数：7790, Loss: 0.0008993219817057252\n",
      "训练次数：7795, Loss: 0.0003423585440032184\n",
      "训练次数：7800, Loss: 0.0007969766738824546\n",
      "训练次数：7805, Loss: 0.0012940046144649386\n",
      "训练次数：7810, Loss: 0.0005424541886895895\n",
      "训练次数：7815, Loss: 0.0005315076559782028\n",
      "训练次数：7820, Loss: 0.0007413612329401076\n",
      "第 163 轮训练总体误差值：0.10381732136011124\n",
      "**********开始本轮验证**********\n",
      "第 163 轮训练在整体验证集上的Loss: 0.36399691086262465\n",
      "allen_162.pth 模型已保存\n",
      "--------------------第164轮训练开始----------------------\n",
      "训练次数：7825, Loss: 0.008215188980102539\n",
      "训练次数：7830, Loss: 0.00246042269282043\n",
      "训练次数：7835, Loss: 0.0010652082273736596\n",
      "训练次数：7840, Loss: 0.0009212521836161613\n",
      "训练次数：7845, Loss: 0.0004286662151571363\n",
      "训练次数：7850, Loss: 0.0023103244602680206\n",
      "训练次数：7855, Loss: 0.001185442553833127\n",
      "训练次数：7860, Loss: 0.0019916826859116554\n",
      "训练次数：7865, Loss: 0.0004769696679431945\n",
      "训练次数：7870, Loss: 0.003920439630746841\n",
      "第 164 轮训练总体误差值：0.09808418154716492\n",
      "**********开始本轮验证**********\n",
      "第 164 轮训练在整体验证集上的Loss: 0.320929950568825\n",
      "allen_163.pth 模型已保存\n",
      "--------------------第165轮训练开始----------------------\n",
      "训练次数：7875, Loss: 0.0065258401446044445\n",
      "训练次数：7880, Loss: 0.005647358484566212\n",
      "训练次数：7885, Loss: 0.00317088863812387\n",
      "训练次数：7890, Loss: 0.010050216689705849\n",
      "训练次数：7895, Loss: 0.0010996743803843856\n",
      "训练次数：7900, Loss: 0.0007680237176828086\n",
      "训练次数：7905, Loss: 0.0006080809398554265\n",
      "训练次数：7910, Loss: 0.00040229313890449703\n",
      "训练次数：7915, Loss: 0.001027547288686037\n",
      "训练次数：7920, Loss: 0.0007572750328108668\n",
      "第 165 轮训练总体误差值：0.12446440011262894\n",
      "**********开始本轮验证**********\n",
      "第 165 轮训练在整体验证集上的Loss: 0.4609300624579191\n",
      "allen_164.pth 模型已保存\n",
      "--------------------第166轮训练开始----------------------\n",
      "训练次数：7925, Loss: 0.003994160797446966\n",
      "训练次数：7930, Loss: 0.002647995250299573\n",
      "训练次数：7935, Loss: 0.0063150725327432156\n",
      "训练次数：7940, Loss: 0.0012587463716045022\n",
      "训练次数：7945, Loss: 0.001462289015762508\n",
      "训练次数：7950, Loss: 0.0014670992968603969\n",
      "训练次数：7955, Loss: 0.0008712022681720555\n",
      "训练次数：7960, Loss: 0.0009347021114081144\n",
      "训练次数：7965, Loss: 0.002398086478933692\n",
      "第 166 轮训练总体误差值：0.1806909143924713\n",
      "**********开始本轮验证**********\n",
      "第 166 轮训练在整体验证集上的Loss: 0.35389447771012783\n",
      "allen_165.pth 模型已保存\n",
      "--------------------第167轮训练开始----------------------\n",
      "训练次数：7970, Loss: 0.00645972928032279\n",
      "训练次数：7975, Loss: 0.004096588585525751\n",
      "训练次数：7980, Loss: 0.0036733062006533146\n",
      "训练次数：7985, Loss: 0.0032914644107222557\n",
      "训练次数：7990, Loss: 0.00023178939591161907\n",
      "训练次数：7995, Loss: 0.0020885898265987635\n",
      "训练次数：8000, Loss: 0.0007350615924224257\n",
      "训练次数：8005, Loss: 0.0005096857203170657\n",
      "训练次数：8010, Loss: 0.0007046829559840262\n",
      "训练次数：8015, Loss: 0.0017488792072981596\n",
      "第 167 轮训练总体误差值：0.11398099362850189\n",
      "**********开始本轮验证**********\n",
      "第 167 轮训练在整体验证集上的Loss: 0.3425768679007888\n",
      "allen_166.pth 模型已保存\n",
      "--------------------第168轮训练开始----------------------\n",
      "训练次数：8020, Loss: 0.0012066189665347338\n",
      "训练次数：8025, Loss: 0.006340016145259142\n",
      "训练次数：8030, Loss: 0.000760582450311631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：8035, Loss: 0.0003819771227426827\n",
      "训练次数：8040, Loss: 0.0009149893885478377\n",
      "训练次数：8045, Loss: 0.0011951109627261758\n",
      "训练次数：8050, Loss: 0.0005370978615246713\n",
      "训练次数：8055, Loss: 0.0003482490428723395\n",
      "训练次数：8060, Loss: 0.0002583070599939674\n",
      "第 168 轮训练总体误差值：0.07503701001405716\n",
      "**********开始本轮验证**********\n",
      "第 168 轮训练在整体验证集上的Loss: 0.2906883037649095\n",
      "allen_167.pth 模型已保存\n",
      "--------------------第169轮训练开始----------------------\n",
      "训练次数：8065, Loss: 0.0029474073089659214\n",
      "训练次数：8070, Loss: 0.0008428855799138546\n",
      "训练次数：8075, Loss: 0.0017355340532958508\n",
      "训练次数：8080, Loss: 0.0019087031250819564\n",
      "训练次数：8085, Loss: 0.0008122500730678439\n",
      "训练次数：8090, Loss: 0.0027697826735675335\n",
      "训练次数：8095, Loss: 0.0011919790413230658\n",
      "训练次数：8100, Loss: 0.0013402268523350358\n",
      "训练次数：8105, Loss: 0.0005084191798232496\n",
      "训练次数：8110, Loss: 0.0037097418680787086\n",
      "第 169 轮训练总体误差值：0.0816311463713646\n",
      "**********开始本轮验证**********\n",
      "第 169 轮训练在整体验证集上的Loss: 0.3608875349164009\n",
      "allen_168.pth 模型已保存\n",
      "--------------------第170轮训练开始----------------------\n",
      "训练次数：8115, Loss: 0.006204016972333193\n",
      "训练次数：8120, Loss: 0.0034564181696623564\n",
      "训练次数：8125, Loss: 0.0026539319660514593\n",
      "训练次数：8130, Loss: 0.013853182084858418\n",
      "训练次数：8135, Loss: 0.0010955168399959803\n",
      "训练次数：8140, Loss: 0.0012292461469769478\n",
      "训练次数：8145, Loss: 0.0004074944881722331\n",
      "训练次数：8150, Loss: 0.0005778804770670831\n",
      "训练次数：8155, Loss: 0.0019732520449906588\n",
      "训练次数：8160, Loss: 0.0032309379894286394\n",
      "第 170 轮训练总体误差值：0.1741686761379242\n",
      "**********开始本轮验证**********\n",
      "第 170 轮训练在整体验证集上的Loss: 0.3775571631267667\n",
      "allen_169.pth 模型已保存\n",
      "--------------------第171轮训练开始----------------------\n",
      "训练次数：8165, Loss: 0.004160724580287933\n",
      "训练次数：8170, Loss: 0.0025312169454991817\n",
      "训练次数：8175, Loss: 0.001158879604190588\n",
      "训练次数：8180, Loss: 0.0019079335033893585\n",
      "训练次数：8185, Loss: 0.0013436939334496856\n",
      "训练次数：8190, Loss: 0.0020756633020937443\n",
      "训练次数：8195, Loss: 0.01126894447952509\n",
      "训练次数：8200, Loss: 0.0009000265854410827\n",
      "训练次数：8205, Loss: 0.020916005596518517\n",
      "第 171 轮训练总体误差值：0.17768186330795288\n",
      "**********开始本轮验证**********\n",
      "第 171 轮训练在整体验证集上的Loss: 0.3934196559712291\n",
      "allen_170.pth 模型已保存\n",
      "--------------------第172轮训练开始----------------------\n",
      "训练次数：8210, Loss: 0.0037972882855683565\n",
      "训练次数：8215, Loss: 0.00459564384073019\n",
      "训练次数：8220, Loss: 0.0017930706962943077\n",
      "训练次数：8225, Loss: 0.0022827808279544115\n",
      "训练次数：8230, Loss: 0.0009004139574244618\n",
      "训练次数：8235, Loss: 0.008577930741012096\n",
      "训练次数：8240, Loss: 0.0008827649871818721\n",
      "训练次数：8245, Loss: 0.000808119133580476\n",
      "训练次数：8250, Loss: 0.0024439687840640545\n",
      "训练次数：8255, Loss: 0.005278092809021473\n",
      "第 172 轮训练总体误差值：0.1537659764289856\n",
      "**********开始本轮验证**********\n",
      "第 172 轮训练在整体验证集上的Loss: 0.6018995717167854\n",
      "allen_171.pth 模型已保存\n",
      "--------------------第173轮训练开始----------------------\n",
      "训练次数：8260, Loss: 0.0031637228094041348\n",
      "训练次数：8265, Loss: 0.0073446123860776424\n",
      "训练次数：8270, Loss: 0.005769389681518078\n",
      "训练次数：8275, Loss: 0.0026691355742514133\n",
      "训练次数：8280, Loss: 0.0020701359026134014\n",
      "训练次数：8285, Loss: 0.0008701476035639644\n",
      "训练次数：8290, Loss: 0.001503242296166718\n",
      "训练次数：8295, Loss: 0.0009235000470653176\n",
      "训练次数：8300, Loss: 0.0013121678493916988\n",
      "第 173 轮训练总体误差值：0.22513730823993683\n",
      "**********开始本轮验证**********\n",
      "第 173 轮训练在整体验证集上的Loss: 0.7800861578434706\n",
      "allen_172.pth 模型已保存\n",
      "--------------------第174轮训练开始----------------------\n",
      "训练次数：8305, Loss: 0.05225813761353493\n",
      "训练次数：8310, Loss: 0.031048346310853958\n",
      "训练次数：8315, Loss: 0.00612312275916338\n",
      "训练次数：8320, Loss: 0.013935375027358532\n",
      "训练次数：8325, Loss: 0.002890456933528185\n",
      "训练次数：8330, Loss: 0.026895102113485336\n",
      "训练次数：8335, Loss: 0.0055253892205655575\n",
      "训练次数：8340, Loss: 0.005144992843270302\n",
      "训练次数：8345, Loss: 0.000834522710647434\n",
      "训练次数：8350, Loss: 0.011500409804284573\n",
      "第 174 轮训练总体误差值：0.5939353108406067\n",
      "**********开始本轮验证**********\n",
      "第 174 轮训练在整体验证集上的Loss: 0.6349860839545727\n",
      "allen_173.pth 模型已保存\n",
      "--------------------第175轮训练开始----------------------\n",
      "训练次数：8355, Loss: 0.020319513976573944\n",
      "训练次数：8360, Loss: 0.01591307856142521\n",
      "训练次数：8365, Loss: 0.004881922155618668\n",
      "训练次数：8370, Loss: 0.01265010703355074\n",
      "训练次数：8375, Loss: 0.0009379314142279327\n",
      "训练次数：8380, Loss: 0.0016170430462807417\n",
      "训练次数：8385, Loss: 0.001257172436453402\n",
      "训练次数：8390, Loss: 0.0007195749203674495\n",
      "训练次数：8395, Loss: 0.0018651613499969244\n",
      "训练次数：8400, Loss: 0.004815992899239063\n",
      "第 175 轮训练总体误差值：0.3564820885658264\n",
      "**********开始本轮验证**********\n",
      "第 175 轮训练在整体验证集上的Loss: 0.4626030521467328\n",
      "allen_174.pth 模型已保存\n",
      "--------------------第176轮训练开始----------------------\n",
      "训练次数：8405, Loss: 0.001323224394582212\n",
      "训练次数：8410, Loss: 0.003987129777669907\n",
      "训练次数：8415, Loss: 0.0008310344419442117\n",
      "训练次数：8420, Loss: 0.0026602474972605705\n",
      "训练次数：8425, Loss: 0.001963093178346753\n",
      "训练次数：8430, Loss: 0.001321726362220943\n",
      "训练次数：8435, Loss: 0.003143903100863099\n",
      "训练次数：8440, Loss: 0.00044859552872367203\n",
      "训练次数：8445, Loss: 0.029298201203346252\n",
      "第 176 轮训练总体误差值：0.2094147801399231\n",
      "**********开始本轮验证**********\n",
      "第 176 轮训练在整体验证集上的Loss: 0.3926007645204663\n",
      "allen_175.pth 模型已保存\n",
      "--------------------第177轮训练开始----------------------\n",
      "训练次数：8450, Loss: 0.014081740751862526\n",
      "训练次数：8455, Loss: 0.0020629428327083588\n",
      "训练次数：8460, Loss: 0.0025295342784374952\n",
      "训练次数：8465, Loss: 0.0024931442458182573\n",
      "训练次数：8470, Loss: 0.0015571321127936244\n",
      "训练次数：8475, Loss: 0.002039428800344467\n",
      "训练次数：8480, Loss: 0.0017991987988352776\n",
      "训练次数：8485, Loss: 0.0006088278605602682\n",
      "训练次数：8490, Loss: 0.0006826673052273691\n",
      "训练次数：8495, Loss: 0.005922295618802309\n",
      "第 177 轮训练总体误差值：0.17824719846248627\n",
      "**********开始本轮验证**********\n",
      "第 177 轮训练在整体验证集上的Loss: 0.3330737007781863\n",
      "allen_176.pth 模型已保存\n",
      "--------------------第178轮训练开始----------------------\n",
      "训练次数：8500, Loss: 0.0015521702589467168\n",
      "训练次数：8505, Loss: 0.011677825823426247\n",
      "训练次数：8510, Loss: 0.0010277782566845417\n",
      "训练次数：8515, Loss: 0.0010526080150157213\n",
      "训练次数：8520, Loss: 0.0007647566380910575\n",
      "训练次数：8525, Loss: 0.0009219154599122703\n",
      "训练次数：8530, Loss: 0.0007170385797508061\n",
      "训练次数：8535, Loss: 0.0005116215907037258\n",
      "训练次数：8540, Loss: 0.0005451531615108252\n",
      "第 178 轮训练总体误差值：0.10057693719863892\n",
      "**********开始本轮验证**********\n",
      "第 178 轮训练在整体验证集上的Loss: 0.39472254924476147\n",
      "allen_177.pth 模型已保存\n",
      "--------------------第179轮训练开始----------------------\n",
      "训练次数：8545, Loss: 0.010805939324200153\n",
      "训练次数：8550, Loss: 0.0022757381666451693\n",
      "训练次数：8555, Loss: 0.0021631992422044277\n",
      "训练次数：8560, Loss: 0.0017105493461713195\n",
      "训练次数：8565, Loss: 0.0012673934688791633\n",
      "训练次数：8570, Loss: 0.004640846513211727\n",
      "训练次数：8575, Loss: 0.0015374742215499282\n",
      "训练次数：8580, Loss: 0.006250547710806131\n",
      "训练次数：8585, Loss: 0.0002420445962343365\n",
      "训练次数：8590, Loss: 0.002215426415205002\n",
      "第 179 轮训练总体误差值：0.12598003447055817\n",
      "**********开始本轮验证**********\n",
      "第 179 轮训练在整体验证集上的Loss: 0.2940481984987855\n",
      "allen_178.pth 模型已保存\n",
      "--------------------第180轮训练开始----------------------\n",
      "训练次数：8595, Loss: 0.002730622421950102\n",
      "训练次数：8600, Loss: 0.009125757031142712\n",
      "训练次数：8605, Loss: 0.0013004879001528025\n",
      "训练次数：8610, Loss: 0.004029063507914543\n",
      "训练次数：8615, Loss: 0.0005508075701072812\n",
      "训练次数：8620, Loss: 0.0014273935230448842\n",
      "训练次数：8625, Loss: 0.00045042394776828587\n",
      "训练次数：8630, Loss: 0.00020649198268074542\n",
      "训练次数：8635, Loss: 0.0005083319265395403\n",
      "训练次数：8640, Loss: 0.0010124713880941272\n",
      "第 180 轮训练总体误差值：0.07713419198989868\n",
      "**********开始本轮验证**********\n",
      "第 180 轮训练在整体验证集上的Loss: 0.3700783113017678\n",
      "allen_179.pth 模型已保存\n",
      "--------------------第181轮训练开始----------------------\n",
      "训练次数：8645, Loss: 0.0025895480066537857\n",
      "训练次数：8650, Loss: 0.001873196684755385\n",
      "训练次数：8655, Loss: 0.0019666915759444237\n",
      "训练次数：8660, Loss: 0.0018811197951436043\n",
      "训练次数：8665, Loss: 0.0006691159214824438\n",
      "训练次数：8670, Loss: 0.0021041962318122387\n",
      "训练次数：8675, Loss: 0.0012727041030302644\n",
      "训练次数：8680, Loss: 0.0013203166890889406\n",
      "训练次数：8685, Loss: 0.001865487894974649\n",
      "第 181 轮训练总体误差值：0.10745185613632202\n",
      "**********开始本轮验证**********\n",
      "第 181 轮训练在整体验证集上的Loss: 0.3008499047718942\n",
      "allen_180.pth 模型已保存\n",
      "--------------------第182轮训练开始----------------------\n",
      "训练次数：8690, Loss: 0.002590794814750552\n",
      "训练次数：8695, Loss: 0.0015538365114480257\n",
      "训练次数：8700, Loss: 0.0013600976672023535\n",
      "训练次数：8705, Loss: 0.0014856538036838174\n",
      "训练次数：8710, Loss: 0.0003486023924779147\n",
      "训练次数：8715, Loss: 0.0014145375462248921\n",
      "训练次数：8720, Loss: 0.0009917713468894362\n",
      "训练次数：8725, Loss: 0.00021751734311692417\n",
      "训练次数：8730, Loss: 0.0005324251251295209\n",
      "训练次数：8735, Loss: 0.0010154147166758776\n",
      "第 182 轮训练总体误差值：0.061265598982572556\n",
      "**********开始本轮验证**********\n",
      "第 182 轮训练在整体验证集上的Loss: 0.3026109025813639\n",
      "allen_181.pth 模型已保存\n",
      "--------------------第183轮训练开始----------------------\n",
      "训练次数：8740, Loss: 0.0007097486522980034\n",
      "训练次数：8745, Loss: 0.003262184327468276\n",
      "训练次数：8750, Loss: 0.0010942311491817236\n",
      "训练次数：8755, Loss: 0.0007928925333544612\n",
      "训练次数：8760, Loss: 0.00035027830745093524\n",
      "训练次数：8765, Loss: 0.0013721348950639367\n",
      "训练次数：8770, Loss: 0.000737033027689904\n",
      "训练次数：8775, Loss: 0.0006060869200155139\n",
      "训练次数：8780, Loss: 0.00032831288990564644\n",
      "第 183 轮训练总体误差值：0.06367014348506927\n",
      "**********开始本轮验证**********\n",
      "第 183 轮训练在整体验证集上的Loss: 0.30065309163182974\n",
      "allen_182.pth 模型已保存\n",
      "--------------------第184轮训练开始----------------------\n",
      "训练次数：8785, Loss: 0.001850217580795288\n",
      "训练次数：8790, Loss: 0.0008921525441110134\n",
      "训练次数：8795, Loss: 0.0005917770322412252\n",
      "训练次数：8800, Loss: 0.0011112347710877657\n",
      "训练次数：8805, Loss: 0.0013304564636200666\n",
      "训练次数：8810, Loss: 0.0012233108282089233\n",
      "训练次数：8815, Loss: 0.0010570002486929297\n",
      "训练次数：8820, Loss: 0.002411474008113146\n",
      "训练次数：8825, Loss: 0.0008028226438909769\n",
      "训练次数：8830, Loss: 0.0006334157660603523\n",
      "第 184 轮训练总体误差值：0.08131074160337448\n",
      "**********开始本轮验证**********\n",
      "第 184 轮训练在整体验证集上的Loss: 0.3167823450639844\n",
      "allen_183.pth 模型已保存\n",
      "--------------------第185轮训练开始----------------------\n",
      "训练次数：8835, Loss: 0.0016256788512691855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：8840, Loss: 0.005729372147470713\n",
      "训练次数：8845, Loss: 0.002078983001410961\n",
      "训练次数：8850, Loss: 0.013085177168250084\n",
      "训练次数：8855, Loss: 0.00035237663541920483\n",
      "训练次数：8860, Loss: 0.00037634995533153415\n",
      "训练次数：8865, Loss: 0.0007767626666463912\n",
      "训练次数：8870, Loss: 0.0002654830168467015\n",
      "训练次数：8875, Loss: 0.0005921678384765983\n",
      "训练次数：8880, Loss: 0.0008852581377141178\n",
      "第 185 轮训练总体误差值：0.07475335896015167\n",
      "**********开始本轮验证**********\n",
      "第 185 轮训练在整体验证集上的Loss: 0.3151636943221092\n",
      "allen_184.pth 模型已保存\n",
      "--------------------第186轮训练开始----------------------\n",
      "训练次数：8885, Loss: 0.0009386065066792071\n",
      "训练次数：8890, Loss: 0.0031689757015556097\n",
      "训练次数：8895, Loss: 0.0007710320060141385\n",
      "训练次数：8900, Loss: 0.002967064268887043\n",
      "训练次数：8905, Loss: 0.0010408326052129269\n",
      "训练次数：8910, Loss: 0.0009181365021504462\n",
      "训练次数：8915, Loss: 0.0009313865448348224\n",
      "训练次数：8920, Loss: 0.0006070242379792035\n",
      "训练次数：8925, Loss: 0.002513256622478366\n",
      "第 186 轮训练总体误差值：0.108228899538517\n",
      "**********开始本轮验证**********\n",
      "第 186 轮训练在整体验证集上的Loss: 0.3242114493623376\n",
      "allen_185.pth 模型已保存\n",
      "--------------------第187轮训练开始----------------------\n",
      "训练次数：8930, Loss: 0.0025928309187293053\n",
      "训练次数：8935, Loss: 0.0023958433885127306\n",
      "训练次数：8940, Loss: 0.0012859604321420193\n",
      "训练次数：8945, Loss: 0.002442804863676429\n",
      "训练次数：8950, Loss: 0.0002842303947545588\n",
      "训练次数：8955, Loss: 0.001975890714675188\n",
      "训练次数：8960, Loss: 0.0006946034845896065\n",
      "训练次数：8965, Loss: 0.00025220250245183706\n",
      "训练次数：8970, Loss: 0.0004988102591596544\n",
      "训练次数：8975, Loss: 0.0016288371989503503\n",
      "第 187 轮训练总体误差值：0.089122474193573\n",
      "**********开始本轮验证**********\n",
      "第 187 轮训练在整体验证集上的Loss: 0.3155249450355768\n",
      "allen_186.pth 模型已保存\n",
      "--------------------第188轮训练开始----------------------\n",
      "训练次数：8980, Loss: 0.003658713772892952\n",
      "训练次数：8985, Loss: 0.004724706988781691\n",
      "训练次数：8990, Loss: 0.002281521214172244\n",
      "训练次数：8995, Loss: 0.0009387804311700165\n",
      "训练次数：9000, Loss: 0.001581547548994422\n",
      "训练次数：9005, Loss: 0.0018506873166188598\n",
      "训练次数：9010, Loss: 0.0010287720942869782\n",
      "训练次数：9015, Loss: 0.0005005570128560066\n",
      "训练次数：9020, Loss: 0.0005178711144253612\n",
      "第 188 轮训练总体误差值：0.13690689206123352\n",
      "**********开始本轮验证**********\n",
      "第 188 轮训练在整体验证集上的Loss: 0.37803418189287186\n",
      "allen_187.pth 模型已保存\n",
      "--------------------第189轮训练开始----------------------\n",
      "训练次数：9025, Loss: 0.005651751067489386\n",
      "训练次数：9030, Loss: 0.0026384179946035147\n",
      "训练次数：9035, Loss: 0.002923921449109912\n",
      "训练次数：9040, Loss: 0.0014196470146998763\n",
      "训练次数：9045, Loss: 0.0006295206258073449\n",
      "训练次数：9050, Loss: 0.012090674601495266\n",
      "训练次数：9055, Loss: 0.0025451206602156162\n",
      "训练次数：9060, Loss: 0.0025532334111630917\n",
      "训练次数：9065, Loss: 0.0007615186041221023\n",
      "训练次数：9070, Loss: 0.0037929611280560493\n",
      "第 189 轮训练总体误差值：0.12550362944602966\n",
      "**********开始本轮验证**********\n",
      "第 189 轮训练在整体验证集上的Loss: 0.30671209329739213\n",
      "allen_188.pth 模型已保存\n",
      "--------------------第190轮训练开始----------------------\n",
      "训练次数：9075, Loss: 0.0006300887907855213\n",
      "训练次数：9080, Loss: 0.00196098443120718\n",
      "训练次数：9085, Loss: 0.0019706066232174635\n",
      "训练次数：9090, Loss: 0.0021128400694578886\n",
      "训练次数：9095, Loss: 0.0006545548676513135\n",
      "训练次数：9100, Loss: 0.001119229942560196\n",
      "训练次数：9105, Loss: 0.0006937543512322009\n",
      "训练次数：9110, Loss: 0.0001932171726366505\n",
      "训练次数：9115, Loss: 0.0006498160073533654\n",
      "训练次数：9120, Loss: 0.002897916128858924\n",
      "第 190 轮训练总体误差值：0.07818395644426346\n",
      "**********开始本轮验证**********\n",
      "第 190 轮训练在整体验证集上的Loss: 0.3409434384666383\n",
      "allen_189.pth 模型已保存\n",
      "--------------------第191轮训练开始----------------------\n",
      "训练次数：9125, Loss: 0.0015022015431895852\n",
      "训练次数：9130, Loss: 0.0023240044247359037\n",
      "训练次数：9135, Loss: 0.0018670493736863136\n",
      "训练次数：9140, Loss: 0.002821533242240548\n",
      "训练次数：9145, Loss: 0.0009018700802698731\n",
      "训练次数：9150, Loss: 0.002007006900385022\n",
      "训练次数：9155, Loss: 0.0014975920785218477\n",
      "训练次数：9160, Loss: 0.0003844505990855396\n",
      "训练次数：9165, Loss: 0.003551603527739644\n",
      "第 191 轮训练总体误差值：0.10266852378845215\n",
      "**********开始本轮验证**********\n",
      "第 191 轮训练在整体验证集上的Loss: 0.31693969340994954\n",
      "allen_190.pth 模型已保存\n",
      "--------------------第192轮训练开始----------------------\n",
      "训练次数：9170, Loss: 0.006372124422341585\n",
      "训练次数：9175, Loss: 0.0018032037187367678\n",
      "训练次数：9180, Loss: 0.003187753027305007\n",
      "训练次数：9185, Loss: 0.0018675357569009066\n",
      "训练次数：9190, Loss: 0.002419696655124426\n",
      "训练次数：9195, Loss: 0.0039896732196211815\n",
      "训练次数：9200, Loss: 0.0015308309812098742\n",
      "训练次数：9205, Loss: 0.0003635767207015306\n",
      "训练次数：9210, Loss: 0.0007850995170883834\n",
      "训练次数：9215, Loss: 0.0022528343833982944\n",
      "第 192 轮训练总体误差值：0.10943805426359177\n",
      "**********开始本轮验证**********\n",
      "第 192 轮训练在整体验证集上的Loss: 0.41907076071947813\n",
      "allen_191.pth 模型已保存\n",
      "--------------------第193轮训练开始----------------------\n",
      "训练次数：9220, Loss: 0.004237460438162088\n",
      "训练次数：9225, Loss: 0.0037005646154284477\n",
      "训练次数：9230, Loss: 0.0026699723675847054\n",
      "训练次数：9235, Loss: 0.0007046598475426435\n",
      "训练次数：9240, Loss: 0.0015939746517688036\n",
      "训练次数：9245, Loss: 0.0017625573091208935\n",
      "训练次数：9250, Loss: 0.0013661494012922049\n",
      "训练次数：9255, Loss: 0.0007545349653810263\n",
      "训练次数：9260, Loss: 0.0007297073607333004\n",
      "第 193 轮训练总体误差值：0.1437780112028122\n",
      "**********开始本轮验证**********\n",
      "第 193 轮训练在整体验证集上的Loss: 0.4008743790909648\n",
      "allen_192.pth 模型已保存\n",
      "--------------------第194轮训练开始----------------------\n",
      "训练次数：9265, Loss: 0.012487748637795448\n",
      "训练次数：9270, Loss: 0.0032052225433290005\n",
      "训练次数：9275, Loss: 0.0036802967078983784\n",
      "训练次数：9280, Loss: 0.0014162649167701602\n",
      "训练次数：9285, Loss: 0.0021796023938804865\n",
      "训练次数：9290, Loss: 0.0024097890127450228\n",
      "训练次数：9295, Loss: 0.0008726672385819256\n",
      "训练次数：9300, Loss: 0.0016067191027104855\n",
      "训练次数：9305, Loss: 0.0005295632872730494\n",
      "训练次数：9310, Loss: 0.0037648372817784548\n",
      "第 194 轮训练总体误差值：0.1371394395828247\n",
      "**********开始本轮验证**********\n",
      "第 194 轮训练在整体验证集上的Loss: 0.422403450589627\n",
      "allen_193.pth 模型已保存\n",
      "--------------------第195轮训练开始----------------------\n",
      "训练次数：9315, Loss: 0.009733378887176514\n",
      "训练次数：9320, Loss: 0.022633645683526993\n",
      "训练次数：9325, Loss: 0.002626669593155384\n",
      "训练次数：9330, Loss: 0.0031332008074969053\n",
      "训练次数：9335, Loss: 0.0007138220826163888\n",
      "训练次数：9340, Loss: 0.002618179889395833\n",
      "训练次数：9345, Loss: 0.0005768835544586182\n",
      "训练次数：9350, Loss: 0.000642521888948977\n",
      "训练次数：9355, Loss: 0.0005749432602897286\n",
      "训练次数：9360, Loss: 0.007562506943941116\n",
      "第 195 轮训练总体误差值：0.17929622530937195\n",
      "**********开始本轮验证**********\n",
      "第 195 轮训练在整体验证集上的Loss: 0.35571268759667873\n",
      "allen_194.pth 模型已保存\n",
      "--------------------第196轮训练开始----------------------\n",
      "训练次数：9365, Loss: 0.00129305652808398\n",
      "训练次数：9370, Loss: 0.0023726352956146\n",
      "训练次数：9375, Loss: 0.0011176270199939609\n",
      "训练次数：9380, Loss: 0.0006263337563723326\n",
      "训练次数：9385, Loss: 0.0009286819258704782\n",
      "训练次数：9390, Loss: 0.001190533279441297\n",
      "训练次数：9395, Loss: 0.000470602884888649\n",
      "训练次数：9400, Loss: 0.0007163802511058748\n",
      "训练次数：9405, Loss: 0.011868264526128769\n",
      "第 196 轮训练总体误差值：0.10581473261117935\n",
      "**********开始本轮验证**********\n",
      "第 196 轮训练在整体验证集上的Loss: 0.31659606471657753\n",
      "allen_195.pth 模型已保存\n",
      "--------------------第197轮训练开始----------------------\n",
      "训练次数：9410, Loss: 0.001423580921255052\n",
      "训练次数：9415, Loss: 0.0005663245101459324\n",
      "训练次数：9420, Loss: 0.0030898365657776594\n",
      "训练次数：9425, Loss: 0.0012714944314211607\n",
      "训练次数：9430, Loss: 0.00032133690547198057\n",
      "训练次数：9435, Loss: 0.0007126550772227347\n",
      "训练次数：9440, Loss: 0.0006552838603965938\n",
      "训练次数：9445, Loss: 0.0002573189849499613\n",
      "训练次数：9450, Loss: 0.0005932526546530426\n",
      "训练次数：9455, Loss: 0.008884571492671967\n",
      "第 197 轮训练总体误差值：0.09498205780982971\n",
      "**********开始本轮验证**********\n",
      "第 197 轮训练在整体验证集上的Loss: 0.3854659693315625\n",
      "allen_196.pth 模型已保存\n",
      "--------------------第198轮训练开始----------------------\n",
      "训练次数：9460, Loss: 0.004304166417568922\n",
      "训练次数：9465, Loss: 0.003637830726802349\n",
      "训练次数：9470, Loss: 0.0029292593244463205\n",
      "训练次数：9475, Loss: 0.0014369400450959802\n",
      "训练次数：9480, Loss: 0.0006452525849454105\n",
      "训练次数：9485, Loss: 0.0014877194771543145\n",
      "训练次数：9490, Loss: 0.0006864771130494773\n",
      "训练次数：9495, Loss: 0.0005645665805786848\n",
      "训练次数：9500, Loss: 0.0004996680072508752\n",
      "第 198 轮训练总体误差值：0.12506727874279022\n",
      "**********开始本轮验证**********\n",
      "第 198 轮训练在整体验证集上的Loss: 0.3455835576169193\n",
      "allen_197.pth 模型已保存\n",
      "--------------------第199轮训练开始----------------------\n",
      "训练次数：9505, Loss: 0.007476331666111946\n",
      "训练次数：9510, Loss: 0.0016244229627773166\n",
      "训练次数：9515, Loss: 0.00121718505397439\n",
      "训练次数：9520, Loss: 0.0007406211225315928\n",
      "训练次数：9525, Loss: 0.0005698145250789821\n",
      "训练次数：9530, Loss: 0.0018778915982693434\n",
      "训练次数：9535, Loss: 0.0012451689690351486\n",
      "训练次数：9540, Loss: 0.0018871147185564041\n",
      "训练次数：9545, Loss: 0.0005813692114315927\n",
      "训练次数：9550, Loss: 0.005598601885139942\n",
      "第 199 轮训练总体误差值：0.1349915713071823\n",
      "**********开始本轮验证**********\n",
      "第 199 轮训练在整体验证集上的Loss: 0.3289133762009442\n",
      "allen_198.pth 模型已保存\n",
      "--------------------第200轮训练开始----------------------\n",
      "训练次数：9555, Loss: 0.003272970672696829\n",
      "训练次数：9560, Loss: 0.0017105410806834698\n",
      "训练次数：9565, Loss: 0.0007610663888044655\n",
      "训练次数：9570, Loss: 0.002122854581102729\n",
      "训练次数：9575, Loss: 0.00033036855165846646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：9580, Loss: 0.0008606298360973597\n",
      "训练次数：9585, Loss: 0.0004959225771017373\n",
      "训练次数：9590, Loss: 0.00046818438568152487\n",
      "训练次数：9595, Loss: 0.0013462697388604283\n",
      "训练次数：9600, Loss: 0.002268988173455\n",
      "第 200 轮训练总体误差值：0.08957770466804504\n",
      "**********开始本轮验证**********\n",
      "第 200 轮训练在整体验证集上的Loss: 0.4509219662286341\n",
      "allen_199.pth 模型已保存\n",
      "--------------------第201轮训练开始----------------------\n",
      "训练次数：9605, Loss: 0.001243889913894236\n",
      "训练次数：9610, Loss: 0.0008546683820895851\n",
      "训练次数：9615, Loss: 0.0009199465857818723\n",
      "训练次数：9620, Loss: 0.0011097632814198732\n",
      "训练次数：9625, Loss: 0.0006988641107454896\n",
      "训练次数：9630, Loss: 0.001333323772996664\n",
      "训练次数：9635, Loss: 0.014173018746078014\n",
      "训练次数：9640, Loss: 0.0009518629522062838\n",
      "训练次数：9645, Loss: 0.005252114962786436\n",
      "第 201 轮训练总体误差值：0.10482530295848846\n",
      "**********开始本轮验证**********\n",
      "第 201 轮训练在整体验证集上的Loss: 0.38838653545826674\n",
      "allen_200.pth 模型已保存\n",
      "--------------------第202轮训练开始----------------------\n",
      "训练次数：9650, Loss: 0.01639055460691452\n",
      "训练次数：9655, Loss: 0.005077434703707695\n",
      "训练次数：9660, Loss: 0.0032586329616606236\n",
      "训练次数：9665, Loss: 0.001736211939714849\n",
      "训练次数：9670, Loss: 0.0003477770951576531\n",
      "训练次数：9675, Loss: 0.010130662471055984\n",
      "训练次数：9680, Loss: 0.0010296095861122012\n",
      "训练次数：9685, Loss: 0.0010923431254923344\n",
      "训练次数：9690, Loss: 0.0023400774225592613\n",
      "训练次数：9695, Loss: 0.004234412685036659\n",
      "第 202 轮训练总体误差值：0.1599772572517395\n",
      "**********开始本轮验证**********\n",
      "第 202 轮训练在整体验证集上的Loss: 0.516723201610148\n",
      "allen_201.pth 模型已保存\n",
      "--------------------第203轮训练开始----------------------\n",
      "训练次数：9700, Loss: 0.00867573544383049\n",
      "训练次数：9705, Loss: 0.007791675627231598\n",
      "训练次数：9710, Loss: 0.005418064538389444\n",
      "训练次数：9715, Loss: 0.0028523006476461887\n",
      "训练次数：9720, Loss: 0.0017153118969872594\n",
      "训练次数：9725, Loss: 0.0045660678297281265\n",
      "训练次数：9730, Loss: 0.0012575120199471712\n",
      "训练次数：9735, Loss: 0.001564167207106948\n",
      "训练次数：9740, Loss: 0.0010924662929028273\n",
      "第 203 轮训练总体误差值：0.25308236479759216\n",
      "**********开始本轮验证**********\n",
      "第 203 轮训练在整体验证集上的Loss: 0.4564464297145605\n",
      "allen_202.pth 模型已保存\n",
      "--------------------第204轮训练开始----------------------\n",
      "训练次数：9745, Loss: 0.012639435939490795\n",
      "训练次数：9750, Loss: 0.0033835084177553654\n",
      "训练次数：9755, Loss: 0.002037782222032547\n",
      "训练次数：9760, Loss: 0.0012220988282933831\n",
      "训练次数：9765, Loss: 0.012672345153987408\n",
      "训练次数：9770, Loss: 0.0007213137578219175\n",
      "训练次数：9775, Loss: 0.0016845334321260452\n",
      "训练次数：9780, Loss: 0.0032515169586986303\n",
      "训练次数：9785, Loss: 0.0008233912521973252\n",
      "训练次数：9790, Loss: 0.00758889876306057\n",
      "第 204 轮训练总体误差值：0.229264497756958\n",
      "**********开始本轮验证**********\n",
      "第 204 轮训练在整体验证集上的Loss: 0.2981614558957517\n",
      "allen_203.pth 模型已保存\n",
      "--------------------第205轮训练开始----------------------\n",
      "训练次数：9795, Loss: 0.008684149011969566\n",
      "训练次数：9800, Loss: 0.015093880705535412\n",
      "训练次数：9805, Loss: 0.0032805700320750475\n",
      "训练次数：9810, Loss: 0.007245159242302179\n",
      "训练次数：9815, Loss: 0.0005150397773832083\n",
      "训练次数：9820, Loss: 0.0007240275153890252\n",
      "训练次数：9825, Loss: 0.00146311370190233\n",
      "训练次数：9830, Loss: 0.0005093746003694832\n",
      "训练次数：9835, Loss: 0.0015056945849210024\n",
      "训练次数：9840, Loss: 0.004132064990699291\n",
      "第 205 轮训练总体误差值：0.2174321711063385\n",
      "**********开始本轮验证**********\n",
      "第 205 轮训练在整体验证集上的Loss: 0.4238234804943204\n",
      "allen_204.pth 模型已保存\n",
      "--------------------第206轮训练开始----------------------\n",
      "训练次数：9845, Loss: 0.003429355565458536\n",
      "训练次数：9850, Loss: 0.0014622603775933385\n",
      "训练次数：9855, Loss: 0.0019078338518738747\n",
      "训练次数：9860, Loss: 0.0018962332978844643\n",
      "训练次数：9865, Loss: 0.002262391149997711\n",
      "训练次数：9870, Loss: 0.029493840411305428\n",
      "训练次数：9875, Loss: 0.0015823936555534601\n",
      "训练次数：9880, Loss: 0.00041658084955997765\n",
      "训练次数：9885, Loss: 0.006522998679429293\n",
      "第 206 轮训练总体误差值：0.17106486856937408\n",
      "**********开始本轮验证**********\n",
      "第 206 轮训练在整体验证集上的Loss: 0.32219401421025395\n",
      "allen_205.pth 模型已保存\n",
      "--------------------第207轮训练开始----------------------\n",
      "训练次数：9890, Loss: 0.0221125278621912\n",
      "训练次数：9895, Loss: 0.000747570360545069\n",
      "训练次数：9900, Loss: 0.004654770717024803\n",
      "训练次数：9905, Loss: 0.0016178303631022573\n",
      "训练次数：9910, Loss: 0.005123694892972708\n",
      "训练次数：9915, Loss: 0.005781497340649366\n",
      "训练次数：9920, Loss: 0.0026586519088596106\n",
      "训练次数：9925, Loss: 0.00079865544103086\n",
      "训练次数：9930, Loss: 0.0008211287786252797\n",
      "训练次数：9935, Loss: 0.021082254126667976\n",
      "第 207 轮训练总体误差值：0.3372521698474884\n",
      "**********开始本轮验证**********\n",
      "第 207 轮训练在整体验证集上的Loss: 0.6243322053924203\n",
      "allen_206.pth 模型已保存\n",
      "--------------------第208轮训练开始----------------------\n",
      "训练次数：9940, Loss: 0.003585241036489606\n",
      "训练次数：9945, Loss: 0.021564485505223274\n",
      "训练次数：9950, Loss: 0.0020542764104902744\n",
      "训练次数：9955, Loss: 0.0020563823636621237\n",
      "训练次数：9960, Loss: 0.0012377760140225291\n",
      "训练次数：9965, Loss: 0.0006069177179597318\n",
      "训练次数：9970, Loss: 0.002490865532308817\n",
      "训练次数：9975, Loss: 0.00047717857523821294\n",
      "训练次数：9980, Loss: 0.0004880801134277135\n",
      "第 208 轮训练总体误差值：0.17011290788650513\n",
      "**********开始本轮验证**********\n",
      "第 208 轮训练在整体验证集上的Loss: 0.4747557914815843\n",
      "allen_207.pth 模型已保存\n",
      "--------------------第209轮训练开始----------------------\n",
      "训练次数：9985, Loss: 0.011172366328537464\n",
      "训练次数：9990, Loss: 0.0014005525736138225\n",
      "训练次数：9995, Loss: 0.001754940953105688\n",
      "训练次数：10000, Loss: 0.0005349689745344222\n",
      "训练次数：10005, Loss: 0.0023902091197669506\n",
      "训练次数：10010, Loss: 0.009659085422754288\n",
      "训练次数：10015, Loss: 0.00046865930198691785\n",
      "训练次数：10020, Loss: 0.001473920070566237\n",
      "训练次数：10025, Loss: 0.0003006157639902085\n",
      "训练次数：10030, Loss: 0.005669487174600363\n",
      "第 209 轮训练总体误差值：0.1067846268415451\n",
      "**********开始本轮验证**********\n",
      "第 209 轮训练在整体验证集上的Loss: 0.3413156229071319\n",
      "allen_208.pth 模型已保存\n",
      "--------------------第210轮训练开始----------------------\n",
      "训练次数：10035, Loss: 0.001398727996274829\n",
      "训练次数：10040, Loss: 0.002040949184447527\n",
      "训练次数：10045, Loss: 0.0009905716869980097\n",
      "训练次数：10050, Loss: 0.0018351164180785418\n",
      "训练次数：10055, Loss: 0.0011918599484488368\n",
      "训练次数：10060, Loss: 0.00032828390249051154\n",
      "训练次数：10065, Loss: 0.0005500965635292232\n",
      "训练次数：10070, Loss: 0.00014149890921544284\n",
      "训练次数：10075, Loss: 0.000509277218952775\n",
      "训练次数：10080, Loss: 0.0023711954709142447\n",
      "第 210 轮训练总体误差值：0.08871322125196457\n",
      "**********开始本轮验证**********\n",
      "第 210 轮训练在整体验证集上的Loss: 0.3760213959030807\n",
      "allen_209.pth 模型已保存\n",
      "--------------------第211轮训练开始----------------------\n",
      "训练次数：10085, Loss: 0.002290690317749977\n",
      "训练次数：10090, Loss: 0.0028753350488841534\n",
      "训练次数：10095, Loss: 0.002360935788601637\n",
      "训练次数：10100, Loss: 0.0005915689398534596\n",
      "训练次数：10105, Loss: 0.0026676992420107126\n",
      "训练次数：10110, Loss: 0.0015570655232295394\n",
      "训练次数：10115, Loss: 0.0022295312955975533\n",
      "训练次数：10120, Loss: 0.0009216440375894308\n",
      "训练次数：10125, Loss: 0.00284403539262712\n",
      "第 211 轮训练总体误差值：0.11482436954975128\n",
      "**********开始本轮验证**********\n",
      "第 211 轮训练在整体验证集上的Loss: 0.3610371109098196\n",
      "allen_210.pth 模型已保存\n",
      "--------------------第212轮训练开始----------------------\n",
      "训练次数：10130, Loss: 0.00580638088285923\n",
      "训练次数：10135, Loss: 0.001136490609496832\n",
      "训练次数：10140, Loss: 0.0012775100767612457\n",
      "训练次数：10145, Loss: 0.0029980328399688005\n",
      "训练次数：10150, Loss: 0.00017652321548666805\n",
      "训练次数：10155, Loss: 0.006858822889626026\n",
      "训练次数：10160, Loss: 0.0013315335381776094\n",
      "训练次数：10165, Loss: 0.0005056445952504873\n",
      "训练次数：10170, Loss: 0.0010972245363518596\n",
      "训练次数：10175, Loss: 0.0033632460981607437\n",
      "第 212 轮训练总体误差值：0.11894921958446503\n",
      "**********开始本轮验证**********\n",
      "第 212 轮训练在整体验证集上的Loss: 0.36638440284878016\n",
      "allen_211.pth 模型已保存\n",
      "--------------------第213轮训练开始----------------------\n",
      "训练次数：10180, Loss: 0.0006317084189504385\n",
      "训练次数：10185, Loss: 0.003202942432835698\n",
      "训练次数：10190, Loss: 0.0016001338372007012\n",
      "训练次数：10195, Loss: 0.0003914166009053588\n",
      "训练次数：10200, Loss: 0.00021807814482599497\n",
      "训练次数：10205, Loss: 0.0015212319558486342\n",
      "训练次数：10210, Loss: 0.0010395580902695656\n",
      "训练次数：10215, Loss: 0.00034147335099987686\n",
      "训练次数：10220, Loss: 0.00025030673714354634\n",
      "第 213 轮训练总体误差值：0.07912721484899521\n",
      "**********开始本轮验证**********\n",
      "第 213 轮训练在整体验证集上的Loss: 0.3441951470449567\n",
      "allen_212.pth 模型已保存\n",
      "--------------------第214轮训练开始----------------------\n",
      "训练次数：10225, Loss: 0.004504027310758829\n",
      "训练次数：10230, Loss: 0.0005068102618679404\n",
      "训练次数：10235, Loss: 0.0017296060686931014\n",
      "训练次数：10240, Loss: 0.0011927334126085043\n",
      "训练次数：10245, Loss: 0.0007178880623541772\n",
      "训练次数：10250, Loss: 0.0053106932900846004\n",
      "训练次数：10255, Loss: 0.0011318470351397991\n",
      "训练次数：10260, Loss: 0.008495193906128407\n",
      "训练次数：10265, Loss: 0.0004844016511924565\n",
      "训练次数：10270, Loss: 0.0038598687388002872\n",
      "第 214 轮训练总体误差值：0.10193877667188644\n",
      "**********开始本轮验证**********\n",
      "第 214 轮训练在整体验证集上的Loss: 0.4151151282712817\n",
      "allen_213.pth 模型已保存\n",
      "--------------------第215轮训练开始----------------------\n",
      "训练次数：10275, Loss: 0.004879229702055454\n",
      "训练次数：10280, Loss: 0.011682985350489616\n",
      "训练次数：10285, Loss: 0.003434761893004179\n",
      "训练次数：10290, Loss: 0.0044871121644973755\n",
      "训练次数：10295, Loss: 0.0006609776755794883\n",
      "训练次数：10300, Loss: 0.0007359485607594252\n",
      "训练次数：10305, Loss: 0.0004889584379270673\n",
      "训练次数：10310, Loss: 0.00036807003198191524\n",
      "训练次数：10315, Loss: 0.0003737224033102393\n",
      "训练次数：10320, Loss: 0.002455228939652443\n",
      "第 215 轮训练总体误差值：0.11576269567012787\n",
      "**********开始本轮验证**********\n",
      "第 215 轮训练在整体验证集上的Loss: 0.3229894614778459\n",
      "allen_214.pth 模型已保存\n",
      "--------------------第216轮训练开始----------------------\n",
      "训练次数：10325, Loss: 0.0018636486493051052\n",
      "训练次数：10330, Loss: 0.0004504145181272179\n",
      "训练次数：10335, Loss: 0.0017702409531921148\n",
      "训练次数：10340, Loss: 0.0008120183483697474\n",
      "训练次数：10345, Loss: 0.0007095321197994053\n",
      "训练次数：10350, Loss: 0.0009581728954799473\n",
      "训练次数：10355, Loss: 0.0006571600679308176\n",
      "训练次数：10360, Loss: 0.0005108254263177514\n",
      "训练次数：10365, Loss: 0.0022051127161830664\n",
      "第 216 轮训练总体误差值：0.07105546444654465\n",
      "**********开始本轮验证**********\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 216 轮训练在整体验证集上的Loss: 0.3330738674849272\n",
      "allen_215.pth 模型已保存\n",
      "--------------------第217轮训练开始----------------------\n",
      "训练次数：10370, Loss: 0.0034368466585874557\n",
      "训练次数：10375, Loss: 0.001204445492476225\n",
      "训练次数：10380, Loss: 0.0006495333509519696\n",
      "训练次数：10385, Loss: 0.0010387746151536703\n",
      "训练次数：10390, Loss: 0.0005439277738332748\n",
      "训练次数：10395, Loss: 0.0017749229446053505\n",
      "训练次数：10400, Loss: 0.0005708591779693961\n",
      "训练次数：10405, Loss: 0.00028370655491016805\n",
      "训练次数：10410, Loss: 0.0006336861406452954\n",
      "训练次数：10415, Loss: 0.002052905037999153\n",
      "第 217 轮训练总体误差值：0.06081744283437729\n",
      "**********开始本轮验证**********\n",
      "第 217 轮训练在整体验证集上的Loss: 0.28872245782986283\n",
      "allen_216.pth 模型已保存\n",
      "--------------------第218轮训练开始----------------------\n",
      "训练次数：10420, Loss: 0.0009786415612325072\n",
      "训练次数：10425, Loss: 0.00400531617924571\n",
      "训练次数：10430, Loss: 0.0006238644709810615\n",
      "训练次数：10435, Loss: 0.0005132858059369028\n",
      "训练次数：10440, Loss: 0.0004519220383372158\n",
      "训练次数：10445, Loss: 0.000529549433849752\n",
      "训练次数：10450, Loss: 0.0004133505863137543\n",
      "训练次数：10455, Loss: 0.00013041295460425317\n",
      "训练次数：10460, Loss: 0.0002329409180674702\n",
      "第 218 轮训练总体误差值：0.06333305686712265\n",
      "**********开始本轮验证**********\n",
      "第 218 轮训练在整体验证集上的Loss: 0.3549327561631799\n",
      "allen_217.pth 模型已保存\n",
      "--------------------第219轮训练开始----------------------\n",
      "训练次数：10465, Loss: 0.008023033849895\n",
      "训练次数：10470, Loss: 0.0008390393340960145\n",
      "训练次数：10475, Loss: 0.003367398399859667\n",
      "训练次数：10480, Loss: 0.001636817934922874\n",
      "训练次数：10485, Loss: 0.00058996572624892\n",
      "训练次数：10490, Loss: 0.0018322307150810957\n",
      "训练次数：10495, Loss: 0.0008863406837917864\n",
      "训练次数：10500, Loss: 0.0008270564139820635\n",
      "训练次数：10505, Loss: 0.00016855269495863467\n",
      "训练次数：10510, Loss: 0.0012934019323438406\n",
      "第 219 轮训练总体误差值：0.08438529819250107\n",
      "**********开始本轮验证**********\n",
      "第 219 轮训练在整体验证集上的Loss: 0.28512401785701513\n",
      "allen_218.pth 模型已保存\n",
      "--------------------第220轮训练开始----------------------\n",
      "训练次数：10515, Loss: 0.0010529751889407635\n",
      "训练次数：10520, Loss: 0.0037701509427279234\n",
      "训练次数：10525, Loss: 0.0003495150594972074\n",
      "训练次数：10530, Loss: 0.0026366612873971462\n",
      "训练次数：10535, Loss: 0.0005191507516428828\n",
      "训练次数：10540, Loss: 0.0007475565071217716\n",
      "训练次数：10545, Loss: 0.0006102512707002461\n",
      "训练次数：10550, Loss: 0.00017311125702690333\n",
      "训练次数：10555, Loss: 0.0005569271161220968\n",
      "训练次数：10560, Loss: 0.0007920214557088912\n",
      "第 220 轮训练总体误差值：0.04081672802567482\n",
      "**********开始本轮验证**********\n",
      "第 220 轮训练在整体验证集上的Loss: 0.34954203851521015\n",
      "allen_219.pth 模型已保存\n",
      "--------------------第221轮训练开始----------------------\n",
      "训练次数：10565, Loss: 0.0006820414564572275\n",
      "训练次数：10570, Loss: 0.0006379071855917573\n",
      "训练次数：10575, Loss: 0.0006709304288960993\n",
      "训练次数：10580, Loss: 0.0005245401989668608\n",
      "训练次数：10585, Loss: 0.000911203445866704\n",
      "训练次数：10590, Loss: 0.0010440803598612547\n",
      "训练次数：10595, Loss: 0.0005989335477352142\n",
      "训练次数：10600, Loss: 0.00026269294903613627\n",
      "训练次数：10605, Loss: 0.0006478421855717897\n",
      "第 221 轮训练总体误差值：0.041035063564777374\n",
      "**********开始本轮验证**********\n",
      "第 221 轮训练在整体验证集上的Loss: 0.30077462922781706\n",
      "allen_220.pth 模型已保存\n",
      "--------------------第222轮训练开始----------------------\n",
      "训练次数：10610, Loss: 0.002504755277186632\n",
      "训练次数：10615, Loss: 0.0008020364912226796\n",
      "训练次数：10620, Loss: 0.00044608215102925897\n",
      "训练次数：10625, Loss: 0.0016566888662055135\n",
      "训练次数：10630, Loss: 0.000856532424222678\n",
      "训练次数：10635, Loss: 0.001347723649814725\n",
      "训练次数：10640, Loss: 0.0007035682210698724\n",
      "训练次数：10645, Loss: 0.00014517531963065267\n",
      "训练次数：10650, Loss: 0.0002694845316000283\n",
      "训练次数：10655, Loss: 0.00079939397983253\n",
      "第 222 轮训练总体误差值：0.04402810335159302\n",
      "**********开始本轮验证**********\n",
      "第 222 轮训练在整体验证集上的Loss: 0.3500561201944947\n",
      "allen_221.pth 模型已保存\n",
      "--------------------第223轮训练开始----------------------\n",
      "训练次数：10660, Loss: 0.0013149123406037688\n",
      "训练次数：10665, Loss: 0.0027181922923773527\n",
      "训练次数：10670, Loss: 0.0005570682696998119\n",
      "训练次数：10675, Loss: 0.0020380914211273193\n",
      "训练次数：10680, Loss: 0.0004822515766136348\n",
      "训练次数：10685, Loss: 0.0005495257792063057\n",
      "训练次数：10690, Loss: 0.0008054703939706087\n",
      "训练次数：10695, Loss: 0.00026390538550913334\n",
      "训练次数：10700, Loss: 0.0014510814798995852\n",
      "第 223 轮训练总体误差值：0.060630861669778824\n",
      "**********开始本轮验证**********\n",
      "第 223 轮训练在整体验证集上的Loss: 0.3174750516191125\n",
      "allen_222.pth 模型已保存\n",
      "--------------------第224轮训练开始----------------------\n",
      "训练次数：10705, Loss: 0.0021853302605450153\n",
      "训练次数：10710, Loss: 0.0009183225338347256\n",
      "训练次数：10715, Loss: 0.001983864698559046\n",
      "训练次数：10720, Loss: 0.0004999585216864944\n",
      "训练次数：10725, Loss: 0.0009905900806188583\n",
      "训练次数：10730, Loss: 0.009076224640011787\n",
      "训练次数：10735, Loss: 0.0005516257951967418\n",
      "训练次数：10740, Loss: 0.010942468419671059\n",
      "训练次数：10745, Loss: 0.0002984940947499126\n",
      "训练次数：10750, Loss: 0.004153992049396038\n",
      "第 224 轮训练总体误差值：0.0780629888176918\n",
      "**********开始本轮验证**********\n",
      "第 224 轮训练在整体验证集上的Loss: 0.4015784952789545\n",
      "allen_223.pth 模型已保存\n",
      "--------------------第225轮训练开始----------------------\n",
      "训练次数：10755, Loss: 0.0015169468242675066\n",
      "训练次数：10760, Loss: 0.0009440943249501288\n",
      "训练次数：10765, Loss: 0.001152017037384212\n",
      "训练次数：10770, Loss: 0.0012568566016852856\n",
      "训练次数：10775, Loss: 0.0008087085443548858\n",
      "训练次数：10780, Loss: 0.0003478185972198844\n",
      "训练次数：10785, Loss: 0.0007766627823002636\n",
      "训练次数：10790, Loss: 0.0003931136743631214\n",
      "训练次数：10795, Loss: 0.0005758933257311583\n",
      "训练次数：10800, Loss: 0.004374003037810326\n",
      "第 225 轮训练总体误差值：0.0876258984208107\n",
      "**********开始本轮验证**********\n",
      "第 225 轮训练在整体验证集上的Loss: 0.3082969281822443\n",
      "allen_224.pth 模型已保存\n",
      "--------------------第226轮训练开始----------------------\n",
      "训练次数：10805, Loss: 0.001119509106501937\n",
      "训练次数：10810, Loss: 0.0020971994381397963\n",
      "训练次数：10815, Loss: 0.0011127141769975424\n",
      "训练次数：10820, Loss: 0.0007733170641586185\n",
      "训练次数：10825, Loss: 0.0012154611758887768\n",
      "训练次数：10830, Loss: 0.0009241731022484601\n",
      "训练次数：10835, Loss: 0.0020258715376257896\n",
      "训练次数：10840, Loss: 0.00038570346077904105\n",
      "训练次数：10845, Loss: 0.0026463111862540245\n",
      "第 226 轮训练总体误差值：0.10753870755434036\n",
      "**********开始本轮验证**********\n",
      "第 226 轮训练在整体验证集上的Loss: 0.3843620982952416\n",
      "allen_225.pth 模型已保存\n",
      "--------------------第227轮训练开始----------------------\n",
      "训练次数：10850, Loss: 0.006652689538896084\n",
      "训练次数：10855, Loss: 0.002370069734752178\n",
      "训练次数：10860, Loss: 0.0014915898209437728\n",
      "训练次数：10865, Loss: 0.0019055308075621724\n",
      "训练次数：10870, Loss: 0.000564008834771812\n",
      "训练次数：10875, Loss: 0.0012464890023693442\n",
      "训练次数：10880, Loss: 0.0005191368982195854\n",
      "训练次数：10885, Loss: 0.00028065565857104957\n",
      "训练次数：10890, Loss: 0.0005523815634660423\n",
      "训练次数：10895, Loss: 0.0010219737887382507\n",
      "第 227 轮训练总体误差值：0.08234630525112152\n",
      "**********开始本轮验证**********\n",
      "第 227 轮训练在整体验证集上的Loss: 0.36080928379669785\n",
      "allen_226.pth 模型已保存\n",
      "--------------------第228轮训练开始----------------------\n",
      "训练次数：10900, Loss: 0.0029980388935655355\n",
      "训练次数：10905, Loss: 0.0019141618395224214\n",
      "训练次数：10910, Loss: 0.002800234593451023\n",
      "训练次数：10915, Loss: 0.000577978789806366\n",
      "训练次数：10920, Loss: 0.0008012626203708351\n",
      "训练次数：10925, Loss: 0.0021531537640839815\n",
      "训练次数：10930, Loss: 0.001641258131712675\n",
      "训练次数：10935, Loss: 0.0005647797952406108\n",
      "训练次数：10940, Loss: 0.0003821883292403072\n",
      "第 228 轮训练总体误差值：0.11873716861009598\n",
      "**********开始本轮验证**********\n",
      "第 228 轮训练在整体验证集上的Loss: 0.3452694620937109\n",
      "allen_227.pth 模型已保存\n",
      "--------------------第229轮训练开始----------------------\n",
      "训练次数：10945, Loss: 0.0032414933666586876\n",
      "训练次数：10950, Loss: 0.0006703970138914883\n",
      "训练次数：10955, Loss: 0.0016465741209685802\n",
      "训练次数：10960, Loss: 0.0009611841524019837\n",
      "训练次数：10965, Loss: 0.00022705494484398514\n",
      "训练次数：10970, Loss: 0.002228716854006052\n",
      "训练次数：10975, Loss: 0.0007703240844421089\n",
      "训练次数：10980, Loss: 0.0007215472287498415\n",
      "训练次数：10985, Loss: 0.00043896635179407895\n",
      "训练次数：10990, Loss: 0.0055198585614562035\n",
      "第 229 轮训练总体误差值：0.0651884451508522\n",
      "**********开始本轮验证**********\n",
      "第 229 轮训练在整体验证集上的Loss: 0.33897648798301816\n",
      "allen_228.pth 模型已保存\n",
      "--------------------第230轮训练开始----------------------\n",
      "训练次数：10995, Loss: 0.001197295030578971\n",
      "训练次数：11000, Loss: 0.004594787023961544\n",
      "训练次数：11005, Loss: 0.001761245192028582\n",
      "训练次数：11010, Loss: 0.01484062522649765\n",
      "训练次数：11015, Loss: 0.0002443839912302792\n",
      "训练次数：11020, Loss: 0.0008367100381292403\n",
      "训练次数：11025, Loss: 0.000726724392734468\n",
      "训练次数：11030, Loss: 0.0002051182818831876\n",
      "训练次数：11035, Loss: 0.0004131551249884069\n",
      "训练次数：11040, Loss: 0.005116521380841732\n",
      "第 230 轮训练总体误差值：0.10816818475723267\n",
      "**********开始本轮验证**********\n",
      "第 230 轮训练在整体验证集上的Loss: 0.336523131467402\n",
      "allen_229.pth 模型已保存\n",
      "--------------------第231轮训练开始----------------------\n",
      "训练次数：11045, Loss: 0.0006845517782494426\n",
      "训练次数：11050, Loss: 0.0005659434827975929\n",
      "训练次数：11055, Loss: 0.0012413198128342628\n",
      "训练次数：11060, Loss: 0.0008930396288633347\n",
      "训练次数：11065, Loss: 0.0005766471731476486\n",
      "训练次数：11070, Loss: 0.001517030643299222\n",
      "训练次数：11075, Loss: 0.0005073261563666165\n",
      "训练次数：11080, Loss: 0.00048052475904114544\n",
      "训练次数：11085, Loss: 0.009650439023971558\n",
      "第 231 轮训练总体误差值：0.0784100741147995\n",
      "**********开始本轮验证**********\n",
      "第 231 轮训练在整体验证集上的Loss: 0.3381544826552272\n",
      "allen_230.pth 模型已保存\n",
      "--------------------第232轮训练开始----------------------\n",
      "训练次数：11090, Loss: 0.0045005278661847115\n",
      "训练次数：11095, Loss: 0.0012462206650525331\n",
      "训练次数：11100, Loss: 0.001650617690756917\n",
      "训练次数：11105, Loss: 0.002443075878545642\n",
      "训练次数：11110, Loss: 0.0005320659256540239\n",
      "训练次数：11115, Loss: 0.015550726093351841\n",
      "训练次数：11120, Loss: 0.0009016492404043674\n",
      "训练次数：11125, Loss: 0.00091197231085971\n",
      "训练次数：11130, Loss: 0.0008632085518911481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：11135, Loss: 0.008477789349853992\n",
      "第 232 轮训练总体误差值：0.13231606781482697\n",
      "**********开始本轮验证**********\n",
      "第 232 轮训练在整体验证集上的Loss: 0.3661460718140006\n",
      "allen_231.pth 模型已保存\n",
      "--------------------第233轮训练开始----------------------\n",
      "训练次数：11140, Loss: 0.0035210514906793833\n",
      "训练次数：11145, Loss: 0.006847673561424017\n",
      "训练次数：11150, Loss: 0.0010244203731417656\n",
      "训练次数：11155, Loss: 0.0014286458026617765\n",
      "训练次数：11160, Loss: 0.000354358198819682\n",
      "训练次数：11165, Loss: 0.0007503057131543756\n",
      "训练次数：11170, Loss: 0.0014381574001163244\n",
      "训练次数：11175, Loss: 0.00028183840913698077\n",
      "训练次数：11180, Loss: 0.0004194564535282552\n",
      "第 233 轮训练总体误差值：0.11262994259595871\n",
      "**********开始本轮验证**********\n",
      "第 233 轮训练在整体验证集上的Loss: 0.3578648343682289\n",
      "allen_232.pth 模型已保存\n",
      "--------------------第234轮训练开始----------------------\n",
      "训练次数：11185, Loss: 0.004044694826006889\n",
      "训练次数：11190, Loss: 0.0026964375283569098\n",
      "训练次数：11195, Loss: 0.0010161350946873426\n",
      "训练次数：11200, Loss: 0.0011665733763948083\n",
      "训练次数：11205, Loss: 0.0006853870581835508\n",
      "训练次数：11210, Loss: 0.0031454802956432104\n",
      "训练次数：11215, Loss: 0.0012433112133294344\n",
      "训练次数：11220, Loss: 0.0008218222064897418\n",
      "训练次数：11225, Loss: 0.000360714562702924\n",
      "训练次数：11230, Loss: 0.004041444044560194\n",
      "第 234 轮训练总体误差值：0.08187714219093323\n",
      "**********开始本轮验证**********\n",
      "第 234 轮训练在整体验证集上的Loss: 0.3742220285348594\n",
      "allen_233.pth 模型已保存\n",
      "--------------------第235轮训练开始----------------------\n",
      "训练次数：11235, Loss: 0.015585850924253464\n",
      "训练次数：11240, Loss: 0.005635639186948538\n",
      "训练次数：11245, Loss: 0.0053438409231603146\n",
      "训练次数：11250, Loss: 0.007470961660146713\n",
      "训练次数：11255, Loss: 0.0014421165687963367\n",
      "训练次数：11260, Loss: 0.0025206131394952536\n",
      "训练次数：11265, Loss: 0.0005393372848629951\n",
      "训练次数：11270, Loss: 0.0005760019412264228\n",
      "训练次数：11275, Loss: 0.0007322580786421895\n",
      "训练次数：11280, Loss: 0.0011529100593179464\n",
      "第 235 轮训练总体误差值：0.19058282673358917\n",
      "**********开始本轮验证**********\n",
      "第 235 轮训练在整体验证集上的Loss: 0.44393948186188936\n",
      "allen_234.pth 模型已保存\n",
      "--------------------第236轮训练开始----------------------\n",
      "训练次数：11285, Loss: 0.002099839970469475\n",
      "训练次数：11290, Loss: 0.0020632403902709484\n",
      "训练次数：11295, Loss: 0.0024647240061312914\n",
      "训练次数：11300, Loss: 0.0009222885128110647\n",
      "训练次数：11305, Loss: 0.0020911137107759714\n",
      "训练次数：11310, Loss: 0.0019534833263605833\n",
      "训练次数：11315, Loss: 0.001777789555490017\n",
      "训练次数：11320, Loss: 0.0007448127726092935\n",
      "训练次数：11325, Loss: 0.0031181764788925648\n",
      "第 236 轮训练总体误差值：0.14323878288269043\n",
      "**********开始本轮验证**********\n",
      "第 236 轮训练在整体验证集上的Loss: 0.3057977333664894\n",
      "allen_235.pth 模型已保存\n",
      "--------------------第237轮训练开始----------------------\n",
      "训练次数：11330, Loss: 0.0022046470548957586\n",
      "训练次数：11335, Loss: 0.0019956682808697224\n",
      "训练次数：11340, Loss: 0.0020721512846648693\n",
      "训练次数：11345, Loss: 0.0035751948598772287\n",
      "训练次数：11350, Loss: 0.00043026532512158155\n",
      "训练次数：11355, Loss: 0.0012080762535333633\n",
      "训练次数：11360, Loss: 0.0009966245852410793\n",
      "训练次数：11365, Loss: 0.00029831897700205445\n",
      "训练次数：11370, Loss: 0.0004874061269219965\n",
      "训练次数：11375, Loss: 0.0022204420529305935\n",
      "第 237 轮训练总体误差值：0.06941135227680206\n",
      "**********开始本轮验证**********\n",
      "第 237 轮训练在整体验证集上的Loss: 0.34536789916455746\n",
      "allen_236.pth 模型已保存\n",
      "--------------------第238轮训练开始----------------------\n",
      "训练次数：11380, Loss: 0.001108518335968256\n",
      "训练次数：11385, Loss: 0.0032501714304089546\n",
      "训练次数：11390, Loss: 0.001222218619659543\n",
      "训练次数：11395, Loss: 0.001237719552591443\n",
      "训练次数：11400, Loss: 0.0004927177214995027\n",
      "训练次数：11405, Loss: 0.0011725638760253787\n",
      "训练次数：11410, Loss: 0.0006010181386955082\n",
      "训练次数：11415, Loss: 0.00032595035736449063\n",
      "训练次数：11420, Loss: 0.00018721978995017707\n",
      "第 238 轮训练总体误差值：0.04874330759048462\n",
      "**********开始本轮验证**********\n",
      "第 238 轮训练在整体验证集上的Loss: 0.3697900655679405\n",
      "allen_237.pth 模型已保存\n",
      "--------------------第239轮训练开始----------------------\n",
      "训练次数：11425, Loss: 0.009851649403572083\n",
      "训练次数：11430, Loss: 0.0010493278969079256\n",
      "训练次数：11435, Loss: 0.0016566001577302814\n",
      "训练次数：11440, Loss: 0.0013544891262426972\n",
      "训练次数：11445, Loss: 0.001104768831282854\n",
      "训练次数：11450, Loss: 0.0011255003046244383\n",
      "训练次数：11455, Loss: 0.001160068903118372\n",
      "训练次数：11460, Loss: 0.0007894376176409423\n",
      "训练次数：11465, Loss: 0.0002822844253387302\n",
      "训练次数：11470, Loss: 0.001036553643643856\n",
      "第 239 轮训练总体误差值：0.07244836539030075\n",
      "**********开始本轮验证**********\n",
      "第 239 轮训练在整体验证集上的Loss: 0.3276463677175343\n",
      "allen_238.pth 模型已保存\n",
      "--------------------第240轮训练开始----------------------\n",
      "训练次数：11475, Loss: 0.001858541276305914\n",
      "训练次数：11480, Loss: 0.003594245994463563\n",
      "训练次数：11485, Loss: 0.0005600076401606202\n",
      "训练次数：11490, Loss: 0.004284887574613094\n",
      "训练次数：11495, Loss: 0.0003508075897116214\n",
      "训练次数：11500, Loss: 0.00046451500384137034\n",
      "训练次数：11505, Loss: 0.0003246476117055863\n",
      "训练次数：11510, Loss: 8.938588871387765e-05\n",
      "训练次数：11515, Loss: 0.0003093918494414538\n",
      "训练次数：11520, Loss: 0.0005231950199231505\n",
      "第 240 轮训练总体误差值：0.042542293667793274\n",
      "**********开始本轮验证**********\n",
      "第 240 轮训练在整体验证集上的Loss: 0.31048422027379274\n",
      "allen_239.pth 模型已保存\n",
      "--------------------第241轮训练开始----------------------\n",
      "训练次数：11525, Loss: 0.00020183589367661625\n",
      "训练次数：11530, Loss: 0.002148601459339261\n",
      "训练次数：11535, Loss: 0.0003847646585199982\n",
      "训练次数：11540, Loss: 0.0014184305910021067\n",
      "训练次数：11545, Loss: 0.0003726690774783492\n",
      "训练次数：11550, Loss: 0.0007295522373169661\n",
      "训练次数：11555, Loss: 0.0008506627636961639\n",
      "训练次数：11560, Loss: 0.00023907417198643088\n",
      "训练次数：11565, Loss: 0.000968178384937346\n",
      "第 241 轮训练总体误差值：0.03550124168395996\n",
      "**********开始本轮验证**********\n",
      "第 241 轮训练在整体验证集上的Loss: 0.3665253296494484\n",
      "allen_240.pth 模型已保存\n",
      "--------------------第242轮训练开始----------------------\n",
      "训练次数：11570, Loss: 0.00193323427811265\n",
      "训练次数：11575, Loss: 0.0009976029396057129\n",
      "训练次数：11580, Loss: 0.0007086273981258273\n",
      "训练次数：11585, Loss: 0.001808073022402823\n",
      "训练次数：11590, Loss: 0.0004995099734514952\n",
      "训练次数：11595, Loss: 0.0006773997447453439\n",
      "训练次数：11600, Loss: 0.000583674933295697\n",
      "训练次数：11605, Loss: 0.0002843348775058985\n",
      "训练次数：11610, Loss: 0.00038097143988125026\n",
      "训练次数：11615, Loss: 0.000810554891359061\n",
      "第 242 轮训练总体误差值：0.05926603451371193\n",
      "**********开始本轮验证**********\n",
      "第 242 轮训练在整体验证集上的Loss: 0.30484616896137595\n",
      "allen_241.pth 模型已保存\n",
      "--------------------第243轮训练开始----------------------\n",
      "训练次数：11620, Loss: 0.0008043776615522802\n",
      "训练次数：11625, Loss: 0.0024977766443043947\n",
      "训练次数：11630, Loss: 0.0006045912159606814\n",
      "训练次数：11635, Loss: 0.0007054039742797613\n",
      "训练次数：11640, Loss: 0.00033426700974814594\n",
      "训练次数：11645, Loss: 0.0004131427558604628\n",
      "训练次数：11650, Loss: 0.0006546431104652584\n",
      "训练次数：11655, Loss: 0.00021180421754252166\n",
      "训练次数：11660, Loss: 0.0002450062893331051\n",
      "第 243 轮训练总体误差值：0.03440457582473755\n",
      "**********开始本轮验证**********\n",
      "第 243 轮训练在整体验证集上的Loss: 0.34464024053886533\n",
      "allen_242.pth 模型已保存\n",
      "--------------------第244轮训练开始----------------------\n",
      "训练次数：11665, Loss: 0.002782450057566166\n",
      "训练次数：11670, Loss: 0.0004149294109083712\n",
      "训练次数：11675, Loss: 0.0017036551143974066\n",
      "训练次数：11680, Loss: 0.0004307664348743856\n",
      "训练次数：11685, Loss: 0.00041675884858705103\n",
      "训练次数：11690, Loss: 0.0009043122408911586\n",
      "训练次数：11695, Loss: 0.0004564186674542725\n",
      "训练次数：11700, Loss: 0.00034206468262709677\n",
      "训练次数：11705, Loss: 0.0001017786780721508\n",
      "训练次数：11710, Loss: 0.0022020700853317976\n",
      "第 244 轮训练总体误差值：0.034603193402290344\n",
      "**********开始本轮验证**********\n",
      "第 244 轮训练在整体验证集上的Loss: 0.28640955314040184\n",
      "allen_243.pth 模型已保存\n",
      "--------------------第245轮训练开始----------------------\n",
      "训练次数：11715, Loss: 0.0004913433804176748\n",
      "训练次数：11720, Loss: 0.0010467643151059747\n",
      "训练次数：11725, Loss: 0.0005689428653568029\n",
      "训练次数：11730, Loss: 0.0002591462398413569\n",
      "训练次数：11735, Loss: 0.00021278999338392168\n",
      "训练次数：11740, Loss: 0.0002493817009963095\n",
      "训练次数：11745, Loss: 0.00022124343377072364\n",
      "训练次数：11750, Loss: 9.686341945780441e-05\n",
      "训练次数：11755, Loss: 0.00027252669679000974\n",
      "训练次数：11760, Loss: 0.0012600686168298125\n",
      "第 245 轮训练总体误差值：0.029402801766991615\n",
      "**********开始本轮验证**********\n",
      "第 245 轮训练在整体验证集上的Loss: 0.344652958214283\n",
      "allen_244.pth 模型已保存\n",
      "--------------------第246轮训练开始----------------------\n",
      "训练次数：11765, Loss: 0.00029376865131780505\n",
      "训练次数：11770, Loss: 0.0006353678181767464\n",
      "训练次数：11775, Loss: 0.0004924709210172296\n",
      "训练次数：11780, Loss: 0.00020757973834406585\n",
      "训练次数：11785, Loss: 0.00043437679414637387\n",
      "训练次数：11790, Loss: 0.0005542810540646315\n",
      "训练次数：11795, Loss: 0.0003928604710381478\n",
      "训练次数：11800, Loss: 0.00026715488638728857\n",
      "训练次数：11805, Loss: 0.002717206720262766\n",
      "第 246 轮训练总体误差值：0.03250579908490181\n",
      "**********开始本轮验证**********\n",
      "第 246 轮训练在整体验证集上的Loss: 0.2892760243266821\n",
      "allen_245.pth 模型已保存\n",
      "--------------------第247轮训练开始----------------------\n",
      "训练次数：11810, Loss: 0.002757692476734519\n",
      "训练次数：11815, Loss: 0.000855853664688766\n",
      "训练次数：11820, Loss: 0.001211613416671753\n",
      "训练次数：11825, Loss: 0.0013056447496637702\n",
      "训练次数：11830, Loss: 0.0001168164744740352\n",
      "训练次数：11835, Loss: 0.00037503516068682075\n",
      "训练次数：11840, Loss: 0.000301953696180135\n",
      "训练次数：11845, Loss: 0.0001460501953260973\n",
      "训练次数：11850, Loss: 0.00018349666788708419\n",
      "训练次数：11855, Loss: 0.0029021480586379766\n",
      "第 247 轮训练总体误差值：0.04238951578736305\n",
      "**********开始本轮验证**********\n",
      "第 247 轮训练在整体验证集上的Loss: 0.3590682242065668\n",
      "allen_246.pth 模型已保存\n",
      "--------------------第248轮训练开始----------------------\n",
      "训练次数：11860, Loss: 0.000919641344808042\n",
      "训练次数：11865, Loss: 0.0009032402304001153\n",
      "训练次数：11870, Loss: 0.0009873573435470462\n",
      "训练次数：11875, Loss: 0.000258895568549633\n",
      "训练次数：11880, Loss: 0.0002810372970998287\n",
      "训练次数：11885, Loss: 0.0003852021472994238\n",
      "训练次数：11890, Loss: 0.0004269700439181179\n",
      "训练次数：11895, Loss: 0.00017595847020857036\n",
      "训练次数：11900, Loss: 0.00014782091602683067\n",
      "第 248 轮训练总体误差值：0.042177826166152954\n",
      "**********开始本轮验证**********\n",
      "第 248 轮训练在整体验证集上的Loss: 0.2616411643102765\n",
      "allen_247.pth 模型已保存\n",
      "--------------------第249轮训练开始----------------------\n",
      "训练次数：11905, Loss: 0.0017970842309296131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：11910, Loss: 0.0004893589648418128\n",
      "训练次数：11915, Loss: 0.0004097183118574321\n",
      "训练次数：11920, Loss: 0.000429029343649745\n",
      "训练次数：11925, Loss: 0.000277639803243801\n",
      "训练次数：11930, Loss: 0.0006691092858090997\n",
      "训练次数：11935, Loss: 0.0003332758496981114\n",
      "训练次数：11940, Loss: 0.0006958360318094492\n",
      "训练次数：11945, Loss: 0.0001316941634286195\n",
      "训练次数：11950, Loss: 0.0050122919492423534\n",
      "第 249 轮训练总体误差值：0.03757555037736893\n",
      "**********开始本轮验证**********\n",
      "第 249 轮训练在整体验证集上的Loss: 0.36365557461977005\n",
      "allen_248.pth 模型已保存\n",
      "--------------------第250轮训练开始----------------------\n",
      "训练次数：11955, Loss: 0.0021985219791531563\n",
      "训练次数：11960, Loss: 0.002032554242759943\n",
      "训练次数：11965, Loss: 0.0004519819049164653\n",
      "训练次数：11970, Loss: 0.0008074176148511469\n",
      "训练次数：11975, Loss: 0.00026082046679221094\n",
      "训练次数：11980, Loss: 0.00029476938652805984\n",
      "训练次数：11985, Loss: 0.00034203424002043903\n",
      "训练次数：11990, Loss: 0.00023964649881236255\n",
      "训练次数：11995, Loss: 0.00027304605464451015\n",
      "训练次数：12000, Loss: 0.0038663193117827177\n",
      "第 250 轮训练总体误差值：0.04834433272480965\n",
      "**********开始本轮验证**********\n",
      "第 250 轮训练在整体验证集上的Loss: 0.2601156113669276\n",
      "allen_249.pth 模型已保存\n",
      "--------------------第251轮训练开始----------------------\n",
      "训练次数：12005, Loss: 0.0007017963216640055\n",
      "训练次数：12010, Loss: 0.0005807545385323465\n",
      "训练次数：12015, Loss: 0.000546099676284939\n",
      "训练次数：12020, Loss: 0.00011019690282410011\n",
      "训练次数：12025, Loss: 0.0005126379546709359\n",
      "训练次数：12030, Loss: 0.000588185852393508\n",
      "训练次数：12035, Loss: 0.00031219085212796926\n",
      "训练次数：12040, Loss: 0.0005203197943046689\n",
      "训练次数：12045, Loss: 0.003600700758397579\n",
      "第 251 轮训练总体误差值：0.03989481180906296\n",
      "**********开始本轮验证**********\n",
      "第 251 轮训练在整体验证集上的Loss: 0.370148797519505\n",
      "allen_250.pth 模型已保存\n",
      "--------------------第252轮训练开始----------------------\n",
      "训练次数：12050, Loss: 0.0035195443779230118\n",
      "训练次数：12055, Loss: 0.0005554447416216135\n",
      "训练次数：12060, Loss: 0.00027179066091775894\n",
      "训练次数：12065, Loss: 0.0013252957724034786\n",
      "训练次数：12070, Loss: 0.0001770637754816562\n",
      "训练次数：12075, Loss: 0.0007504003006033599\n",
      "训练次数：12080, Loss: 0.0005041833501309156\n",
      "训练次数：12085, Loss: 0.0003089234232902527\n",
      "训练次数：12090, Loss: 0.0002441885881125927\n",
      "训练次数：12095, Loss: 0.002901744795963168\n",
      "第 252 轮训练总体误差值：0.04710621386766434\n",
      "**********开始本轮验证**********\n",
      "第 252 轮训练在整体验证集上的Loss: 0.2712676636874676\n",
      "allen_251.pth 模型已保存\n",
      "--------------------第253轮训练开始----------------------\n",
      "训练次数：12100, Loss: 0.002188178477808833\n",
      "训练次数：12105, Loss: 0.0013043518410995603\n",
      "训练次数：12110, Loss: 0.0007985919364728034\n",
      "训练次数：12115, Loss: 0.0005389923462644219\n",
      "训练次数：12120, Loss: 0.0003443726454861462\n",
      "训练次数：12125, Loss: 0.0005896146176382899\n",
      "训练次数：12130, Loss: 0.00039162341272458434\n",
      "训练次数：12135, Loss: 0.0001693953963695094\n",
      "训练次数：12140, Loss: 0.00020027703430969268\n",
      "第 253 轮训练总体误差值：0.046103186905384064\n",
      "**********开始本轮验证**********\n",
      "第 253 轮训练在整体验证集上的Loss: 0.386676580645144\n",
      "allen_252.pth 模型已保存\n",
      "--------------------第254轮训练开始----------------------\n",
      "训练次数：12145, Loss: 0.0068672411143779755\n",
      "训练次数：12150, Loss: 0.0008066556765697896\n",
      "训练次数：12155, Loss: 0.0023800856433808804\n",
      "训练次数：12160, Loss: 0.0006254350300878286\n",
      "训练次数：12165, Loss: 0.0006186251412145793\n",
      "训练次数：12170, Loss: 0.0016333431703969836\n",
      "训练次数：12175, Loss: 0.0006193234003148973\n",
      "训练次数：12180, Loss: 0.007703757844865322\n",
      "训练次数：12185, Loss: 0.0007236332749016583\n",
      "训练次数：12190, Loss: 0.003079543821513653\n",
      "第 254 轮训练总体误差值：0.11151613295078278\n",
      "**********开始本轮验证**********\n",
      "第 254 轮训练在整体验证集上的Loss: 0.4200039766728878\n",
      "allen_253.pth 模型已保存\n",
      "--------------------第255轮训练开始----------------------\n",
      "训练次数：12195, Loss: 0.0037719975225627422\n",
      "训练次数：12200, Loss: 0.002025267807766795\n",
      "训练次数：12205, Loss: 0.0017770706908777356\n",
      "训练次数：12210, Loss: 0.0170200876891613\n",
      "训练次数：12215, Loss: 0.0010861922055482864\n",
      "训练次数：12220, Loss: 0.0011153144296258688\n",
      "训练次数：12225, Loss: 0.001145835965871811\n",
      "训练次数：12230, Loss: 0.0008694507414475083\n",
      "训练次数：12235, Loss: 0.00162597990129143\n",
      "训练次数：12240, Loss: 0.007894875481724739\n",
      "第 255 轮训练总体误差值：0.18942177295684814\n",
      "**********开始本轮验证**********\n",
      "第 255 轮训练在整体验证集上的Loss: 0.6885335445404053\n",
      "allen_254.pth 模型已保存\n",
      "--------------------第256轮训练开始----------------------\n",
      "训练次数：12245, Loss: 0.014640551060438156\n",
      "训练次数：12250, Loss: 0.008670185692608356\n",
      "训练次数：12255, Loss: 0.007776065729558468\n",
      "训练次数：12260, Loss: 0.00193570158444345\n",
      "训练次数：12265, Loss: 0.005199263337999582\n",
      "训练次数：12270, Loss: 0.0036712647415697575\n",
      "训练次数：12275, Loss: 0.013149372301995754\n",
      "训练次数：12280, Loss: 0.004732983652502298\n",
      "训练次数：12285, Loss: 0.03209133818745613\n",
      "第 256 轮训练总体误差值：0.44709867238998413\n",
      "**********开始本轮验证**********\n",
      "第 256 轮训练在整体验证集上的Loss: 0.4664404671639204\n",
      "allen_255.pth 模型已保存\n",
      "--------------------第257轮训练开始----------------------\n",
      "训练次数：12290, Loss: 0.012639976106584072\n",
      "训练次数：12295, Loss: 0.0012230848660692573\n",
      "训练次数：12300, Loss: 0.012073276564478874\n",
      "训练次数：12305, Loss: 0.0024875046219676733\n",
      "训练次数：12310, Loss: 0.0009919946314767003\n",
      "训练次数：12315, Loss: 0.0032270094379782677\n",
      "训练次数：12320, Loss: 0.0013573357136920094\n",
      "训练次数：12325, Loss: 0.0010300505673512816\n",
      "训练次数：12330, Loss: 0.0014237043214961886\n",
      "训练次数：12335, Loss: 0.004645306617021561\n",
      "第 257 轮训练总体误差值：0.2244560867547989\n",
      "**********开始本轮验证**********\n",
      "第 257 轮训练在整体验证集上的Loss: 0.4242612076923251\n",
      "allen_256.pth 模型已保存\n",
      "--------------------第258轮训练开始----------------------\n",
      "训练次数：12340, Loss: 0.008687617257237434\n",
      "训练次数：12345, Loss: 0.008590436540544033\n",
      "训练次数：12350, Loss: 0.0029183963779360056\n",
      "训练次数：12355, Loss: 0.0007607481093145907\n",
      "训练次数：12360, Loss: 0.0027476304676383734\n",
      "训练次数：12365, Loss: 0.0012185786617919803\n",
      "训练次数：12370, Loss: 0.0031039088498800993\n",
      "训练次数：12375, Loss: 0.0006516866851598024\n",
      "训练次数：12380, Loss: 0.0008942537824623287\n",
      "第 258 轮训练总体误差值：0.22149987518787384\n",
      "**********开始本轮验证**********\n",
      "第 258 轮训练在整体验证集上的Loss: 0.5347864832729101\n",
      "allen_257.pth 模型已保存\n",
      "--------------------第259轮训练开始----------------------\n",
      "训练次数：12385, Loss: 0.013005582615733147\n",
      "训练次数：12390, Loss: 0.006212545558810234\n",
      "训练次数：12395, Loss: 0.004331340081989765\n",
      "训练次数：12400, Loss: 0.0029172233771532774\n",
      "训练次数：12405, Loss: 0.001019334769807756\n",
      "训练次数：12410, Loss: 0.017961829900741577\n",
      "训练次数：12415, Loss: 0.0012074753176420927\n",
      "训练次数：12420, Loss: 0.0052864691242575645\n",
      "训练次数：12425, Loss: 0.0002656568249221891\n",
      "训练次数：12430, Loss: 0.0016455290606245399\n",
      "第 259 轮训练总体误差值：0.18068502843379974\n",
      "**********开始本轮验证**********\n",
      "第 259 轮训练在整体验证集上的Loss: 0.3125265510752797\n",
      "allen_258.pth 模型已保存\n",
      "--------------------第260轮训练开始----------------------\n",
      "训练次数：12435, Loss: 0.001139685045927763\n",
      "训练次数：12440, Loss: 0.0024791124742478132\n",
      "训练次数：12445, Loss: 0.0011345166712999344\n",
      "训练次数：12450, Loss: 0.004422476049512625\n",
      "训练次数：12455, Loss: 0.00038913454045541584\n",
      "训练次数：12460, Loss: 0.0005078795365989208\n",
      "训练次数：12465, Loss: 0.0005663612973876297\n",
      "训练次数：12470, Loss: 0.0003781492414418608\n",
      "训练次数：12475, Loss: 0.00046912248944863677\n",
      "训练次数：12480, Loss: 0.001642158953472972\n",
      "第 260 轮训练总体误差值：0.08964619785547256\n",
      "**********开始本轮验证**********\n",
      "第 260 轮训练在整体验证集上的Loss: 0.2938519613817334\n",
      "allen_259.pth 模型已保存\n",
      "--------------------第261轮训练开始----------------------\n",
      "训练次数：12485, Loss: 0.0016681184060871601\n",
      "训练次数：12490, Loss: 0.0012206266401335597\n",
      "训练次数：12495, Loss: 0.0010733581148087978\n",
      "训练次数：12500, Loss: 0.0006971111288294196\n",
      "训练次数：12505, Loss: 0.0005039856769144535\n",
      "训练次数：12510, Loss: 0.001384476781822741\n",
      "训练次数：12515, Loss: 0.005660246126353741\n",
      "训练次数：12520, Loss: 0.000851634016726166\n",
      "训练次数：12525, Loss: 0.013056088238954544\n",
      "第 261 轮训练总体误差值：0.09634894877672195\n",
      "**********开始本轮验证**********\n",
      "第 261 轮训练在整体验证集上的Loss: 0.3385110218077898\n",
      "allen_260.pth 模型已保存\n",
      "--------------------第262轮训练开始----------------------\n",
      "训练次数：12530, Loss: 0.0019806909840554\n",
      "训练次数：12535, Loss: 0.0007117254426702857\n",
      "训练次数：12540, Loss: 0.0006135987350717187\n",
      "训练次数：12545, Loss: 0.001256234711036086\n",
      "训练次数：12550, Loss: 0.0007034667651169002\n",
      "训练次数：12555, Loss: 0.0015941888559609652\n",
      "训练次数：12560, Loss: 0.0016424470813944936\n",
      "训练次数：12565, Loss: 0.0004520358925219625\n",
      "训练次数：12570, Loss: 0.005058714654296637\n",
      "训练次数：12575, Loss: 0.001109396223910153\n",
      "第 262 轮训练总体误差值：0.15143215656280518\n",
      "**********开始本轮验证**********\n",
      "第 262 轮训练在整体验证集上的Loss: 0.4354523690417409\n",
      "allen_261.pth 模型已保存\n",
      "--------------------第263轮训练开始----------------------\n",
      "训练次数：12580, Loss: 0.0014647296629846096\n",
      "训练次数：12585, Loss: 0.016073133796453476\n",
      "训练次数：12590, Loss: 0.0005507965106517076\n",
      "训练次数：12595, Loss: 0.0011348244734108448\n",
      "训练次数：12600, Loss: 0.001082485425285995\n",
      "训练次数：12605, Loss: 0.0020814277231693268\n",
      "训练次数：12610, Loss: 0.0014121101703494787\n",
      "训练次数：12615, Loss: 0.00043361674761399627\n",
      "训练次数：12620, Loss: 0.0010213337372988462\n",
      "第 263 轮训练总体误差值：0.11582478135824203\n",
      "**********开始本轮验证**********\n",
      "第 263 轮训练在整体验证集上的Loss: 0.563447062857449\n",
      "allen_262.pth 模型已保存\n",
      "--------------------第264轮训练开始----------------------\n",
      "训练次数：12625, Loss: 0.015293395146727562\n",
      "训练次数：12630, Loss: 0.004488363862037659\n",
      "训练次数：12635, Loss: 0.004193586762994528\n",
      "训练次数：12640, Loss: 0.0035378928296267986\n",
      "训练次数：12645, Loss: 0.002328281057998538\n",
      "训练次数：12650, Loss: 0.008328501135110855\n",
      "训练次数：12655, Loss: 0.0014256618451327085\n",
      "训练次数：12660, Loss: 0.0036657797172665596\n",
      "训练次数：12665, Loss: 0.0004459545889403671\n",
      "训练次数：12670, Loss: 0.008784729987382889\n",
      "第 264 轮训练总体误差值：0.1986583173274994\n",
      "**********开始本轮验证**********\n",
      "第 264 轮训练在整体验证集上的Loss: 0.6042003398761153\n",
      "allen_263.pth 模型已保存\n",
      "--------------------第265轮训练开始----------------------\n",
      "训练次数：12675, Loss: 0.04954339191317558\n",
      "训练次数：12680, Loss: 0.011553443036973476\n",
      "训练次数：12685, Loss: 0.007053283508867025\n",
      "训练次数：12690, Loss: 0.028784416615962982\n",
      "训练次数：12695, Loss: 0.0035558422096073627\n",
      "训练次数：12700, Loss: 0.0011221757158637047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：12705, Loss: 0.0031882417388260365\n",
      "训练次数：12710, Loss: 0.0008724221843294799\n",
      "训练次数：12715, Loss: 0.0011499184183776379\n",
      "训练次数：12720, Loss: 0.003946262877434492\n",
      "第 265 轮训练总体误差值：0.5246611833572388\n",
      "**********开始本轮验证**********\n",
      "第 265 轮训练在整体验证集上的Loss: 0.4991957852616906\n",
      "allen_264.pth 模型已保存\n",
      "--------------------第266轮训练开始----------------------\n",
      "训练次数：12725, Loss: 0.006910592317581177\n",
      "训练次数：12730, Loss: 0.002118044998496771\n",
      "训练次数：12735, Loss: 0.003277956508100033\n",
      "训练次数：12740, Loss: 0.0018570544198155403\n",
      "训练次数：12745, Loss: 0.0009744252893142402\n",
      "训练次数：12750, Loss: 0.001427407143637538\n",
      "训练次数：12755, Loss: 0.0028831514064222574\n",
      "训练次数：12760, Loss: 0.0005657116998918355\n",
      "训练次数：12765, Loss: 0.0024204112123697996\n",
      "第 266 轮训练总体误差值：0.19002944231033325\n",
      "**********开始本轮验证**********\n",
      "第 266 轮训练在整体验证集上的Loss: 0.410663740709424\n",
      "allen_265.pth 模型已保存\n",
      "--------------------第267轮训练开始----------------------\n",
      "训练次数：12770, Loss: 0.009436351247131824\n",
      "训练次数：12775, Loss: 0.0008125055464915931\n",
      "训练次数：12780, Loss: 0.0011538821272552013\n",
      "训练次数：12785, Loss: 0.0014091476332396269\n",
      "训练次数：12790, Loss: 0.0005970196216367185\n",
      "训练次数：12795, Loss: 0.0031178488861769438\n",
      "训练次数：12800, Loss: 0.0012039258144795895\n",
      "训练次数：12805, Loss: 0.0007258520345203578\n",
      "训练次数：12810, Loss: 0.00046783394645899534\n",
      "训练次数：12815, Loss: 0.002814051927998662\n",
      "第 267 轮训练总体误差值：0.10702495276927948\n",
      "**********开始本轮验证**********\n",
      "第 267 轮训练在整体验证集上的Loss: 0.44083242397755384\n",
      "allen_266.pth 模型已保存\n",
      "--------------------第268轮训练开始----------------------\n",
      "训练次数：12820, Loss: 0.0035007582046091557\n",
      "训练次数：12825, Loss: 0.002169440034776926\n",
      "训练次数：12830, Loss: 0.000984324375167489\n",
      "训练次数：12835, Loss: 0.0008562930743210018\n",
      "训练次数：12840, Loss: 0.0006223744712769985\n",
      "训练次数：12845, Loss: 0.00038225078606046736\n",
      "训练次数：12850, Loss: 0.0008232283289544284\n",
      "训练次数：12855, Loss: 0.00029176726820878685\n",
      "训练次数：12860, Loss: 0.0003968240926042199\n",
      "第 268 轮训练总体误差值：0.07830464094877243\n",
      "**********开始本轮验证**********\n",
      "第 268 轮训练在整体验证集上的Loss: 0.3329093009233475\n",
      "allen_267.pth 模型已保存\n",
      "--------------------第269轮训练开始----------------------\n",
      "训练次数：12865, Loss: 0.0023852006997913122\n",
      "训练次数：12870, Loss: 0.0010798678267747164\n",
      "训练次数：12875, Loss: 0.0009532657568342984\n",
      "训练次数：12880, Loss: 0.0012407925678417087\n",
      "训练次数：12885, Loss: 0.0004461497301235795\n",
      "训练次数：12890, Loss: 0.014363621361553669\n",
      "训练次数：12895, Loss: 0.0010392419062554836\n",
      "训练次数：12900, Loss: 0.0021099247969686985\n",
      "训练次数：12905, Loss: 0.00015293604519683868\n",
      "训练次数：12910, Loss: 0.0032625445164740086\n",
      "第 269 轮训练总体误差值：0.0675370991230011\n",
      "**********开始本轮验证**********\n",
      "第 269 轮训练在整体验证集上的Loss: 0.3892065496183932\n",
      "allen_268.pth 模型已保存\n",
      "--------------------第270轮训练开始----------------------\n",
      "训练次数：12915, Loss: 0.0023003786336630583\n",
      "训练次数：12920, Loss: 0.0016441240441054106\n",
      "训练次数：12925, Loss: 0.0011123594595119357\n",
      "训练次数：12930, Loss: 0.0017543414141982794\n",
      "训练次数：12935, Loss: 0.0006535962456837296\n",
      "训练次数：12940, Loss: 0.0011670946842059493\n",
      "训练次数：12945, Loss: 0.0007893388974480331\n",
      "训练次数：12950, Loss: 0.0002091139176627621\n",
      "训练次数：12955, Loss: 0.00048600544687360525\n",
      "训练次数：12960, Loss: 0.0017592629883438349\n",
      "第 270 轮训练总体误差值：0.0790109634399414\n",
      "**********开始本轮验证**********\n",
      "第 270 轮训练在整体验证集上的Loss: 0.3181998850777745\n",
      "allen_269.pth 模型已保存\n",
      "--------------------第271轮训练开始----------------------\n",
      "训练次数：12965, Loss: 0.00032608944457024336\n",
      "训练次数：12970, Loss: 0.0006751069449819624\n",
      "训练次数：12975, Loss: 0.00034096086164936423\n",
      "训练次数：12980, Loss: 0.0005479996907524765\n",
      "训练次数：12985, Loss: 0.00043928885133937\n",
      "训练次数：12990, Loss: 0.000649487366899848\n",
      "训练次数：12995, Loss: 0.0009813446085900068\n",
      "训练次数：13000, Loss: 0.0002889615425374359\n",
      "训练次数：13005, Loss: 0.0012782131088897586\n",
      "第 271 轮训练总体误差值：0.03404577076435089\n",
      "**********开始本轮验证**********\n",
      "第 271 轮训练在整体验证集上的Loss: 0.3545753564685583\n",
      "allen_270.pth 模型已保存\n",
      "--------------------第272轮训练开始----------------------\n",
      "训练次数：13010, Loss: 0.002765998477116227\n",
      "训练次数：13015, Loss: 0.0007236875826492906\n",
      "训练次数：13020, Loss: 0.00036921873106621206\n",
      "训练次数：13025, Loss: 0.0012569744139909744\n",
      "训练次数：13030, Loss: 0.0006091190734878182\n",
      "训练次数：13035, Loss: 0.0003803329891525209\n",
      "训练次数：13040, Loss: 0.0004901798674836755\n",
      "训练次数：13045, Loss: 0.00020092415797989815\n",
      "训练次数：13050, Loss: 0.0002597154234535992\n",
      "训练次数：13055, Loss: 0.0011143283918499947\n",
      "第 272 轮训练总体误差值：0.048992231488227844\n",
      "**********开始本轮验证**********\n",
      "第 272 轮训练在整体验证集上的Loss: 0.3103704429231584\n",
      "allen_271.pth 模型已保存\n",
      "--------------------第273轮训练开始----------------------\n",
      "训练次数：13060, Loss: 0.0005401438102126122\n",
      "训练次数：13065, Loss: 0.001132104080170393\n",
      "训练次数：13070, Loss: 0.00014761363854631782\n",
      "训练次数：13075, Loss: 0.00048216083087027073\n",
      "训练次数：13080, Loss: 0.00036435789661481977\n",
      "训练次数：13085, Loss: 0.0003249055880587548\n",
      "训练次数：13090, Loss: 0.000518015818670392\n",
      "训练次数：13095, Loss: 0.00026096051442436874\n",
      "训练次数：13100, Loss: 0.0006298578809946775\n",
      "第 273 轮训练总体误差值：0.05700708553195\n",
      "**********开始本轮验证**********\n",
      "第 273 轮训练在整体验证集上的Loss: 0.3617782895453274\n",
      "allen_272.pth 模型已保存\n",
      "--------------------第274轮训练开始----------------------\n",
      "训练次数：13105, Loss: 0.0023524691350758076\n",
      "训练次数：13110, Loss: 0.0007112945895642042\n",
      "训练次数：13115, Loss: 0.0011514911893755198\n",
      "训练次数：13120, Loss: 0.0004893626319244504\n",
      "训练次数：13125, Loss: 0.0007466253009624779\n",
      "训练次数：13130, Loss: 0.002005778718739748\n",
      "训练次数：13135, Loss: 0.0008393677999265492\n",
      "训练次数：13140, Loss: 0.004004382528364658\n",
      "训练次数：13145, Loss: 0.0004053677839692682\n",
      "训练次数：13150, Loss: 0.0017889413284137845\n",
      "第 274 轮训练总体误差值：0.08441299200057983\n",
      "**********开始本轮验证**********\n",
      "第 274 轮训练在整体验证集上的Loss: 0.41667535342276096\n",
      "allen_273.pth 模型已保存\n",
      "--------------------第275轮训练开始----------------------\n",
      "训练次数：13155, Loss: 0.004227559082210064\n",
      "训练次数：13160, Loss: 0.0058305030688643456\n",
      "训练次数：13165, Loss: 0.0006666936096735299\n",
      "训练次数：13170, Loss: 0.007408352103084326\n",
      "训练次数：13175, Loss: 0.0004273697850294411\n",
      "训练次数：13180, Loss: 0.0009748025913722813\n",
      "训练次数：13185, Loss: 0.0012050811201334\n",
      "训练次数：13190, Loss: 0.0007305205217562616\n",
      "训练次数：13195, Loss: 0.0005188393406569958\n",
      "训练次数：13200, Loss: 0.0027065197937190533\n",
      "第 275 轮训练总体误差值：0.14594320952892303\n",
      "**********开始本轮验证**********\n",
      "第 275 轮训练在整体验证集上的Loss: 0.4921744894236326\n",
      "allen_274.pth 模型已保存\n",
      "--------------------第276轮训练开始----------------------\n",
      "训练次数：13205, Loss: 0.0069334967993199825\n",
      "训练次数：13210, Loss: 0.006611338816583157\n",
      "训练次数：13215, Loss: 0.005829737987369299\n",
      "训练次数：13220, Loss: 0.0019262167625129223\n",
      "训练次数：13225, Loss: 0.000902536092326045\n",
      "训练次数：13230, Loss: 0.001032357569783926\n",
      "训练次数：13235, Loss: 0.002661560196429491\n",
      "训练次数：13240, Loss: 0.001254935166798532\n",
      "训练次数：13245, Loss: 0.0052159931510686874\n",
      "第 276 轮训练总体误差值：0.18797869980335236\n",
      "**********开始本轮验证**********\n",
      "第 276 轮训练在整体验证集上的Loss: 0.43008650559931993\n",
      "allen_275.pth 模型已保存\n",
      "--------------------第277轮训练开始----------------------\n",
      "训练次数：13250, Loss: 0.013295638374984264\n",
      "训练次数：13255, Loss: 0.007658614777028561\n",
      "训练次数：13260, Loss: 0.001978923799470067\n",
      "训练次数：13265, Loss: 0.0018608462996780872\n",
      "训练次数：13270, Loss: 0.00017329698312096298\n",
      "训练次数：13275, Loss: 0.007469604257494211\n",
      "训练次数：13280, Loss: 0.0004954913747496903\n",
      "训练次数：13285, Loss: 0.0003673257597256452\n",
      "训练次数：13290, Loss: 0.00040907892980612814\n",
      "训练次数：13295, Loss: 0.004048006609082222\n",
      "第 277 轮训练总体误差值：0.13409197330474854\n",
      "**********开始本轮验证**********\n",
      "第 277 轮训练在整体验证集上的Loss: 0.36395030096173286\n",
      "allen_276.pth 模型已保存\n",
      "--------------------第278轮训练开始----------------------\n",
      "训练次数：13300, Loss: 0.006116537842899561\n",
      "训练次数：13305, Loss: 0.005391118582338095\n",
      "训练次数：13310, Loss: 0.0010724387830123305\n",
      "训练次数：13315, Loss: 0.0008698346791788936\n",
      "训练次数：13320, Loss: 0.0005762841901741922\n",
      "训练次数：13325, Loss: 0.0007004213402979076\n",
      "训练次数：13330, Loss: 0.0006705113337375224\n",
      "训练次数：13335, Loss: 0.00021563029440585524\n",
      "训练次数：13340, Loss: 0.0004370686365291476\n",
      "第 278 轮训练总体误差值：0.12280914187431335\n",
      "**********开始本轮验证**********\n",
      "第 278 轮训练在整体验证集上的Loss: 0.37189463060349226\n",
      "allen_277.pth 模型已保存\n",
      "--------------------第279轮训练开始----------------------\n",
      "训练次数：13345, Loss: 0.005014665424823761\n",
      "训练次数：13350, Loss: 0.0009314871858805418\n",
      "训练次数：13355, Loss: 0.0012605473166331649\n",
      "训练次数：13360, Loss: 0.0004341774038039148\n",
      "训练次数：13365, Loss: 0.000437764945672825\n",
      "训练次数：13370, Loss: 0.008824251592159271\n",
      "训练次数：13375, Loss: 0.0005976756801828742\n",
      "训练次数：13380, Loss: 0.015936229377985\n",
      "训练次数：13385, Loss: 0.0005742173525504768\n",
      "训练次数：13390, Loss: 0.002043123124167323\n",
      "第 279 轮训练总体误差值：0.07660939544439316\n",
      "**********开始本轮验证**********\n",
      "第 279 轮训练在整体验证集上的Loss: 0.37708421144634485\n",
      "allen_278.pth 模型已保存\n",
      "--------------------第280轮训练开始----------------------\n",
      "训练次数：13395, Loss: 0.0021969503723084927\n",
      "训练次数：13400, Loss: 0.0018775099888443947\n",
      "训练次数：13405, Loss: 0.0006327576702460647\n",
      "训练次数：13410, Loss: 0.0011643500765785575\n",
      "训练次数：13415, Loss: 0.00039653939893469214\n",
      "训练次数：13420, Loss: 0.00108308345079422\n",
      "训练次数：13425, Loss: 0.0005236490978859365\n",
      "训练次数：13430, Loss: 0.00026724525378085673\n",
      "训练次数：13435, Loss: 0.00041475947364233434\n",
      "训练次数：13440, Loss: 0.0009059943840838969\n",
      "第 280 轮训练总体误差值：0.055756404995918274\n",
      "**********开始本轮验证**********\n",
      "第 280 轮训练在整体验证集上的Loss: 0.3720640214160085\n",
      "allen_279.pth 模型已保存\n",
      "--------------------第281轮训练开始----------------------\n",
      "训练次数：13445, Loss: 0.003870453219860792\n",
      "训练次数：13450, Loss: 0.0013249830808490515\n",
      "训练次数：13455, Loss: 0.0015033208765089512\n",
      "训练次数：13460, Loss: 0.0020029740408062935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：13465, Loss: 0.0007701382273808122\n",
      "训练次数：13470, Loss: 0.0010259569389745593\n",
      "训练次数：13475, Loss: 0.0009851297363638878\n",
      "训练次数：13480, Loss: 0.0005516785313375294\n",
      "训练次数：13485, Loss: 0.0030320980586111546\n",
      "第 281 轮训练总体误差值：0.10012953728437424\n",
      "**********开始本轮验证**********\n",
      "第 281 轮训练在整体验证集上的Loss: 0.3731624507345259\n",
      "allen_280.pth 模型已保存\n",
      "--------------------第282轮训练开始----------------------\n",
      "训练次数：13490, Loss: 0.003942063078284264\n",
      "训练次数：13495, Loss: 0.0013908901019021869\n",
      "训练次数：13500, Loss: 0.0006866241456009448\n",
      "训练次数：13505, Loss: 0.0010424427455291152\n",
      "训练次数：13510, Loss: 0.0005132355727255344\n",
      "训练次数：13515, Loss: 0.0006694991025142372\n",
      "训练次数：13520, Loss: 0.00027780450182035565\n",
      "训练次数：13525, Loss: 0.0005245499778538942\n",
      "训练次数：13530, Loss: 0.0004992575268261135\n",
      "训练次数：13535, Loss: 0.0020823751110583544\n",
      "第 282 轮训练总体误差值：0.0615205317735672\n",
      "**********开始本轮验证**********\n",
      "第 282 轮训练在整体验证集上的Loss: 0.3425650792196393\n",
      "allen_281.pth 模型已保存\n",
      "--------------------第283轮训练开始----------------------\n",
      "训练次数：13540, Loss: 0.002170636085793376\n",
      "训练次数：13545, Loss: 0.0018380038673058152\n",
      "训练次数：13550, Loss: 0.001035301829688251\n",
      "训练次数：13555, Loss: 0.00030869845068082213\n",
      "训练次数：13560, Loss: 0.0008258426678366959\n",
      "训练次数：13565, Loss: 0.0012453800300136209\n",
      "训练次数：13570, Loss: 0.0007839881582185626\n",
      "训练次数：13575, Loss: 0.0003961926850024611\n",
      "训练次数：13580, Loss: 0.000491107115522027\n",
      "第 283 轮训练总体误差值：0.06809886544942856\n",
      "**********开始本轮验证**********\n",
      "第 283 轮训练在整体验证集上的Loss: 0.38416612055152655\n",
      "allen_282.pth 模型已保存\n",
      "--------------------第284轮训练开始----------------------\n",
      "训练次数：13585, Loss: 0.000953025883063674\n",
      "训练次数：13590, Loss: 0.0011766745010390878\n",
      "训练次数：13595, Loss: 0.0010258721886202693\n",
      "训练次数：13600, Loss: 0.0013186042197048664\n",
      "训练次数：13605, Loss: 0.0005040131509304047\n",
      "训练次数：13610, Loss: 0.002018467988818884\n",
      "训练次数：13615, Loss: 0.0009576858137734234\n",
      "训练次数：13620, Loss: 0.01806073822081089\n",
      "训练次数：13625, Loss: 0.0009664091048762202\n",
      "训练次数：13630, Loss: 0.000526130199432373\n",
      "第 284 轮训练总体误差值：0.1302863359451294\n",
      "**********开始本轮验证**********\n",
      "第 284 轮训练在整体验证集上的Loss: 0.4280687151476741\n",
      "allen_283.pth 模型已保存\n",
      "--------------------第285轮训练开始----------------------\n",
      "训练次数：13635, Loss: 0.004673738963901997\n",
      "训练次数：13640, Loss: 0.005047543440014124\n",
      "训练次数：13645, Loss: 0.0020410369616001844\n",
      "训练次数：13650, Loss: 0.003292706096544862\n",
      "训练次数：13655, Loss: 0.0004281069559510797\n",
      "训练次数：13660, Loss: 0.001828822074458003\n",
      "训练次数：13665, Loss: 0.0006065657362341881\n",
      "训练次数：13670, Loss: 0.0008204445475712419\n",
      "训练次数：13675, Loss: 0.00303207291290164\n",
      "训练次数：13680, Loss: 0.0004597191873472184\n",
      "第 285 轮训练总体误差值：0.12109662592411041\n",
      "**********开始本轮验证**********\n",
      "第 285 轮训练在整体验证集上的Loss: 0.41882044542580843\n",
      "allen_284.pth 模型已保存\n",
      "--------------------第286轮训练开始----------------------\n",
      "训练次数：13685, Loss: 0.002842035610228777\n",
      "训练次数：13690, Loss: 0.0014645273331552744\n",
      "训练次数：13695, Loss: 0.0009074746631085873\n",
      "训练次数：13700, Loss: 0.0009196572937071323\n",
      "训练次数：13705, Loss: 0.0008317409665323794\n",
      "训练次数：13710, Loss: 0.0009645308018662035\n",
      "训练次数：13715, Loss: 0.0009649121784605086\n",
      "训练次数：13720, Loss: 0.0006049694493412971\n",
      "训练次数：13725, Loss: 0.031211649999022484\n",
      "第 286 轮训练总体误差值：0.12532329559326172\n",
      "**********开始本轮验证**********\n",
      "第 286 轮训练在整体验证集上的Loss: 0.3884100643917918\n",
      "allen_285.pth 模型已保存\n",
      "--------------------第287轮训练开始----------------------\n",
      "训练次数：13730, Loss: 0.006843600422143936\n",
      "训练次数：13735, Loss: 0.0039021323900669813\n",
      "训练次数：13740, Loss: 0.002855270402505994\n",
      "训练次数：13745, Loss: 0.007346643600612879\n",
      "训练次数：13750, Loss: 0.0007764639449305832\n",
      "训练次数：13755, Loss: 0.003195279510691762\n",
      "训练次数：13760, Loss: 0.0014527258463203907\n",
      "训练次数：13765, Loss: 0.0009154818253591657\n",
      "训练次数：13770, Loss: 0.0007076357142068446\n",
      "训练次数：13775, Loss: 0.004954022355377674\n",
      "第 287 轮训练总体误差值：0.17976413667201996\n",
      "**********开始本轮验证**********\n",
      "第 287 轮训练在整体验证集上的Loss: 0.4492799686267972\n",
      "allen_286.pth 模型已保存\n",
      "--------------------第288轮训练开始----------------------\n",
      "训练次数：13780, Loss: 0.003033908549696207\n",
      "训练次数：13785, Loss: 0.006332763005048037\n",
      "训练次数：13790, Loss: 0.0010600528912618756\n",
      "训练次数：13795, Loss: 0.0005503970896825194\n",
      "训练次数：13800, Loss: 0.0006193591980263591\n",
      "训练次数：13805, Loss: 0.0005841696402058005\n",
      "训练次数：13810, Loss: 0.0006218276685103774\n",
      "训练次数：13815, Loss: 0.0002943662693724036\n",
      "训练次数：13820, Loss: 0.0004309971409384161\n",
      "第 288 轮训练总体误差值：0.08830399811267853\n",
      "**********开始本轮验证**********\n",
      "第 288 轮训练在整体验证集上的Loss: 0.3995982836931944\n",
      "allen_287.pth 模型已保存\n",
      "--------------------第289轮训练开始----------------------\n",
      "训练次数：13825, Loss: 0.003507116809487343\n",
      "训练次数：13830, Loss: 0.002333157928660512\n",
      "训练次数：13835, Loss: 0.0013865629443898797\n",
      "训练次数：13840, Loss: 0.0010070170974358916\n",
      "训练次数：13845, Loss: 0.0004960704827681184\n",
      "训练次数：13850, Loss: 0.000919985759537667\n",
      "训练次数：13855, Loss: 0.0007017985335551202\n",
      "训练次数：13860, Loss: 0.001100195455364883\n",
      "训练次数：13865, Loss: 0.00023906044953037053\n",
      "训练次数：13870, Loss: 0.0018749674782156944\n",
      "第 289 轮训练总体误差值：0.06631006300449371\n",
      "**********开始本轮验证**********\n",
      "第 289 轮训练在整体验证集上的Loss: 0.3871642220765352\n",
      "allen_288.pth 模型已保存\n",
      "--------------------第290轮训练开始----------------------\n",
      "训练次数：13875, Loss: 0.0014739178586751223\n",
      "训练次数：13880, Loss: 0.002476090332493186\n",
      "训练次数：13885, Loss: 0.0005476055084727705\n",
      "训练次数：13890, Loss: 0.0012168575776740909\n",
      "训练次数：13895, Loss: 0.0002902043634094298\n",
      "训练次数：13900, Loss: 0.0004181913973297924\n",
      "训练次数：13905, Loss: 0.00032088285661302507\n",
      "训练次数：13910, Loss: 0.00016976789629552513\n",
      "训练次数：13915, Loss: 0.00030501838773489\n",
      "训练次数：13920, Loss: 0.0011114630615338683\n",
      "第 290 轮训练总体误差值：0.041955552995204926\n",
      "**********开始本轮验证**********\n",
      "第 290 轮训练在整体验证集上的Loss: 0.29050512379035354\n",
      "allen_289.pth 模型已保存\n",
      "--------------------第291轮训练开始----------------------\n",
      "训练次数：13925, Loss: 0.0006569799734279513\n",
      "训练次数：13930, Loss: 0.0005512788775376976\n",
      "训练次数：13935, Loss: 0.0007651534979231656\n",
      "训练次数：13940, Loss: 0.0005670437822118402\n",
      "训练次数：13945, Loss: 0.000363109924364835\n",
      "训练次数：13950, Loss: 0.0007065116660669446\n",
      "训练次数：13955, Loss: 0.0004118169308640063\n",
      "训练次数：13960, Loss: 0.00033280072966590524\n",
      "训练次数：13965, Loss: 0.001621116534806788\n",
      "第 291 轮训练总体误差值：0.03462177515029907\n",
      "**********开始本轮验证**********\n",
      "第 291 轮训练在整体验证集上的Loss: 0.3536257781088352\n",
      "allen_290.pth 模型已保存\n",
      "--------------------第292轮训练开始----------------------\n",
      "训练次数：13970, Loss: 0.0022080380003899336\n",
      "训练次数：13975, Loss: 0.0007571153109893203\n",
      "训练次数：13980, Loss: 0.00042098009726032615\n",
      "训练次数：13985, Loss: 0.0009085412602871656\n",
      "训练次数：13990, Loss: 0.00047810704563744366\n",
      "训练次数：13995, Loss: 0.0009075901471078396\n",
      "训练次数：14000, Loss: 0.0005124678718857467\n",
      "训练次数：14005, Loss: 0.0001476544130127877\n",
      "训练次数：14010, Loss: 0.0002040761464741081\n",
      "训练次数：14015, Loss: 0.002027335111051798\n",
      "第 292 轮训练总体误差值：0.03487366810441017\n",
      "**********开始本轮验证**********\n",
      "第 292 轮训练在整体验证集上的Loss: 0.33225176529958844\n",
      "allen_291.pth 模型已保存\n",
      "--------------------第293轮训练开始----------------------\n",
      "训练次数：14020, Loss: 0.0012577513698488474\n",
      "训练次数：14025, Loss: 0.0008303771028295159\n",
      "训练次数：14030, Loss: 0.0005680184694938362\n",
      "训练次数：14035, Loss: 0.0007724410970695317\n",
      "训练次数：14040, Loss: 0.00043668519356288016\n",
      "训练次数：14045, Loss: 0.0004189952742308378\n",
      "训练次数：14050, Loss: 0.00038671231595799327\n",
      "训练次数：14055, Loss: 0.00010436258162371814\n",
      "训练次数：14060, Loss: 0.00016380382294300944\n",
      "第 293 轮训练总体误差值：0.03585789352655411\n",
      "**********开始本轮验证**********\n",
      "第 293 轮训练在整体验证集上的Loss: 0.3446480864658952\n",
      "allen_292.pth 模型已保存\n",
      "--------------------第294轮训练开始----------------------\n",
      "训练次数：14065, Loss: 0.00265482347458601\n",
      "训练次数：14070, Loss: 0.0003056449058931321\n",
      "训练次数：14075, Loss: 0.00034413827233947814\n",
      "训练次数：14080, Loss: 0.00034431691165082157\n",
      "训练次数：14085, Loss: 0.0002744613157119602\n",
      "训练次数：14090, Loss: 0.0006567348027601838\n",
      "训练次数：14095, Loss: 0.00031124718952924013\n",
      "训练次数：14100, Loss: 0.0003006754850503057\n",
      "训练次数：14105, Loss: 7.648827158845961e-05\n",
      "训练次数：14110, Loss: 0.002371314214542508\n",
      "第 294 轮训练总体误差值：0.0303536057472229\n",
      "**********开始本轮验证**********\n",
      "第 294 轮训练在整体验证集上的Loss: 0.3197652413509786\n",
      "allen_293.pth 模型已保存\n",
      "--------------------第295轮训练开始----------------------\n",
      "训练次数：14115, Loss: 0.0006222727824933827\n",
      "训练次数：14120, Loss: 0.000849337549880147\n",
      "训练次数：14125, Loss: 0.0002671972324606031\n",
      "训练次数：14130, Loss: 0.0005182098248042166\n",
      "训练次数：14135, Loss: 0.0004341612511780113\n",
      "训练次数：14140, Loss: 0.0002580687287263572\n",
      "训练次数：14145, Loss: 0.00024770398158580065\n",
      "训练次数：14150, Loss: 7.575198833364993e-05\n",
      "训练次数：14155, Loss: 0.0001917095942189917\n",
      "训练次数：14160, Loss: 0.0019646103028208017\n",
      "第 295 轮训练总体误差值：0.029624847695231438\n",
      "**********开始本轮验证**********\n",
      "第 295 轮训练在整体验证集上的Loss: 0.33880363078787923\n",
      "allen_294.pth 模型已保存\n",
      "--------------------第296轮训练开始----------------------\n",
      "训练次数：14165, Loss: 0.00033142438041977584\n",
      "训练次数：14170, Loss: 0.0004862194473389536\n",
      "训练次数：14175, Loss: 0.00047239745617844164\n",
      "训练次数：14180, Loss: 0.00022595126938540488\n",
      "训练次数：14185, Loss: 0.0005113780498504639\n",
      "训练次数：14190, Loss: 0.0004531520535238087\n",
      "训练次数：14195, Loss: 0.0003380301350262016\n",
      "训练次数：14200, Loss: 0.00019320582214277238\n",
      "训练次数：14205, Loss: 0.0024412651546299458\n",
      "第 296 轮训练总体误差值：0.029333174228668213\n",
      "**********开始本轮验证**********\n",
      "第 296 轮训练在整体验证集上的Loss: 0.3318685768172145\n",
      "allen_295.pth 模型已保存\n",
      "--------------------第297轮训练开始----------------------\n",
      "训练次数：14210, Loss: 0.0015153924468904734\n",
      "训练次数：14215, Loss: 0.00043522054329514503\n",
      "训练次数：14220, Loss: 0.0009300413657911122\n",
      "训练次数：14225, Loss: 0.0009204700472764671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练次数：14230, Loss: 0.00028509445837698877\n",
      "训练次数：14235, Loss: 0.00028072731220163405\n",
      "训练次数：14240, Loss: 0.00019957403128501028\n",
      "训练次数：14245, Loss: 0.00017742018098942935\n",
      "训练次数：14250, Loss: 0.00018028686463367194\n",
      "训练次数：14255, Loss: 0.0027105154003947973\n",
      "第 297 轮训练总体误差值：0.02981092408299446\n",
      "**********开始本轮验证**********\n",
      "第 297 轮训练在整体验证集上的Loss: 0.3162786988541484\n",
      "allen_296.pth 模型已保存\n",
      "--------------------第298轮训练开始----------------------\n",
      "训练次数：14260, Loss: 0.0004573563055600971\n",
      "训练次数：14265, Loss: 0.00041698041604831815\n",
      "训练次数：14270, Loss: 0.0005279973847791553\n",
      "训练次数：14275, Loss: 0.00018407872994430363\n",
      "训练次数：14280, Loss: 0.00019513521692715585\n",
      "训练次数：14285, Loss: 0.00036064974847249687\n",
      "训练次数：14290, Loss: 0.00031402349122799933\n",
      "训练次数：14295, Loss: 0.0001797143486328423\n",
      "训练次数：14300, Loss: 0.0001269000058528036\n",
      "第 298 轮训练总体误差值：0.026602301746606827\n",
      "**********开始本轮验证**********\n",
      "第 298 轮训练在整体验证集上的Loss: 0.33900557924062014\n",
      "allen_297.pth 模型已保存\n",
      "--------------------第299轮训练开始----------------------\n",
      "训练次数：14305, Loss: 0.0009859255515038967\n",
      "训练次数：14310, Loss: 0.00031861610477790236\n",
      "训练次数：14315, Loss: 0.0006565501098521054\n",
      "训练次数：14320, Loss: 0.0002942510473076254\n",
      "训练次数：14325, Loss: 0.00014024692063685507\n",
      "训练次数：14330, Loss: 0.0003673211031127721\n",
      "训练次数：14335, Loss: 0.0002845209965016693\n",
      "训练次数：14340, Loss: 0.0002588534844107926\n",
      "训练次数：14345, Loss: 4.777334106620401e-05\n",
      "训练次数：14350, Loss: 0.004051428288221359\n",
      "第 299 轮训练总体误差值：0.028582535684108734\n",
      "**********开始本轮验证**********\n",
      "第 299 轮训练在整体验证集上的Loss: 0.3008581246249378\n",
      "allen_298.pth 模型已保存\n",
      "--------------------第300轮训练开始----------------------\n",
      "训练次数：14355, Loss: 0.0005831325543113053\n",
      "训练次数：14360, Loss: 0.0006836510146968067\n",
      "训练次数：14365, Loss: 0.00046892769751138985\n",
      "训练次数：14370, Loss: 0.00028808327624574304\n",
      "训练次数：14375, Loss: 0.0001455725432606414\n",
      "训练次数：14380, Loss: 0.00030091049848124385\n",
      "训练次数：14385, Loss: 0.0001462963264202699\n",
      "训练次数：14390, Loss: 8.411824092036113e-05\n",
      "训练次数：14395, Loss: 0.0001979468943318352\n",
      "训练次数：14400, Loss: 0.0018808746244758368\n",
      "第 300 轮训练总体误差值：0.02888166345655918\n",
      "**********开始本轮验证**********\n",
      "第 300 轮训练在整体验证集上的Loss: 0.3459365703165531\n",
      "allen_299.pth 模型已保存\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "# 记录训练次数\n",
    "total_train_step = 0\n",
    "# 记录测试次数\n",
    "total_test_step = 0    \n",
    "\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    print(\"--------------------第{}轮训练开始----------------------\".format(t+1))\n",
    "    model.train()\n",
    "    \n",
    "    # 记录一轮训练的总损失值\n",
    "    total_train_loss = 0\n",
    "    for data in train_loader:\n",
    "        feats, tars = data\n",
    "        feats = feats\n",
    "        tars = tars\n",
    "        \n",
    "        y_train_pred = model(feats)\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(y_train_pred, tars)\n",
    "        \n",
    "        total_train_loss += loss\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimiser.step()\n",
    "\n",
    "        total_train_step += 1\n",
    "        \n",
    "        if total_train_step % 5 == 0:\n",
    "            print(\"训练次数：{}, Loss: {}\".format(total_train_step,loss.item()))\n",
    "    print('第 {} 轮训练总体误差值：{}'.format(t+1,total_train_loss))\n",
    "    \n",
    "    #测试步骤开始\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        print(\"**********开始本轮验证**********\".format(t+1))\n",
    "        for data in test_loader:\n",
    "            feats,tars = data\n",
    "            feats = feats\n",
    "            tars = tars\n",
    "\n",
    "            y_train_pred = model(feats)\n",
    "            \n",
    "            loss = loss_fn(y_train_pred,tars)\n",
    "            \n",
    "            total_test_loss += loss.item()\n",
    "            \n",
    "    print(\"第 {} 轮训练在整体验证集上的Loss: {}\".format(t+1,total_test_loss))\n",
    "\n",
    "    total_test_step += 1\n",
    "\n",
    "    #保存每一轮训练的模型\n",
    "    torch.save(model.state_dict(), \"./saved_model3/allen_{}.pth\".format(t))\n",
    "    print(\"allen_{}.pth 模型已保存\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41d448b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "model.load_state_dict(torch.load(r\"./saved_model3/allen_299.pth\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8209d69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预测第一个被试的测试数据\n",
    "model.eval()\n",
    "y_test_pred = model(testX.to(device))\n",
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb49471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2273, device='cuda:0', grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 计算RMSE\n",
    "mse_loss = loss_fn(y_test_pred, testY.to(device))\n",
    "rmse_loss = torch.sqrt(mse_loss)\n",
    "print(rmse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48e1e3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1340, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 使用MAE损失函数计算损失\n",
    "mae_loss = F.l1_loss(y_test_pred, testY.to(device))\n",
    "mae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c37dfaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转移到CPU并更改数据类型为numpy.ndarray\n",
    "pred_value = y_test_pred.cpu().detach().numpy()\n",
    "true_value = testY.cpu().numpy()\n",
    "pred_value = scaler3.inverse_transform(pred_value)\n",
    "true_value = scaler3.inverse_transform(true_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c01dad5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_value = true_value[:,-1].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d40c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_value = pred_value[:,-1].round() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8df22b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1f9d1379910>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成示例数据，实际观测值和预测值\n",
    "actual_values = true_value\n",
    "predicted_values = pred_value\n",
    "\n",
    "# 计算Clarke EGA图中的区域\n",
    "def clarke_ega_region(actual, predicted):\n",
    "    abs_diff = np.abs(predicted - actual)\n",
    "    zones = np.zeros_like(abs_diff, dtype=int)\n",
    "    zones[(abs_diff <= 1)] = 1\n",
    "    zones[(abs_diff <= 2) & (abs_diff >1)] = 2\n",
    "    zones[(abs_diff <= 3) & (abs_diff > 2)] = 3\n",
    "    zones[(abs_diff <= 4) & (abs_diff > 3)] = 4\n",
    "    zones[(abs_diff > 5)] = 5\n",
    "    return zones\n",
    "\n",
    "zones = clarke_ega_region(actual_values, predicted_values)\n",
    "\n",
    "# 绘制Clarke EGA图\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(actual_values, predicted_values, c=zones, cmap='cool', marker='o')\n",
    "plt.plot([30,300], [30,300], color='gray', linestyle='--')\n",
    "plt.xlim(30,300)\n",
    "plt.ylim(30,300)\n",
    "plt.title(\"Clarke EGA\")\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "\n",
    "plt.grid()\n",
    "plt.colorbar(label=\"Zone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acd765d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制predict 和 targets 的对比图\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(pred_value, label=\"Predict\")    # 预测值\n",
    "plt.plot(true_value, label=\"targets\")    # 真实值\n",
    "plt.grid(True, color='gray', linestyle='--', linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ece37f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 24, 7])\n"
     ]
    }
   ],
   "source": [
    "# 想使用训练集的最后一个窗口预测训练集的下一个数据，再将窗口第一个数据弹出，将预测值插入窗口末尾组成一个新窗口。但是模型的输出是单个血糖值\n",
    "# 缺了一些时间特征。要想实现真正的预测（有误差积累的预测）必须改变模型，使模型输出一个样本。\n",
    "result = []\n",
    "x = testX[0,:,:].unsqueeze(0).to(device)\n",
    "print(x.shape)\n",
    "for i in range(50):\n",
    "    \n",
    "    y = model(x)\n",
    "    \n",
    "    x = torch.cat((x[:,1:,:], y.unsqueeze(1)), dim=1)\n",
    "\n",
    "    result.append(y.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a53d5798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1, 7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = np.array(result)\n",
    "print(result.shape)\n",
    "pred_values = scaler3.inverse_transform(result.reshape(-1,7))[:,-1].round()\n",
    "\n",
    "true_values = testY.cpu().numpy()\n",
    "true_values = scaler3.inverse_transform(true_values)[:,-1].round()\n",
    "\n",
    "plt.plot(pred_values,color='cyan',label='predicts')\n",
    "plt.plot(true_values,color='orange', label='targets')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3736aa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(344,len(testY)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
